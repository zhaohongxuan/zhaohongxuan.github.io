[{"title":"2025：平凡的一年","path":"/2026/01/28/2025-review/","content":"转眼间，已经2026年1月底，明天就是我的35岁生日，2025年度复盘的文档在年底都已建好，但是迟迟没有动笔，我当时给自己找到理由是：复盘太过于正式，会让自己形成表演人格，而我并不需要给任何人展示我的人生， 我很赞同某些人不写年终总结，他们有自己的复盘机制，但是对于我来说年终复盘是一个很好的回顾的机会，年终总结我也写了好几年的，所以我决定今年继续，这只是给自己做一个阶段性的回顾，无关任何人，我没有那么多观众，场上只有我一个人。 健康健康目前对我来说是最最重要的，因为有了健康的1才有了其他的0，健康也包括了和肉体健康和精神健康， 保持肉体健康是所有一切的基础，灵魂需要栖居在这个肉体躯壳上，健康的肉体需要充足的睡眠，健康的饮食和规律的运动（有氧+无氧）。 良好的睡眠是所有的健康基础，更是在运动之上，由于睡觉一直戴手表，因此我能够完整的记录我的睡眠状况，现在有了睡眠评分，更是很容易能够判断自己的睡眠质量，大部分时候基本上都能很快入睡，基本上每天睡眠评分都能在 90 分以上甚至是 100 分。我是那种不赖床的人，如果睡醒了就很难再睡，因此基本上 6、7点多醒了之后就开始洗冷水澡、早起运动开启新的一天了。 饮食方面，在公司时候，基本上会自己准备简午晚餐，一般会有优质蛋白，三文鱼鸡胸肉牛肉等，然后搭配一个慢碳+鸡蛋+蔬菜，使用保鲜密封袋装好，到公司吃饭的时候微波炉里热一下就可以直接吃，每次吃完密封袋就可以扔了，不需要洗碗非常方便。 4 月份开始[[冲冷水澡这件小事|洗冷水澡]]，一直到现在，基本上没有间断过，倒不是什么难事或者值得夸耀的，和Naval说的一样，刚开始脑海会有个声音说水非常冷，所以缩手缩脚的不敢进，现在已经基本没有犹豫时间了，打开花洒就能直接进去，当身体真正接触到冷水时会发现其实没有那么冷，相当一部分的冷是大脑虚构的，现在洗冷水澡已经和做俯卧撑一样成为我早起Routine一部分了。 睡了冷水澡，我的早起 Routine 还会做 50 个俯卧撑和 50 个深蹲，50 个俯卧撑本来是已经做了很长一段时间了，但是在看完[[Pavel Durov - Lex Fridman Podcast]] 的播客之后，我又为自己增加了 50 个深蹲，现在深蹲也成为了早上 Routine 的一部分。 跑步今年是我开始持续跑步 12 年了，今年跑步确实比较多，因为一些天气不好的时候，我也会在公司的健身房跑步，因此虽然每次基本上都是 5 公里，但是频率保持的，所以今年还是跑了有 1400km。 其实年初，我是没有设置目标的，基本上比较随缘。不把跑步看成是一种必须要完成的任务，而是把跑步当做一种习惯，不需要靠毅力完成，事实上如果是要靠毅力的话，我想要我不会持续这十几年。 跑步对我而言是一种冥想，只不过不是盘腿坐着的冥想，而是动态的，在跑步的过程中可以思考一些我一直在思考的问题，或者就只关注在脚下的每一步，或者关注于每一次的呼吸。这都让我的内心获得了更多的平静，今年依然是没有定具体的目标，能够到 1000km 就好。 力量训练今年开始练习引体引上了，从刚开始的一次只能拉五六个，到现在基本上已经很容易做到 20 个了。公司的新健身房开始使用之后，开始练习负重深蹲了，最高能蹲到 130kg 了，不过后面我也不打算继续往上练了，我的目标不是成为大肌霸，我觉得肌肉很大很难看，我想要的是更加健康匀称的身材。看完[[超越百岁：长寿的科学与艺术]]之后，我基本上每周会有一次练习力量训练，然后一天休息，5 天时间进行有氧训练，就是区间2心率跑步。 工作2025年是AI 爆发的一年，所有人都似乎都开始意识到AI的影响力，程序员是最能直观感受到这种变化的一群人，Coding Agent的能力每天都在持续进化，我从年初开始在工作中使用 Curosr 和 Github Copilot，到现在基本上90 %以上的业务代码全部都由AI Agent完成了， 不仅可以写代码，还有很多的文档也都是AI Agent帮忙完成的，然后人工再做调整，AI 现在来构建我的工作流，还在大团队分享了我的 [[AI Coding工具的使用分享]]，让更多的人使用AI来提高自己的工作效率。 关于工作，我的一贯观点是：需求是做不完的，bug 是解不完的，特别是在看了高广辉猝死的案例，必须要用最少的时间来投入到价值最高的任务中去，专注于核心任务。同时要注意放松，不能一直高强度投入，特别是现在 AI Agent发展这么迅猛的阶段，认真花一段时间来写一个prompt更为重要,让 Agent 跑起来，然后就是自己短暂的休息时间了，去茶水间、或者楼下溜一圈都是 OK 的，作为人类，你需要的是让自己的脑子更加清晰，给 AI 提供更清晰的上下文和指令，而不是拼体力。相信我，大部分你认为天要塌下来的任务到最后塌不下来，恐惧只源于想象。 关于加班，今年的加班相比较之前而言少了许多，对于互联网公司，加班是不可避免的，但是基本上每天也能在 9 点之前下班，工作日的运动一般也是在公司进行了，在中午或者晚上，基本上没有缺席的日子，如果是跑步就在公司旁边的绿道上进行，跑完之后在健身房冲澡，完美解决没有时间跑步借口的问题。 AI Agent 无疑大幅提升了效率，特别是让开发的时间大幅降低，可以有更多的时间去思考做什么，如何设计等根本问题，让 AI 提供各种 option，然后给出决策，Coding 本身变得越来越廉价，但是判断的价值正在上升，因为有的时候 AI 写的代码并不简洁优雅，工程师的价值正在重估， 每个人都需要思考 AI 不能做什么，以及 AI 可以放大什么，毕竟在快速变化的世界里能适应变化的人才能生存。 生活今年9 月份小渔上幼儿园了，越来越明显感觉到现在已经是一个独立的个体了，吃饭、睡觉、上厕所等基本上能够自理了，最让人欣慰的是之前一直尿裤子的问题也消失了，很多事情可能自己急也没用，可能到了一定时间节点就会消失了，成长也是一样。 今年和女儿一起练习拼图，刚开始和我一起探索，共度了很多美好的亲子时光，刚开始的时候拼图是非常困难的，可能摸索好大一会儿才拼好一片，但是随着拼的次数增加，大脑记住了大部分的模式，现在女儿拼图的速度已经非常快了，自己一个人对于120片的拼图也能很快拼好，很多时候比我的速度都要快了。 旅游今年年中和老婆一起去日本玩了 5 天，整个行程挺紧的，不过玩得也是很开心，去了神户须磨，在海边躺了一天，在大阪玩了两天，吃了很多好吃的，走马观花的逛了很多地方，还给老婆买了个包，整体来讲大阪之行还算是比较顺利和美好的，不过现在中日关系有些紧张，今年大概率可能就去不了。 暑假的时候和女儿还有她堂姐一起去了海昌公园，一起玩泡泡水枪打水仗，看了虎鲸表演、美人鱼、水母群等，下午的时候下起了暴雨，在暴雨中坐了缆车，整个过程和姐姐一起玩得非常开心。 国庆节青岛自驾游，总体来说还算不错，在青岛和日照玩了几天，基本上就是在沙滩上玩，在别的很多地方都让抱着，对于小孩子而言，没有什么比玩沙子更开心的事情了，和女儿堆了很多沙堡，非常快乐，到了国庆节天气开始狂风暴雨，提前回上海了，唯一不开心的事情是在黄岛开车的时候还被摄像头拍了，人生第一次被摄像头拍到逆行被罚钱。 金秋十月，带全家人去杭州了几次，去九溪看红叶，爬了标毅线的一部分，拜访了灵隐寺，灵隐路上的红叶非常漂亮，杭州很美。 读书今年读书整体上和去年差不多，能够直观的感觉到的是：工作日的上班途中，地铁上我基本上都会使用阅读器看微信读书或者用iPad 进行 PDF 的阅读，细数下来今年还是读了不少书基本上每个月都有一本。 数量不是关键，关键是我能从书中吸取到什么东西。今年都的最好的五本书是： [[超越百岁：长寿的科学与艺术]] [[马可瓦尔多（卡尔维诺作品）]] [[小岛经济学]] [[爱的艺术]] [[雪球特别版：段永平投资问答录（商业逻辑篇）]] 今年很喜欢在阳台上读书，每天早上起来，洗完冷水澡、做完俯卧撑，在阳台上静坐一段时间看书，早上起来整个城市都是安静的，没有人打扰，这种感觉真的能让人感受到平静的力量。 总结回看 2025 年，我给自己打 80 分。整体是踏实的一年：我对想做的事依然保持了很强的执行力，也把更多注意力放在了健康上——规律训练让身体状态更匀称稳定，持续跑步也让我更容易获得平静。说到底，我做这些事情，是为了让生活更好、家庭更幸福，也让自己内心更安稳。 遗憾的是，今年公开写作明显少了。虽然在 Obsidian 里记录了不少，但很多停留在零散的素材，没能沉淀成系统的文章和博客。2026 年我希望自己多思考、多输出，把记录变成作品：更稳定地写、更持续地发布。","tags":["年终总结"],"categories":["年终总结"]},{"title":"2024：拥抱不确定","path":"/2025/02/19/2024-review/","content":"不知不觉马上就过 2025农历蛇年了，这篇年终总结也从 2024 年 12 月份开始要写的年终总结也一直拖到了现在（1 月 13 号），又拖到了今天发布，一直都在以各种借口拖延，加班很多，工作很「忙」，但是对我来说，「忙」也要抽出时间来做一个简短的总结来回顾一下这一年，人生总要在一定的时间停下来，思考复盘一下，一直忙忙忙，其实是盲盲盲，被事情遮蔽了眼睛会离自己的目标越来越远。 失业2024 最大的变化应该就是经历了失业，2024 年好像没经历过失业就不好意思似的。 前司是一个外企，主要做的是奢侈品电商的生意，2024 年业绩加速下滑，卖身 coupon 之后先后在 3 月份和 6 月份连续裁员了两波，我在6 月份的裁员名单上。虽然不舍，但是没有办法，业务线关停不是个人能够阻拦的，裁员时 Manager 也在不断的给我们推荐其他的面试机会。 整个 7 月份和 8 月份基本上都是在面试中度过的，能感受到今年的就业形势确实不好，很多公司其实没有真的在招人，或者说是在，基本上每天一场到 2 场面试，心情也是起起伏伏，好几个面试都是到了最后谈薪资挂的，还有好几次是 3～4 面挂的，确实有些焦虑，经历了一个多月的GAP时间入职了携程商旅。 新机商旅主要是做Saas toB生意的，国内的 Saas 市场确实非常畸形，基本上都是在完成甲方爸爸的各种需求，哪个甲方爸爸更大更有钱就更听谁的。 从 9 月份入职以来，刚好跟上开始加班赶进度，开始每周六都上上班，每天基本上都要 9 点～10 点下班，周六也要加班，一直到元旦才结束，彻底体验了一把 996，我前司的 Leader 也跟我一起进入了携程，他干了不到 3 个月在转正前走了，一直呆在国企的人是没有办法适应互联网这种工作环境，而我选择继续坚守，因为之前落户到一半，被裁员了，首先要现稳住把上海落户这件事情先办好。 在前司，我是团队中年龄最小的，基本上有问题也还可以请教老同事什么的，在新公司，我们的团队中有不少外包员工，正式员工年龄都比较小好几个都是校招生，我是团队中正式员工中年龄最大的，基本上很多事情都会问我，承担了更多的责任。 适应新的公司确实需要时间，在目前的阶段，需求如雪花一般飘来，代码经过测试测过就上线了，代码中没有UT，也没有 review，有专门的 review 评审会，但是时间很短，基本上看不出来什么问题，特别是一个 MR 中有几十个文件变更这种。代码质量完全不能保障，线上经常出现这样那样的问题，不是在救火就是在救火的路上，确实压力比较大。 绩效在互联网公司是第一重要的事情，所以底层员工之间格外的卷，基本上每个人都是为了晋升和绩效拼了命的工作，特别是为了晋升，基本上晋升一次就像脱了一层皮一样，互联网公司就是这么神奇的地方，只要加入了就会自动开始卷起来。在本来就不太乐观的大环境下，外企加速撤离让互联网企业更加肆无忌惮，携程还算互联网公司里面比较好的，但是下面的各个 BU 又是另外一番景象了，比如居家办公，在大部分 BU 里已经名存实亡了。 运动跑步8月份的时候跑步里程达到了10000公里了，以前觉得一万公里是一个很难达到的数字，跑步10年也达到了这个数字，算是一个里程碑吧，毕竟人生也不过才三万多天。 对我来说，健康是第一重要的事情，健康是 1，其他的都是 0，因此我还是在践行跑步来保持身体健康，我最少会安排一周两次的跑步，不管再忙，不同的是今年没有参加一场马拉松，对马拉松不再狂热了，跑步已经完全融入生活了，虽然今年每次跑步的距离不长，超过 10km 的都很少，但是频次很高，基本上每周都会跑 3～5 次，所以，总结下来，这一年还是跑了有一千多公里，对不追求成绩的我来说，已经很好了。 跑步了一千多公里，虽然今年每次跑的都不远，但是频次高，公司也有跑步机，所以冬天跑步的并不少，所以也有1000km，但是体重没有降下去，应该是因为力量训练少了。 骑行在发发奇的时候周末还有时间出去骑车，骑了好几次淀山湖，但是到新公司之后几乎不再骑行了，因为刚好遇到了周末加班，周末本来休息时间就一天主要用来陪娃玩了，没有时间出去骑车了。 读书今年读书也还不少，能看到八月份没有读完一本书，因为忙着准备面试，静不下来心来读书，我的读书时间基本上就是在地铁上进行的，地铁上的通勤时间就是我的阅读时间。 从读书的分类来看，我的确是一个 J 人，更多喜欢历史和哲学。今年我阅读了更多的历史和哲学，也渐渐接受了步入中年的事实，慢慢开始向内求索，去看内心最真实的想法，尝试和自己和解。 下面是我使用 Obsidian 微信读书插件同步了我所有在微信读书读过的书籍，然后配合 dataview 插件可以制作比较漂亮的读书卡片。 读完了两本英文原著，一本是 Steve Jobs 的《Make something wonderful》还有一个是 Morgan Hosel 的《The Psychology of Money》都收获满满。 生活家庭提前还贷，把目前房子的商贷提前还完了 旅行3月份去了覆卮山，玩的很开心4月份去了苏州太湖西山5月份回了老家，去龙门山上采摘樱桃，玩的很开心8月底，在暑假的尾巴收到了offer， 带老妈和女儿回老家呆了一周多，在家里玩的很开心，虽然一到家就被蚊子咬了几个包 .9～12月基本上就是加班了，周末就在周边附近玩了，哪里也没有去，10月份第三次环太湖计划也被迫终止。","tags":["年终总结"],"categories":["年终总结"]},{"title":"记录人生第一次裁员","path":"/2024/10/10/layoff-first-time/","content":"新公司入职有一段时间了，感觉是时候记录一下裁员的这段经历了，「裁员」在这个行业里应该是每个人都必须经历的事情，现在回想起来那一个多月真的是比较煎熬和恐惧。 2024年7月19日，体验了人生中的第一次裁员，现在所做的公司是一个跨境电商Farfetch，疫情结束后业绩加速衰落，3月份刚经历一波裁员，我的几个同事都被裁掉了，6月份又来了一波裁员，谁也没想到来的会这么快，只不过这一次这个天猫的业务都要关门了，当然我们team和隔壁team的全都被裁员了，其实这已经不是第一次裁员了，从2022年年中的时候就已经有第一波裁员了，首先裁员的是外包同学，然后是我们team的其中一位同学。2023年年中的时候又经历了一波裁员，到这一次已经是第4次裁员了。 我对裁员其实没有特别大的抵触，公司还算厚道，毕竟裁员补偿N+3还算厚道，还按照年工资进行折算，补偿非常丰厚，部门领导也很nice，忙着给我们推荐各种各样的工作机会。虽然是业务调整，虽然原因不在自己，但是依然是有很强的挫败感，受到了莫大的打击。 很多被裁同事都说要出去玩，放松一下，但是对我来说，我无法忽视失业这件事情，外出旅游在我看来是一个逃避，必须要直视问题，解决问题才能解开心中的疙瘩，于是基本上每天都是面试，复习，刷Leetcode算法题，总结面试经验等等，焦虑和紧张一直伴随着我，白天基本上就是上午下午两场，基本上每天都有面试。招聘市场确实不是很好，很多公司一个岗位可能有大量的竞争，经常面试到2、3轮之后挂掉的，还有面试过了不发Offer的，确实都让人很糟心 整个夏天最热的时候，基本上很少出门，都呆在家里，跑步也不多，可能是心情的原因，找工作的这段时间我的体重减少了至少 10 斤，食欲一直不怎么好。 一直在家里待着找工作实在是考验心态，面试的过程中，大部分的公司都是很 nice 的，但是也有一些很傻X的公司。心情就像过山车一样，随着每天的各种面试和反馈一起波动，一天面2到3场，一天就过去了，当然在我看来这一段时间也是很宝贵的人生体验，再过若干年以后这一段经历也是，不过，随着时间的增加和面试经验的增加，明显感觉情况开始逐渐变好了，之前一些公司1、2面就挂，慢慢的可以进到3、4轮以及最终轮了，于是offer变成顺理成章的事情了。 我的工作机会主要是朋友推荐，有前公司 Leader 帮忙介绍的工作机会，还有一些猎头推荐的外企机会，还有yihong大哥给推荐的几个外企，最后就是 Boss直聘了，领英上投递的公司普遍反应很慢，有的公司我都入职很久了才打电话过来说要面试。 现在的就业市场确实很残酷，不仅有大批量的毕业生涌入，还有很多被裁员的也在市场上竞争，工作没有前几年那么好找了，但是机会依然还有不少，但是对于个人的能力的要求也越来越高，不仅仅是算法，还有更多的场景设计题，公司大多都会更加全面的考察一个人的综合能力，额外的开源项目会让自己多收获一些面试机会，同事面试官也会加分不少，但是主要还是得自己的实力足够硬，在面试的过程中，最有效的方法，还是不停的面试，然后总结、改进，继续面试，螺旋上升，没有其他的捷径。 我也不知道过了这么久才想起写这么一篇关于裁员的blog，回过头来出那一段时间过得确实很焦虑，现在联系之前的同事，还有一些年龄大的同事还没找到合适的工作，这个行业可能比我想象的要更加残酷一些，未来不可避免的肯定还会遇到裁员，但是有了这一段经历感觉也没有那么害怕了，都是宝贵的人生经验。 从现在开始要逐步积累自己的势能，在公司做事情的时候，一定要多考虑对自身的提升，哪些可以作为杠杆为自己的未来加分，对公司来说可能我们只是一个「螺丝钉」，但是对于你自己来说，你就是第一负「责任人」，我们永远可以在「当下」做一些事情来改变「未来」的处境。","tags":["裁员","面试"],"categories":["散文随笔"]},{"title":"使用Obsidian Dataview搭建微信读书阅读主页","path":"/2024/05/31/obsidian-weread-card-overview/","content":"之前在Weread的Wiki中介绍过使用Dataview和Minimal主题管理微信读书的方法：使用Dataview进行书籍管理 ，随着Weread插件的不断迭代，现在增加了不少元数据，比如，开始阅读日期:readingDate，完成阅读日期：finishedDate ，阅读进度：progress等，且不需要手动添加readYear属性了，有了这些新的数据就可以更好的汇总读书数据了。 使用效果如图： 准备 下载 Obsidian - Sharpen your thinking，并安装好软件 安装Obsidian Weread 插件，本人开发的一款Obsidian插件，用于同步所有的微信读书数据，有了数据才能做汇总页，可以在Obsidian官方市场下载或者Github Release页面下载手动安装：GitHub - zhaohongxuanobsidian-weread-plugin 安装Obsidian Dataview插件，官方市场下载 Minimal主题或者自定义Card View 的css， 如果使用Minimal主题的话就不需要自定义css了， 步骤同步微信读书数据通过本人开发的 Obsidian Weread 插件，将自己微信读书的数据同步到Obsidian中，有了数据才能做汇总页，更多使用说明，可以参考微信读书Obsidian插件主页：GitHub - zhaohongxuanobsidian-weread-plugin: Obsidian Weread Plugin is a plugin to sync Weread(微信读书) hightlights and annotations into your Obsidian Vault. 这里需要记录下自己的微信读书笔记的文件夹，比如我自己的是Reading/Weread 主题准备选项一：安装minimal 主题，直接在官方主题市场搜索下载 选项二：由于Card View的效果提取自minimal主题，因此，如果不适用minimal主题的话就需要手动安装Card View的css样式表。下载Cards.css 放置到自定义css文件夹中、然后启用该css。 具体操作如下： 创建Card页面创建一个空白页面，以源码的方式编辑文档，在文件的顶部，粘贴以下代码： ---cssclasses: - cards - cards-cols-5 - iframe-wide - cards-cover - cards-align-bottom--- 这段代码是和css搭配的，顶部有这些属性的文档才会应用Card View 样式，不会影响到其他的文档。 使用Dataview筛选数据使用Dataview可以很方便的筛选、汇总数据，这里主要使用微信读书笔记的元数据进行筛选和汇总，这些字段默认都会在文档顶部的frontmatter中存在。 我这里主要使用的属性如下： cover 书籍的封面 file.link 表示的是双链地址 readingTime 阅读时长 readingStatus 阅读状态，总共有四个状态，空、在读、读过、读完。 author 作者 readingDate 开始阅读的时间 finishedDate 开始阅读的时间 lastReadDate 最近一次阅读时间 我的微信读书汇总页面，总共分成三个部分，2024在读清单、2024完成清单、历史完成清单，把当前年份领出来就是为了方便自己查看当年的数据。 2024年在读清单这里包括了，我2024年阅读的书籍，过滤条件为： 微信读书文件夹，我这里是 Reading/weread cover不为空的 readingStatus 是在读的 lastReadDate.year 是 2024年的最后一个条件表示的是，如果一本书在今年以前没读完，今年又重新读了，会被归结到今年在读清单里。 table without id (![]( + cover + )) as cover ,file.link as Title, readingTime, readingStatus, author as Author, dateformat(readingDate,yyyy-MM-dd) from Reading/weread where cover != null and readingStatus = 在读 and lastReadDate.year = 2024 2024年已读清单这个脚本抓取的是2024年已经阅读完成的书籍，上在读不一样的地方： readingStatus 是读完的，这个依赖于你自己在微信读书上面的标记，一般来说，我们每读一本书都会标记成读完。 finishedDate.year 2024 table without id (![]( + cover + )) as cover, file.link as Title, author as Author, 笔记： + noteCount as NoteCount, dateformat(finishedDate,yyyy-MM-dd) , readingTimefrom Reading/weread where cover != null and readingStatus = 读完 and finishedDate.year = 2024 SORT finishedDate DESC 历史已读就是上面的脚本，把上面的换成，就是历史所有的已读书籍。 table without id (![]( + cover + )) as Cover ,file.link as Title, author as Author, 笔记： + noteCount as NoteCount, dateformat(finishedDate,yyyy-MM-dd) as FinishedDate from Reading/weread where cover != null and readingStatus = 读完 and finishedDate.year 2024sort finishedDate DESC 总结Obsdian的玩法很多，你可以根据自己的实际需求来进行更改，添加自己需要展示的字段，删除不需要展示的字段，而且不使用自定义css和minimal主题也可以完成，比如使用Project插件和Component插件，可以参考：Obsidian使用Components快速搭建可视化图书库_哔哩哔哩_bilibili和 和 Projects 插件结合的场景 · zhaohongxuanobsidian-weread-plugin · Discussion #130 · GitHub References Obsidian - Sharpen your thinking GitHub - zhaohongxuanobsidian-weread-plugin: Obsidian Weread Plugin is a plugin to sync Weread(微信读书) hightlights and annotations into your Obsidian Vault. Snippet so you can use Dataview Cards from Minimal theme in any theme - Share showcase - Obsidian Forum","tags":["obsidian","微信读书"],"categories":["工具效率"]},{"title":"Scala中 implicit 用法","path":"/2024/05/31/scala-implict/","content":"Background最近一段时间接手了几个Spark相关的大数据项目，主要使用Scala来编写代码，做了几个需求，感觉Scala这门语言还挺有意思，Scala以前也学习过，但是是很早了，很多语法点都忘了，在工作中经常编写的代码是Spark Job，使用stream的方式来编写代码，感觉非常的舒服。Spark中经常使用的一个操作是使用$来选择Column，比如下面使用$选择dt这一列， val omnitracking_ios = spark.read.parquet(file_path).filter($dt = one_month_ago_fmt) 起初我并没有在意，起初我还以为$的用法是字符串插值，但是后来发现不是的，这一下子激发了我的好奇心，于是花时间研究了一下，Spark 中的$是 import spark.implicits._ 导入的： SQLImplicits中的 StringToColumn类 implicit class StringToColumn(val sc: StringContext) def $(args: Any*): ColumnName = new ColumnName(sc.s(args: _*)) 分析一下源码，虽然源码只有三行，但是知识点还是比较密集的： 首先，第一行，StringToColumn是一个隐式类，定义了一个隐式类StringToColumn，它接受一个StringContext类型的参数sc。StringContext是Scala中的一个类，用于处理字符串插值(interpolator)（例如，shello $name）。 第二行在隐式类中定义了一个$方法， $(args: Any*): ColumnName，该方法返回一个ColumnName对象。 第三行：new ColumnName(sc.s(args: _*))：使用生成的字符串创建一个新的ColumnName对象。关键点在sc.s(args: _*)方法 ，使用StringContext类中的s方法将args参数插入到StringContext中的字符串模板中。args: _*表示将参数序列展开成单独的参数。 我们知道Scala中的字符串插值使用方法是： val path = s$base_path/dt=$last_date_fmt 这里，我们就可以以字符串插值的方式来使用$了 比如从Dataframe中选择一个Column val columnName = $columnName 这里隐式类的作用是在特定的作用域中自动将某种类型转换为隐式类的实例，从而可以调用隐式类中的方法。在这个例子中，当你在字符串上下文中使用$插值时，Scala会自动将StringContext转换为StringToColumn，从而可以调用$方法。 通过隐式类和字符串插值机制，Spark SQL允许用户方便地将字符串转换为ColumnName对象，从而进一步转换为Column对象。这使得代码在处理列名时更加直观和简洁。具体代码如下 Scala中 implicit 用法Scala中的implicit关键字用于定义隐式转换和隐式参数，可以简化代码和提高可读性。 隐式转换隐式转换用于在需要某种类型但实际提供的类型不匹配时，自动将一种类型转换为另一种类型。可以通过定义隐式函数或隐式类来实现。 隐式函数示例：自动调用 intToString，将 Int 转换为 String implicit def intToString(x: Int): String = x.toStringval s: String = 42 在这个例子中，intToString函数将Int类型转换为String类型。因为implicit关键字的存在，当需要String类型但提供的是Int类型时，编译器会自动应用这个隐式函数。 隐式类示例：implicit class RichInt(val x: Int) def square: Int = x * xval num = 4println(num.square) // 输出 16 在这个例子中，RichInt是一个隐式类，它为Int类型增加了square方法。这样，我们可以直接调用num.square，即使Int类型本身没有square方法。 隐式参数隐式参数是一种可以自动传递给函数或方法的参数。如果一个方法的最后一个参数列表被标记为implicit，那么在调用这个方法时，如果没有提供这些参数，Scala编译器会在作用域内寻找合适的隐式值来填充。 示例：case class User(name: String)def greet(implicit user: User): String = sHello, $user.name!implicit val defaultUser: User = User(John Doe)println(greet) // 输出 Hello, John Doe! 在这个例子中，greet方法需要一个User类型的隐式参数。因为在作用域内定义了一个隐式值defaultUser，所以调用greet时不需要显式地传递参数。 使用场景 增强现有类型：通过隐式类，可以为现有类型添加新的方法，而不需要修改类型本身。 类型转换：隐式函数可以在需要某种类型但提供的类型不匹配时，自动进行类型转换。 依赖注入：隐式参数可以用于依赖注入，使得代码更加简洁和易于测试。 类型类模式：在Scala中，类型类通过隐式参数和隐式转换实现，提供了一种灵活的多态性。 Reference Implicits syntax - Understanding implicit in Scala - Stack Overflow","tags":["scala","spark"],"categories":["源码解析"]},{"title":"RIME 输入法使用体验","path":"/2024/03/20/most-powerful-input-method-rime/","content":"磨刀不误砍柴工，输入法是平时使用频率极高的工具类软件，因此值得花时间去让这个工具变得更加趁手，在 2022 年我学会了双拼输入法（如果你还在使用全拼，我强烈建议学一下双拼，可以参考我之前写的这篇博客：也许你该试试双拼输入法 | Hank’s Blog 我一直用的是 macOS 系统自带的双拼输入法，今年年初看到很多 X 友都强烈推荐 RIME输入法，我决定使用这个开源的输入法，使用至今已经3个多月了，这篇文章就来总结一下我的使用体验。这篇文章只是我的体验，不会详细介绍 RIME 输入法的详细功能，更详细的配置可以查官方文档，希望能对你使用输入法产生一些启发。 为什么是RIME？ RIME是一个高度定制的输入法，意味着它非常的自由。 它是基于 yaml 配置的，没有GUI，因此需要你有一些程序基础和耐心才能配置。 强大的拓展系统，可以使用 lua 实现自定义功能。 体积小巧，无须联网，没有隐私问题。 基于上面这些对于一个程序员来说完全不是问题，而且是优势，因此我选择使用它来作为我的输入法再好不过了。当然，如果你对输入法没有感受到痛点，我建议还是使用成品输入法，现在关闭这篇文章还来得及，至少现在来说，支持双拼的微信输入法已经足够好用了（除去隐私问题）。 基础配置在Mac平台的一个比较受欢迎的实现是 Squirrel 输入法，中文又称鼠须管，别担心配置文件是在各个平台通用的，因此只需要维护一个自己的一套输入法配置就好了，所有平台都可以共享。 强烈建议不要从头开始写一份配置，目前网络上友有很多鼠须管配置文件，我使用的是mint-rime，也成为oh-my-rime，你也可以基于其他的配置文件来二次配置。 薄荷拼音的基本配置可以参考这里：oh-my-rime Input Method | Mint Pinyin，讲的可以说是非常细致了。 安装配置下载安装直接下载配置文件zip包，解压之后放置在 ~/Library/Rime 中，然后在菜单栏点击菜单栏【ㄓ】-【重新部署】即可完成基础配。如果是使用全拼输入法的话这里就可以正常使用了。 这种方式适合大部分用户，方便快捷，后续可以使用云盘来同步配置文件。 软链接安装如果是Git用户，可以fork一份配置，然后git clone到本地的项目文件夹 ，进入仓库目录，将本地目录创建软链接到到 Rime 的配置目录： ln -s $(pwd) ~/Library/Rime ⚠️ 使用这种方式的时候要注意，如果是public repo 的话custom_phrase.txt 中不要放置敏感的信息。 进阶配置安装完成之后一般就能使用了，但是如果要实现一些自定义的功能，需要修改配置，修改配置的方法有两种： 直接修改原始配置： Patch 配置，我建议使用第二种方式，Patch 在不影响原始配置文件的情况下来实现自定义的功能，支持覆盖配置和新增配置，后续在更新作者配置的时候更加方便，如果使用Github的话，只需要写一个Github action就可以定时同步配置了 下面来介绍一下我Patch的一些配置，你可以做一些参考。 Patch 自己的输入方案默认情况下，RIME使用的一般都是拼音输入法，我们可以根据自己的需求修改自己的方案，在 default.yaml 可以配置自己需要的输入方案我自己是双拼用户，所以，在schema list中只保留了小鹤双拼 我这里根据自己的需要，只保留了小鹤双拼的方案，设置方法很简单，新增一个 default.custom.yaml 中把其他的schema都删除掉，只保留double_pinyin_flypy，然后设置候选字一页为 9 个： patch: schema_list: - schema: double_pinyin_flypy # 小鹤双拼 menu: page_size: 9 你可以根据自己的需求保留相应的方案，使用的时候使用 ctrl + ~ 切换方案。 Patch 自定义皮肤首先要理解如何自定义皮肤，下面是鼠须管输入法皮肤每个配置项，你可以自己根据自己的喜好来定制自己的专属皮肤。也可以使用 Squirrel 皮肤设计软件GitHub - LEOYoon-TsawSquirrel-Designer: Squirrel Theme Simulator来设计皮肤，目前我使用的皮肤就是这个皮肤设计软件自带的 flat 主题，我感觉非常漂亮。 新增一个 squirrel.custom.yaml 配置文件用来覆盖默认的主题配置，分别patch 掉 style和preset_color_schemes字段。 patch: style: # 选择皮肤，亮色与暗色主题 color_scheme: flat_light color_scheme_dark: purity_of_form_custom preset_color_schemes: flat_light: name: flat_light font_face: Helvetica font_point: 15.0 candidate_list_layout: linear text_orientation: horizontal inline_preedit: false translucency: true mutual_exclusive: true corner_radius: 15.0 hilited_corner_radius: 13.0 border_height: -5.0 border_width: -5.0 line_spacing: 4.0 spacing: 10.0 alpha: 60.0 shadow_size: 1.0 color_space: display_p3 back_color: 0x1AFFFFFF candidate_text_color: 0xB3000000 comment_text_color: 0x80333333 label_color: 0xBB333333 hilited_candidate_back_color: 0x7DC6C6C6 hilited_candidate_text_color: 0x000000 hilited_comment_text_color: 0xBF333333 hilited_candidate_label_color: 0x000000 preedit_back_color: 0x1A000000 text_color: 0xBF323232 hilited_text_color: 0xBF1A1A1A 然后重新部署就可以生效了。 Patch 双拼 preedit_format默认情况下，输入双拼音节，comment框中会自动转换为全拼，但是按回车之后上屏的依然还是双拼，我感觉还是不习惯，可以把这个配置改掉，我在Github上找到了解决的方案：双拼模式下怎么能不让输入框的拼音自动展开成全拼？ · Issue #261 · rimesquirrel · GitHub 在 double_pinyin_flypy.schema.yaml 文件里，找到 translator配置项，把 preedit_format 设置为 []，这样双拼就不会自动展开成全拼了。 最终结果如下： macOS更新托盘图标Release Squirrel System Tray Icon for MacOS VenturaSonoma · lewangdevrime-ice · GitHub默认的托盘图标很窄，可以参考这个连接：修改为系统输入法一样的宽图标，强迫症狂喜。 配置同步如果在一个设备上修改了配置，如何在其他的设备上还能够正常同步？ 同步至 iCloud1、配置文件里打开 installation.yaml，将 id 改为自己设备的名称，比如家里的Macbook Pro之类的。2、复制下面路径代码粘贴进去，将 admin 替换为 Mac 管理员名称（代码里 RimeSync 是同步后文件夹名称，支持自定义）。 sync_dir: /Users/admin/Library/Mobile Documents/com~apple~CloudDocs/RimeSync 更多同步的选项可以看文档：多设备同步 | oh-my-rime输入法 Git 同步上面的「软链接安装」章节已经提到了，如果使用Git管理的话，最好通过软链接的方式安装，就和正常管理一个项目一样简单。 手机端iPhone上面可以使用【仓输入法】GitHub - imfuxiaoHamster: librime for iOS App，配置文件和电脑端的位置文件一样，只需要把配置文件复制一份到iCloud的仓输入法文件夹就可以了，然后部署就可以了。 参考资料 GitHub - Mintimateoh-my-rime: The Simple Config Template Of Rime By Mintimate. QQ Chat-Group: 703260572 Rime 配置：雾凇拼音 - Dvel’s Blog GitHub - ssnhdrime: Rime Squirrel 鼠须管配置文件（朙月拼音、小鹤双拼、自然码双拼） GitHub - iDvelrime-ice: Rime 配置：雾凇拼音 | 长期维护的简体词库 GitHub - imfuxiaoHamster: librime for iOS App","tags":["双拼输入法","Rime","鼠须管"],"categories":["工具效率"]},{"title":"Raft算法笔记","path":"/2024/02/22/raft-notes/","content":"最近看了DDIA，对于分布式共识算法很感兴趣，可以说共识算法是分布式的基石，而 Raft 算法又是共识算法中最简单的一个，Raft算法是一个专门用于管理日志复制的共识算法。共识（consensus）是大家关心的某件事情（比如选举、分布式锁、全局ID、数据复制等等）达成一致的过程及其算法。 Raft算法诞生与2013年，论文名字叫作《In Search of an Understandable Consensus Algorithm》，寻找一个更加容易理解的共识算法，从名字就能看出来，作者对 Paxos 的绝望。 复制状态机在分布式系统中，为了提升高可用，一般使用基于副本的容错模型：复制状态机，复制状态机使用多个成员组成集群，成员之间数据完全一致（也称为副本），它可以保证即使在小部分（≤ (N-1)2）节点故障的情况下，系统仍然能正常对外提供服务。 复制状态机一般和共识算法一起才能发挥作用，下面是一个典型的复制状态机架构。 从图中我们可以清晰的看到： 第一步：客户端发起数据写入请求。 第二步：共识模块负责将请求写入Log，以及将Log 复制到其他的Server。 第三步：将Log应用到状态机，由于每一个Server的Log中存储的命令序列是完全相同的，因此可以保证所有Server产生相同的结果。 第四步：状态机把结果返回给客户端。 Raft算法的核心Raft算法通过选举机制确保每个任期（Term）中只有一个领导者（Leader），这个Strong Leader 负责处理客户端的请求和日志的复制。这样可以保证系统的高效性和一致性，避免了多个领导者引起的冲突，从而实现共识。 只有Leader才能接受来自Client的日志请求，Leader收到日志请求之后将日志写入到磁盘（无须咨询其他Server），然后将日志复制到其他Follower，这个过程是单向的。使用LeaderFollower模型可以大大简化日志复制的管理。 Raft算法的核心问题这三个核心问题是： Leader选举 （Leader Election） 日志复制（Log replication） 确定性（Safety） 最后一项确定性其实是前两个问题的约束条件，Raft算法在同一时刻有如下保证： Leader Append-Only：Leader日志单调递增，Leader永远不会覆盖或者删除自己日志里面的内容，永远只会新增内容 Log Matching：日志匹配，如果两个server的日志包含了相同的Index和Term，那么在该index之前的所有条目都是相同的。 Leader Completeness：Leader完整性，如果日志条目被提交到给定任期，那么该日志会被复制到更高任期的Leader上。 State Machine Safety：状态机安全，如果Server已经确定给定Index出的日志条目已经应用到了状态机，那么其他Server一定不会知道该Index处应用不同的日志条目。 如何选出一个Leader？Raft节点总共有三种状态： Leader ：集群中只可能有一个Leader，Leader的作用是把Log复制到其他节点，周期性的向Follower发送心跳，维持统治。 Follower：跟随者，只能被动接受日志，Follower超时之后自动变为Candidate开始竞选Leader。 Candidate：竞选者，选举时间超时之后，Follower变为Candidate 其中Leader和Follower是持久状态，Candidate是一个中间状态，在选举时间超时之后Follower自动变为Candidate开始竞选Leader。 Raft 算法中，节点之间采用 RPC 进行通信，下面两种 RPC 是 Raft 基础功能的必要实现： RequestVote RPC：请求投票 RPC，候选人在选举期间发起，用于通知其他节点投票 AppendEntries RPC：日志复制 RPC，由领导者发起，用于复制日志和提供心跳消息。 另外Raft中还有另外一个比较重要的概念：term 任期，每个term都由选举产生，每个Term都是一个单调递增的编号，每一轮选举都是一个Term周期，在一个Term中只能产生一个Leader ，每个node都存储了当前term的编号。 一个term一般包含两个阶段，选举阶段和统治阶段，当然如果没有选举成功，比如在集群扩容时产生的平票问题，则只有选举阶段。在上面的图中，term1开始一次新选举，选举成功之后开始正常统治，term2和term1类似，term3则是选举失败，term4正常选举成功。term在Raft中起到了逻辑时钟的作用，它可以保障Raft在任意时刻只有一个Leader，特别是在集群成员变更的时候，比如上面的term3阶段，这个阶段没有Leader，集群不能对外界提供服务，由于各个节点设置的随机超时时间不一样，最先超时的Follower节点首先变为Candidate开始竞选Leader，竞选成功之后就是后面的term4阶段。 选举流程Raft使用心跳机制来出发选举，Raft选举过程节点状态迁移图如下： 初始状态下所有节点都是Follower， 随机设定的选举时间超时之后，Follower变为Candidate，Candidate将自己的Term+1开始竞选Leader，向所有节点发送投票请求（RequestVote RPC），投票会有三种结果： 选举成功：如果Candidate获得大部分选票（$N2+1$），那么将从Candidate升级为Leader 选举失败：有两种情况会导致选举失败，1. 选举过程中发现其他Leader的心跳； 2. 投票请求响应的Term大于当前节点的Term则选举时候不到 选举超时：投票请求知道固定时间内没有收到其他节点的响应，或者收到了响应的节点数量没有大于$N2+1$ ,那么选举就会超时，进入下一轮选举。 Leader在发现其他Server有更高的任期编号，则自动退回到Follower。 这个选举流程还是挺简单的，但是我们仍然会有疑问，节点的投票条件是什么？其实就一条：具备完备的 committed log（被多数节点接受并且持久化的的日志） 数据即可，有两种情况： 如果收到的请求投票消息的Term小于自己当前的Term，则拒绝投票。 如果收到的请求投票消息的Term大于自己当前的Term，则更新自己的Term为收到的Term，节点状态转变为Follower。 如果自己还没有投票或者已经投票给了当前的Candidate，且收到的请求投票消息的Last Log Index和Term都大于等于自己的Last Log Index和Term，则投赞成票。 如果收到的请求投票消息的Last Log Index和Term都小于自己的Last Log Index和Term，则拒绝投票。 当出现多个Candidate同时宣布自己是Leader时，由于选举过程中存在随机化的因素，可能会出现选平票的情况。在这种情况下，Raft算法规定如果两个Candidate的Term相同，那么选举将以最先收到选票的Candidate为准。其它候选者在接收到更高Term的选票后会立即转变为Follower，参与下一轮的选举。这样可以确保最终只有一个领导者被选举出来。 References In Search of an Understandable Consensus Algorithm 云原生 etcd 系列 ｜ 最难 paxos 最易 raft","tags":["raft","共识算法","分布式"],"categories":["技术随笔"]},{"title":"生意再小，也要有自己的事业","path":"/2024/01/06/start-your-business/","content":"读完了《重来：更为简单有效的商业思维》这本小册子，最大的感受是，「生意再小也要有自己的事业」，且越早开始越好。 事业的可以从自己的「痒处」开始，也就是打造自己需要的产品，不一定是颠覆的产品，可以在现有的产品上进行微创新，但是至少一定解决了人的一些痛点或者痒点的产品。 一定要抓住这个稍纵即逝的灵感，然后以非常强的行动力去执行，比如放弃出去玩，花上一个周末去打造一个原型产品，然后不断发布产品，投放社区和市场，获取反馈，不断迭代，螺旋型上升，空有灵感，一文不值。 2022年做的微信读书Obsidian插件就是这种感觉，自己在使用的过程需要自己手动copy笔记到Obsidian，感觉很麻烦，于是产生了一个简单的想法：做个插件来同步笔记，给自己偷懒，接下来就是学习Typescript，然后废寝忘食的开始写代码，我记得有一天早上4点起床就开始抱着电脑开始写代码了，到早上8点多发布了插件的第一个版本，整个过程非常投入，完全不感觉到累，只感受到了创造的快乐。 📌 斯坦利·库布里克（Stanley Kubrick）曾经这样激励电影制片人：“找个摄像机和一些胶片吧，随便拍个什么样的片子出来都成。”库布里克明白，当你刚开始一项工作时，你必须开始创造自己的东西。最重要的事情就是起而行之。所以，拿起摄像机，灌张唱片，开始拍摄吧 一个绝妙点子还不够，更重要的是超强的行动力，有了行动才有反馈，并产生新点子，然后更好的促使自己行动，就像是一个滚雪球的过程。因此，如果有主意和想法就笃定一点，不要到处询问意见。这里我要分享和菜头的一篇文章：槽边往事: 在完成前保持沉默。 乔布斯曾说过，当我们知道了我们所做的世界上的事物都是由哪些并不比我们聪明或者优秀的人打造出来的，我们就可以着手去改变，我们可以创造给这个世界带来美好的事物。一旦我们理解了这个道理，我们就会变得不一样。 每一个人都可以有自己的灵感创意，跟随自己的好奇心和兴趣创造出一些有趣的产品，开启自己的事业，这个事业可以不大，只要满足一定用户群体然后持续盈利即可。大有大的难处，小有小的优点，「小」意味着改正错误的成本很小，而且没有在聚光灯之下意味着我们可以灵活调整策略，解决问题，测试创意。因此公司不一定要很大，只有能持续盈利即可。 当然，这个过程会很难，不要轻易放弃自己的主业，可以先在业余时间探索一下自己的兴趣，创作点属于自己的产品，这样可以获得更多的满足感，另一方面还有可能改善经济状况，同时也为未来的职业发展打下基础。 人这一辈子很短，做有趣的事情，去创造吧，在这个宇宙中留下一些足迹吧。 References 重来：更为简单有效的商业思维","tags":["读书笔记","思考","商业"],"categories":["散文随笔"]},{"title":"我的Obsidian笔记工作流","path":"/2024/01/04/obsidian-workflow/","content":"个人认为笔记的本质是： 让思考继续发生。记笔记不是目的，是为了更好的服务于思考，但是大脑不善于存储和检索，因此才要记笔记，本质是上是给大脑减压，记笔记的各种方法也都是为了让大脑更好的思考。大脑本能是躲避思考的，所以要尽可能简化记笔记的流程，形成习惯。 由于我对卡片笔记的理解还不够深刻，也还在探索中，因此这篇文章旨在分享我的一些心得和体会，每个人的习惯不一样，因此笔记方法因人而已，别人的方法不一定是适合自己的，每个人都要探索形成自己的笔记方法。 我的笔记原则 没有最好的笔记软件，没有工具可以解决所有问题。 没有最好的笔记方法，不迷信任何人的方法，探索自己记录笔记的方法。 方法是可以被改进的，工具是可以被改进的。 记录笔记时多记录元数据，多建立链接和标签，尽量和其他笔记发生链接，尽量不建立Orphan笔记。 笔记要定期回顾，把过期的draft笔记清理掉。 为什么是Obsidian？ Obsidian很简单，开箱即用，虽然没有开源，但是个人用户免费。 Obsidian基于纯文本的markdown文件，不怕跑路，就算跑路了，markdown转移到其他软件中成本也小。 Obsidian不是基于网络的，离线同步的模式可以更好的适应不同的环境。 Obsidian够开放，插件市场很丰富，还可以自己编写插件，定制属于自己的功能。 Obsidian在支持双链的同时还保持了和传统笔记一样的文件夹层级，对于普通用户更加友好，大纲型笔记（如RoamResearch和logseq为代表）可能不太适合我（并不是说大纲型笔记不好）。 当然，这只是当下的选择而已，以后可能还会随着时间变化，不必执着于工具，掌握了方法，使用Apple Notes一样可以把笔记整理的很好，笔记工具有很多，选择一个自己趁手的工具就好了，在不断的写作中不断迭代自己的方法即可。 Obsidian 工作流目前我的卡片笔记工作流，是基于Obsidian的Daily Notes，也称为Journal构建的。对我来说，记log最大的优点在于记录的时候不用思考这个笔记应该放在哪里，不要小瞧这个小问题，这一步很消耗脑力，大脑为了躲避思考，可能就会排斥做笔记，做笔记的难度就提升了。 Journal型笔记最大的优点就在于记录的时候压力很小，如果大脑中有一个idea，直接capture住这个idea加入到log中就行了，在这个过程中尽可能多的为这个idea添加元数据，比如标签或者双链，这就需要自己在建立笔记的时候尽量多使用标签或者双链，这样，我们在以后提取的时候就能够尽可能多的提取到有用的信息，让自己大脑可以方便的Switch Context，有了这些特征信息，大脑就能更快、更准确的把这些信息提取出来，让思考继续发生。有了这些idea，一些伟大的产品就可以诞生，可能是一个side project，甚至是一个company。 下面是我在Obsidian中记录笔记的workflow： 捕获 Capture捕获（Capture）是记录脑瓜子里一闪而过的一些想法，这里就分成了两类： 一类是自己想到的，比如散步的时候，一闪而过的灵感。 一类是在阅读，这里的阅读很宽泛，包括读书、rss工具、公众号、社交媒体或者看视频和听博客时候自己想到的一些想法。这里Journal其实充当了灵感笔记（Fleeting Note ）的作用。 捕获想法（灵感）Capture灵感和想法需要即时性，因为灵感不常有，是个非常稀缺的东西，一般出现在reflection中，比如正念的过程，或者刚睡醒的早上，或者运动的过程中。大部分时候就是一瞬间的事情，理论上可以用任何工具，手机上自带的Notes 或者Todolist都是可以的，这一步主要是帮助自己快速捕捉到大脑的想法，因为这些灵感稍纵即逝。 在移动端，我自己使用Obsidian的Quickadd插件，下拉就可以在Journal记录想法，手机上不适合大段的编辑文字，但是非常适合捕捉灵感。比如在地铁上，或者走路的时候，突然迸发的灵感，就可以用手机随时记录。 在电脑端，我会直接在Obsidian的Journal中直接记录。平时我的电脑的一个屏幕里是专门放置的Obsidian，如果是简单的想法，我会直接在log中记录想法，然后打上标签，如果未来以后有什么计划，比如要写一个帖子或者blog等，会建立一个双向链接的Placeholder，然后打上标签，比如 #tasks/write等，这些标签会在一个主页里通过dataview和Tasks插件进行搜索展示： not donesort by due descdescription includes tasks/write 如果是要发一个X帖子这样的简单的Task，我就直接在Journal中新建一个bullet list 记录，然后随手打一个标签，然后使用Dataview汇总： list L.textfrom Journalflatten file.lists as Lwhere contains(L.tags, #backlog) and contains(L.tags, #twitter) 捕获阅读信息更多时候，我们是在阅读的时候产生的灵感，我们被我们的好奇心和兴趣所牵引，去阅读、观看、收听一些我们感兴趣的内容，我常用的工具如下： 阅读工具： 微信读书，我使用自己写的Obsidian Weread Plugin同步读书笔记到Obsidian中。 NetNewsWire：Apple平台最佳的开源rss阅读器，订阅的优秀的blog和newsletter来收集信息。 Safari阅读列表：一些gitbook会收藏进safari的阅读列表中，在碎片时间进行阅读。 社交媒体： X（Twitter）：关注海内外一些优秀的开发者分享的一些有趣的内容。 Telegram：关注了一些开发者的频道，会分享一些业界比较关注的资讯。 IT之家：已经使用十年了，基本上每天都会刷一会儿 媒体工具： Bilibili：看一些自己感兴趣的视频， 小宇宙：在跑步或者地铁上的时候会听一些自己订阅的播客。 如果是读到的感兴趣的内容，就需要建立一个简单的卡片笔记，把援引的链接记录下来，然后把文章的内容和自己的想法下来，在这一步就是类似于制作卡片的过程，不需要过多的引用原文，要尽可能多的思考，然后用自己的话写出来，然后尽可能多的添加元数据信息，比如各种标签，以及关联上各种已经存在的链接，让这个卡片渐渐丰满起来，这个卡片是为了以后整理加工使用的， 这一步千万不要着急，一天能有个三四个卡片就够了，每个卡片代表了自己思考的过程。 整理和提取整理是把这些零散的信息，重新加工成自己需要的笔记，在捕获这一步，我们已经尽可能多的把信息保存下来了。比如，各种个样的标签，我这里使用Obsidian的dataview插件和tasks插件，把需要进一步整理的任务列出来，仅此，检索这些需要进一步处理的任务变得简单。 此外，由于我们此前已经在文献笔记卡片上记录了足够多的信息，因此，就算过了几天，大脑也能快速切换到当前的上下文，快速进入记笔记的状态，不用担心提笔忘字。比如，我们要根据卡片内容，写一个twitter帖子，或者写一篇blog，我们可以根据现在卡片上的内容以及关联的各种信息和其他卡片，进一步整理加工，形成一个永久笔记（Permanent Notes）。 这一步可能比较耗时，比如一篇blog写上大半天都是有可能的。 输出和回顾 你对某件事情越感兴趣，就会阅读得越多，思考得越多，进而收集的笔记越多，最终越有可能从中提出问题和想法。它可能正是你一开始就感兴趣的东西，但更有可能是你的兴趣已经发生了变化，这就是洞见的作用。 –《卡片笔记写作法》 最终，我们写出了一个有价值的内容，可以存放到一个单独的文件夹保存，等待以后检索和提取，也可以分享到社交平台上接受检验，我们的目的不在于分享本身，而是公开学习的过程可以促使我们更好的思考和学习，而笔记只是学习的成果。当然笔记并不是要在文件夹中吃灰的，而是需要经常回顾的，在回顾的过程中，可能会产生新的灵感，每一次回顾，我们都可以获取新的收获。我一般使用Random的插件来随机访问自己写的笔记，然后反思之后产生新的想法。 总结简述一下我一天的记录流程： 每天早上起床洗漱完成之后，打开Journal，看下Dashboard，回顾一下先前的任务和没有做完的事情，然和写下这一天的主要目标🎯，比如完成某个任务，学习一个主题等。 看一会儿RSS和X，如果看到感兴趣的主题，会capture成为一个卡片，然后链接到Journal中，然后给卡片打上各种标签，如果当时有时间就思考，然后构建一个卡片，如果没有时间，那就打上标记TBD，等待后续进一步处理，Dashboard中会记录各种TBD的卡片的记录。 地铁上使用微信读书标记以及写想法，然后使用插件同步笔记到Obsidian中。 工作中遇到的一些问题，或者想法也会及时capture到journal中。 有自己的时间的时候开始整理自己的卡片，根据卡片整理成永久笔记。分享自己的研究学习成果到互联网。 删除没有用的draft note 这个流程的核心是有一个地方可以存放自己的闪念笔记（Fleeting Notes，存放自己的灵感和草稿），然后将它们源源不断地转换为永久笔记，永久笔记就是自己学习的成果，可以将它们分享到网络上，或者存放在自己单独的文件夹中。在持续不断的[[公开学习]]中，我们不断将学到的东西转换为其他人能够看的懂的内容，这种[[费曼学习法]]可以极大的提高自己的学习效率，在一个小小的领域里面不断研究，进步是非常迅速的。 每个人都有自己的记录笔记的方式方法，每个人记录笔记的方法不一定适合他人，最多只能给启发。 References 《卡片笔记写作法：如何实现从阅读到写作》 我的 Obsidian 使用经验 程序员的喵","tags":["obsidian","卡片笔记","工具效率"],"categories":["工具效率"]},{"title":"再见，我的2023","path":"/2023/12/27/2023-review/","content":"首先我要感谢这一年的自己，对自己说一声辛苦了。虽然这一年过得十分艰难，很多事情都发展不顺利，但是还是要对自己说一声辛苦了，最起码坚持到了最后，成功又度过了一年。 一些收获从2023年底到今年年初，主要是和同学一起翻译《Python for MATLAB Development》，人民邮电出版社引进的一本比较小众的技术书，出版社审核的时间有点长，不出意外的话，应该2024年第一季度会出版，这是我正式翻译的第一本书，难度确实不小，虽然现在各类翻译软件层出不穷，但是想要准确的翻译还是有不小的挑战的，里面的专业词汇有点多，长句也很多，花了将近半年才翻译完。 开源方面，今年没挖大坑，主要就是围绕着跑步和骑行构建了一些自己的工具。首先是使用@ben-29 的workout page,把自己的骑行数据展示到我的运动主页了，确实很很酷。 围绕着跑步也贡献了一部分代码，一个比较大的项目是：上马自动签到工具，为了给自己偷懒，自己分析上马官网前端代码，使用Nodejs写了一个上马签到的程序，由于之前都是Java技术栈，没怎么使用过Nodejs，边查Javascript语言文档边写代码，最终花了一个晚上和一个上午把工具给做出来了。去年做的微信读书Obsidian插件也是，主意都是一念之间想起来的，Typescript语言也是边学边写，那时候还没有ChatGPT，结果三天就把原型代码写出来了，还是挺佩服我自己的。 此外，还给Running Page贡献了几个feature，比如为Keep导出的GPX文件增加心率数据，还有为同步到Garmin的运动记录中增加Device Info等。这些都是我在实际中遇到的问题，我只不过是把这些问题解决了而已，同时这些Feature也能帮助别人，何乐而不为呢？ 今年开始花费了不少在Twitter（X）上公开表达，主要是把自己的一些想法和学到的东西分享出来，主要是下半年开始玩，粉丝涨到了3K多，不是特别在意粉丝的多少，这些数据都是次要的，发推主要是为了分享自己学习的一些结果，公开学习有助于自己表达。 生活日常女儿今年已经两岁多了，这个时间段是最调皮捣蛋的时候，而且精力十分旺盛，作息时间已经和大人基本一致了，需要花费很多精力去陪她，回想刚过年的时候，女儿刚学会走路，趔趔趄趄的往前扑，仿佛看到了小时候的自己。和小朋友在一起的时候虽然有的时候各种淘气捣蛋惹人生气，但是大部分很开心，因为一切都是向上的，在每一天平淡的日子里，她们在一点点的成长。 生活就是日常点滴的汇聚，大多数时候都感觉生活很幸福的，自从去年年底买了车之后，今年去的地方也多了，去了上海海洋馆，野生动物园，金山城市沙滩，东海等，自驾回老家洛阳了两趟，和老婆一起去了老君山，鸡冠洞等，除此之外，去周边的儿童乐园玩什么的，开车也是很方便的，不得不说，车在一定程度上提高了生活的幸福感。 就像一个平静的湖面突然落入一颗石子一样，总是会出现一些意外来打破生活的平静，五一刚从老家回上海没几天，大哥就中风了，情况很严重，做了脑部手术，老妈需要回家一段时间照顾，我也请假在家了一段时间来照顾女儿，突然有一瞬间，我感觉这个世界太残酷了，健康是一个人的根本，但是大部分健康的人是体会不到的，你正在经历的日常可能就是他人遥不可及的梦。 八月份的时候，女儿在小区里走路的时候，被一个4岁的小男孩骑车撞了一下，我赶紧带她去儿科医院缝了针，这是当爸爸的最难受的一次，虽然伤口很小，但是女儿哭的特别厉害，这时候恨不得自己替她承受这一份苦难，然而并不能，这一刻，我又一次体会到了父母的艰辛。而事情还没结束，由于当时对方父母不在场，监控又在死角，还好当时旁边有好心人说了这个小男孩家里的门牌号，最终又是一场心累的沟通，经过居委的多次调节，对方答应承担医药费了。好在小孩子的伤口都恢复的比较快，一周缝线就脱落了，但是还是有一些伤疤，一直在用去伤疤的药，现在伤疤越来越淡了，期待伤疤赶快消失。 细数下来，今年发生的事情几乎都是不怎么好的事情，可能大脑对于不好的事情总是记的特别牢固，但是对于开心快乐的时刻忘的比较快，经常在翻阅照片的时候才会发现大部分时候记录的都是快乐的时光，可能快乐的时间过得太快导致记忆出现偏差了吧。 新玩意儿年初购买了 Macbook Pro 14 2021 ，之前的Macbook Pro 2017屏幕出现了舞台光，非常影响使用，这个应该算是通病，但是苹果没有维修计划，只能便宜卖了，刚好2021款的降价幅度比较大，不到9700就能到手了，于是果断下单了，体验下来确实要比英特尔芯片的Macbook要强大不少，出门基本上没带过充电线。 Giant Revolt F1 主要用于上下班通勤，单程38km骑了好几个月，最后胖了好几斤，骑车的确不能减肥，想要减肥而买车还是需要三思。 由于时光相册关停，相册备份成了一个问题，刚好双十一入手了 Green DX4600 NAS，买成品NAS主要是考虑到折腾的少，主要用于照片备份以及搭建影音库，没有必要自己折腾，刚好把之前的盛夏的三块2.5寸硬盘都利用上了。 终于把之前的眼镜淘汰了，配了蔡司的眼镜，相比较之前的旧眼镜，感觉蔡司的镜片透光度提升了很多，眼镜店里测了下旧眼镜，发现透光度只有86%了，我也不知道这两年咋过的。。总之，这些天天使用的工具，一定要选好的，能提高了不少幸福度。 另外，今年还花了128买了微信读书年卡会员，总体感觉还是挺值的，一年之内读了不少书，还攒了不好书币，应该算是超值了，不过明年应该不会再续了，先把手上攒的书读完再说。 工作相关这一年的中国经济的基调是“下降”，公司作为一家外企发展并不太好，呆在现在的公司已经3年了，能感受到今年要做的需求再慢慢减少，就目前来说，公司的现金流紧张，现在正在经历裁员和私有化，最最操蛋的是，已经Vest的股票也要作废，令人发指，然而Repackage却符合该国的法律，真是滑稽啊。 基金投资躺平了一年之后，亏损日益扩大，最多的一只基金已经亏损了近50%，好在年中的时候看李笑来的《让时间陪你慢慢变富》的时候，学到了分散投资，把一部分资金投入了美股的ETF基金，减少了相当一部分的损失，不过整体上对未来在股市上的预期降低了很多。 有那么几个瞬间，我仿佛想明白了工作的意义，工作只是手段，不是目的，如果工作是朝着自己的长期目标前进的时候，那么你一定做着自己热爱的事情，那就勇敢前行吧，如果不是，那么就要重新想象自己未来的长期目标和工作的关系了，重新寻找一个能唤起自己激情的地方吧，多寻找，多尝试，我想总会找到的。 读书粗略的想好像这一年没怎么读书，但是看了微信读书的报告，还是吓了一跳，发现这一年居然读了十几本书，大部分时候都是在地铁上读，因为平时自己的时间真的太少了，有的时候还挺喜欢在地铁上读书的，感觉比在家里沙发上读书更容易专注，仿佛地铁嘈杂的声音是白噪声似的，地铁上我一般使用Boox Poker3电纸书阅读，对眼睛友好，用它读了不少历史方面的书，特别是张宏杰老师的书，太上瘾了，下面简单列一下今年看的书。 1月《悉达多》 2月《纳瓦尔宝典》 3月《汴京之围：北宋末年的外交、战争和人》 4月《Kafka权威指南》《Designing Data-Intensive Applications》（Ongoing） 5月《道德经》 6月《楚汉双雄》、《智慧和魔咒》 7月《法治的细节》、《饥饿的盛世》、《千年悖论》 8月《大明王朝的七张面孔》 9月《让时间陪你慢慢变富》 10月《中国历代政治得失》 11月《我与地坛》、《宝贵的人生建议》 12月《定位》、《长安的荔枝》、《挑战不可能》（Ongoing） 这里面的书除了DDIA都看完了，DDIA事由于中英对照着看，进度有点慢，到现在还有几个章节没看完，不过收获确实很大，对数据系统有了更加深刻的认知。 骑行和跑步上半年的主旋律是骑行，3月份的时候买了一辆平把公路车Giant Revolt F1，一直拿来用于上下班，今年骑了好几次淀山湖，还有太浦河，前灯古镇，当然冬天的时候还骑了苏州太湖的东山（本来打算骑东西山的，风太吹了，放弃）。 骑行的时间长了，跑步自然就少了，今年总共跑了六百多公里，和往年比应该是最少一年了，不过今年依然跑了两个马拉松，一个是苏州半程马拉松，还有一个就是上马，很明显都没PB，但是都跑到了我的理想区间，半马1个小时44分，全马3个小时50分钟，主要就是10月份练了一个月，能达到这样的成绩我已经很满意了，明年应该会继续报名上马。 运动是内啡肽分泌的一个重要途径，内啡肽被称为脑内吗啡，能让人感受到幸福，所以我每周都会进行几次运动，冬天的话频次会相对减少一些，但是好的天气一定会出去运动。 思考和展望2023年，过得不算太好， 但是仍然有失有的，我仍然感谢生活，至少我都挺过来了，2024年，我应该会更多的时间花费在家庭上，陪伴女儿成长，多出去玩一玩。在技术上深化一下自己的技术栈，拓展自己的职业边界，更多的时间来公开学习，多写作，多记录自己的想法，写作是澄清自己思想的方法，把遇到的各种问题和解决方法，多输出一些有价值的内容，探索自己的好奇心和Passion，寻找更多可能性，争取更多的闲暇时间来build something wonderful，可以是一个开源小工具，可以是写一本书，可以是任何东西，总之，可以让世界变得更加美好就够了。 我一直认为人生重在体验，体验需要Dive into，所以有的时候需要大胆一些，勇敢一些，尝试一些未曾经体验过的事物，探索内心深处的热爱，去从未到达的地方，去感受这个世界的五彩斑斓，人生是旷野，方向不止一个，多花一点思考自己前行的目标，保持内心平和，身体健康。·","tags":["总结"],"categories":["年终总结"]},{"title":"使用Templater在Obsidian中实现每日诗词","path":"/2023/12/20/obsidian-support-daily-poem/","content":"一直使用Templater的Quote功能，使用方法也很简单，直接使用% tp.web.daily_quote() % ，但是默认调用的接口是：https://api.quotable.io, 返回的英文的名言，如果想要中文的名言或者每日诗词等就没法做到。 好在Templater的作者还留了一个口子：用户脚本，用户可以自己按照CommomJS的规范来编写自己的脚本，文档参考这里：Templater User function，这里需要注意的是：不支持第三方node module！！ 创建脚本因此我们只需要调用一个今日诗词的接口就行了，这里选择了今日诗词的接口，接下来就是请求数据然后解析数据了。然后由于obsidian的限制，我们不能直接引用第三方的node module，比如node-fetch，好在Templater暴露了obsidian自身的接口，接口都在tp.obsidian中，因此，我们可以利用Obsidian自身的request方法来调用古诗词的api返回我们自己想要的内容，下面是示例代码： async function daily_poem(tp) const response = await tp.obsidian.request(https://v1.jinrishici.com/all/); const content,origin,author = JSON.parse(response) ; return `[!quote] $content cite style=text-align: right; display: block; — $author·《$origin》/cite` module.exports = daily_poem; 代码中对cite的位置做了调整，默认是向左对齐的，我改成了向右对齐，如果不喜欢的，可以手动修改。 使用脚本保存脚本复制上面的脚本代码保存为一个js文件，这里命名为daily_poem.js，并将脚本存放在Vault中的一个文件夹中，笔者设置的是：Assets/Script，你可以根据自己的实际需求设定，这个文件夹在下面使用的使用要用。 设定脚本所在的文件夹 在Daily Notes模板中使用在自己的Daily Notes的模板中直接使用 % tp.user.daily_poem(tp) %即可使用，这里必须要传tp进去，因为tp是Templater的全局变量，如果不手动传入，就不能调用obsidian的request方法。下面是我在Daily Notes中使用的效果： 当然，除了调用现成的API处理json数据之外，如果访问的页面是原始HTML，还可以处理DOM元素，使用选择器来获取我们想要的数据，可玩性更高了。 References 使用脚本自定义用户函数 Obsidian内置函数","tags":["obsidian","古诗词"],"categories":["工具效率"]},{"title":"Kafka为什么这么快？","path":"/2023/12/19/why-kafka-so-fast/","content":"Kafka为什么这么快（吞吐性高）？kafka作为一个处理实时数据和日志的管道，每秒可以处理几十万条消息，那么为什么Kafka的吞吐量这么高呢？ 我们先来看一下Kafka的文件存储系统： 分区机制Kafka中一个主题有多个Partition（分区），一个Topic可以横跨多个Broker。在生产消息时，因此在向Topic发送消息的时候将消息并发地写入到多个broker ，broker的数量可以横向扩展。 在消费消息时，引入了消费者群组（Consumer Group）的概念，一个分区只能被一个消费者群组中的的一个消费者消息，但是可以被其他群组的消费者消费，可以在一个消费组里起多个消费者，每个消费者消费一个分区，这样就提高了消费者的性能。需要注意的是，消费组里的消费者个数如果多于分区数的话，那些多出来的消费者就会处于空闲状态，所以一个消费组里的消费者个数跟分区数相等就好了。 分区的设计使得Kafka消息的读写性能可以突破单台broker的IO性能瓶颈，可以在创建主题的时候指定分区数，也可以在主题创建完成之后去修改分区数，通过增加分区数可以实现水平扩展，但是要注意，分区数也不是越多越好，一般达到某一个阈值之后，再增加分区数性能反而会下降，具体阈值需要对Kafka集群进行压测才能确定。 日志分段存储为了防止日志（Log）过大，Kafka引入了日志分段（LogSegment）的概念，将日志切分成多个日志分段。在磁盘上，日志是一个目录，每个日志分段对应于日志目录下的日志文件、偏移量索引文件、时间戳索引文件（可能还有其他文件）。向日志中追加消息是顺序写入的，只有最后一个日志分段才能执行写入操作，之前所有的日志分段都不能写入数据。 为了便于检索，每个日志分段都有两个索引文件：偏移量索引文件和时间戳索引文件。每个日志分段都有一个基准偏移量baseOffset，用来表示当前日志分段中第一条消息的offset。偏移量索引文件和时间戳索引文件是以稀疏索引的方式构造的，偏移量索引文件中的偏移量和时间戳索引文件中的时间戳都是严格单调递增的。查询指定偏移量（或时间戳）时，使用二分查找快速定位到偏移量（或时间戳）的位置。可见Kafka中对消息的查找速度还是非常快的。 操作系统页缓存页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘IO的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问。 Kafka中大量使用了页缓存，消息都是先被写入页缓存，再由操作系统负责具体的刷盘任务（Kafka中也提供了同步刷盘和异步刷盘的功能） Kafka并不太依赖JVM内存大小，而是主要利用Page Cache，如果使用应用层缓存（JVM堆内存），会增加GC负担，增加停顿时间和延迟，创建对象的开销也会比较高。 读取操作可以直接在Page Cache上进行，如果消费和生产速度相当，甚至不需要通过物理磁盘直接交换数据，这是Kafka高吞吐量的一个重要原因。 这么做还有一个优势，如果Kafka重启，JVM内的Cache会失效，Page Cache依然可用。 磁盘顺序访问Kafka的每条消息都是append的，不会从中间写入和删除消息，保证了磁盘的顺序访问，所以不管文件多大，写入总是O(1)的时间复杂度。减少频繁的小IO操作，Kafka的策略是把消息集合在一起，批量发送，尽可能减少对磁盘的访问。 批量操作写入的时候放到RecordAccumulator进行聚合，批量压缩，还有批量刷盘等… 异步操作异步操作可以在调用send方法后立即返回，等待buffer满了之后交给poll线程，发送消息、接收消息、复制数据也都是通过NetworkClient封装的poll的方式。 零拷贝 Kafka 使用零复制技术向客户端发送消息——也就是说，Kafka 直接把消 息从文件（或者更确切地说是 Linux 文件系统缓存）里发送到网络通道，而不需要经过任 何中间缓冲区。这是 Kafka 与其他大部分数据库系统不一样的地方，其他数据库在将数据 发送给客户端之前会先把它们保存在本地缓存里。这项技术避免了字节复制，也不需要管理内存缓冲区，从而获得更好的性能。 我们以将磁盘文件通过网络发送为例。传统模式下，一般使用如下伪代码所示的方法先将文件数据读入内存，然后通过Socket将内存中的数据发送出去。 伪代码如下： buffer = File.readSocket.send(buffer) 这一过程实际上发生了四次数据拷贝。首先通过系统调用将文件数据读入到内核态Buffer（DMA拷贝），然后应用程序将内存态Buffer数据读入到用户态Buffer（CPU拷贝），接着用户程序通过Socket发送数据时将用户态Buffer数据拷贝到内核态Buffer（CPU拷贝），最后通过DMA拷贝将数据拷贝到NIC Buffer。同时，还伴随着四次上下文切换。 sendfile和transferTo实现零拷贝 Linux 2.4+内核通过sendfile系统调用，提供了零拷贝。数据通过DMA拷贝到内核态Buffer后，直接通过DMA拷贝到NIC Buffer，无需CPU拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件-网络发送由一个sendfile调用完成，整个过程只有两次上下文切换，因此大大提高了性能。 具体实现上，Kafka的数据传输通过TransportLayer来完成，其子类PlaintextTransportLayer通过Java NIO的FileChannel的transferTo和transferFrom方法实现零拷贝。 数据压缩Kafka使用端到端的块压缩功能。如果启用，数据将由producer压缩，以压缩格式写入服务器，并由 consumer 解压缩。压缩将提高 consumer 的吞吐量，但需付出一定的解压成本。这在跨数据中心镜像数据时尤其有用。 目前 Kafka 共支持四种主要的压缩类型：Gzip、Snappy、Lz4 和 Zstd。关于这几种压缩的特性， 压缩类型 压缩比率 CPU 使用率 压缩速度 带宽使用率 Gzip Highest Highest Slowest Lowest Snappy Medium Moderate Moderate Medium Lz4 Low Lowest Fastest Highest Zstd Medium Moderate Moderate Medium Referreces Apache Kafka Design Efficient data transfer through zero copy - IBM Developer","tags":["kafka","消息中间件","高并发"],"categories":["技术随笔"]},{"title":"小米AX1800实现科学上网","path":"/2023/12/17/xiaomi-ax1800-shellclash/","content":"一直想在家中实现全局科学上网，这样在家里就不需要一直开着各种客户端了，一方面是每个设备科学上网的客户端都还不一样，存在重复配置，另一方面，客户端也会加快电池的消耗，本来打算投资软路由或者旁路由的，经过一番搜索发现小米的AX1800路由器是基于openwrt的，可以通过ShellClash项目在不影响原系统的情况下实现科学上网，这篇文章记录一下安装的经过，理论上所有的openwrt的路由器都可以安装，只要搜索自己路由器的型号，查找ssh登录的方法就行了。 固件准备并不是所有的版本都能刷OpenClash，小米AX1800最后一个可以开通ssh的版本是：1.0.336下载地址： miwifi_rm1800_firmware_fafda_1.0.336.bin在路由器的系统状态页点击：手动升级，然后选择下载的固件，进行降级。 开启ssh并设置root密码路由器降级成功之后，在路由器管理界面，打开Chrome控制台，将下面的脚本粘贴进去， function getSTOK() let match = location.href.match(/;stok=(.*?)\\//); if (!match) return null; return match[1];function execute(stok, command) command = encodeURIComponent(command); let path = `/cgi-bin/luci/;stok=$stok/api/misystem/set_config_iotdev?bssid=SteelyWinguser_id=SteelyWingssid=-h%0A$command%0A`; console.log(path); return fetch(new Request(location.origin + path));function enableSSH() stok = getSTOK(); if (!stok) console.error(stok not found in URL); return; console.log(`stok = “$stok”`); password = prompt(Input new SSH password); if (!password) console.error(You must input password); return; execute(stok, ` nvram set ssh_en=1 nvram commit sed -i ‘s/channel=.*/channel=\\\\”debug\\\\”/g’ /etc/init.d/dropbear /etc/init.d/dropbear start ` ) .then((response) = response.text()) .then((text) = console.log(text)); console.log(New SSH password: +password); execute(stok, `echo -e “$password\\ $password” | passwd root`) .then((response) = response.text()) .then((text) = console.log(text));enableSSH(); 在弹出狂中填入ssh root账号的密码，这里设置为admin ssh登录首先确定一下路由器的ip地址，在路由器管理界面可以查看到，一般是192.168.31.1，因为我是中继的，所以路由器的地址是192.168.1.7。这里需要根据自己的实际需求来修改。 使用下面的ssh命令，输入刚才设置的密码admin登录到小米路由器后台： ssh root@192.168.1.7 正常情况下应该是可以登录的，但是我的报了个错： Unable to negotiate with 192.168.1.7 port 22: no matching host key type found. Their offer: ssh-rsa 使用下面的命令可以正常登录了。 ssh -oHostKeyAlgorithms=+ssh-rsa root@192.168.1.7 安装ShellClash访问 ShellClash安装有详细的安装步骤 如果可以访问Github可以用Github源，如果不行的话可以使用jsDelivrCDN源或者作者私人源。 路由设备使用curl安装： #GitHub源(可能需要代理)export url=https://raw.githubusercontent.com/juewuy/ShellCrash/master sh -c $(curl -kfsSl $url/install.sh) source /etc/profile /dev/null 或者 #jsDelivrCDN源export url=https://fastly.jsdelivr.net/gh/juewuy/ShellCrash@master sh -c $(curl -kfsSl $url/install.sh) source /etc/profile /dev/null 或者 #作者私人源export url=https://gh.jwsc.eu.org/master sh -c $(curl -kfsSl $url/install.sh) source /etc/profile /dev/null 按照指引安装即可。 使用Clash安装成功之后，在命令行中输入clash进入面板 导入配置这里选择2，导入Clash配置文件链接。如果你买的是现成的机场的话，一般会有clash订阅的地址，copy粘贴到里面即可。 如果是自己搭建的V2ray的话，需要生成订阅链接，把其他协议如ss，ssr，vmess等转换为clash，可以使用开源工具sub-web自己搭建，也可以使用别人搭建的公益网站，，注意⚠️：使用第三方的转换工具可能会导致节点泄漏，这里笔者使用公益网站的是：https://convert.imgki.com/ 使用方法很简单，把vmess协议的链接放进去，然后点击生成订阅，剩下的可以上一步一样。 安装面板在开始菜单中输入9 更新卸载 选择4 安装本地Dashboard面板，安装推荐安装即可。 面板Dashboard安装完成之后，输入http://192.168.1.7:9999/ui/ 即可进入Clash后台，这里的ip地址改成自己路由器的地址。 接下来就是愉快的使用了。 参考 https://github.com/juewuy/ShellCrash/blob/master/README_CN.md 小米 AX1800 安装 ShellClash - 知乎 https://forum.openwrt.org/t/unable-to-connect-via-ssh-no-matching-host-key-type-found/114430","tags":["科学上网","AX1800","Clash","ShellClash"],"categories":["工具效率"]},{"title":"上海马拉松自动签到工具","path":"/2023/11/05/shangma-auto-sign-tool/","content":"前端时间写的上海马拉松自动签到工具已经完成很久了，有不少跑友都反映上马抽中了，而我也在经历了8年没中之后，今年很“幸运”的抽中了上海马拉松了，开心之情溢于言表，于是便想写一些内容来记录一下这个过程。 上海马拉松在中国应该算是顶级的马拉松赛事了，对于每一位跑者都意义非凡，对我来说，我一直想要跑一次上马，然而从15年开始抽签，一直抽到2022年，一直都没中，于是在小红书上看一些攻略，发现有人说上马积分对于抽签比重占的很大，尤其是当年度的积分，由于积分只能通过跑步、签到、以及赛事获取，我打算从签到和跑步来实现我攒积分的目标，其中跑步我已经在前面的文章中写过了，可以将Apple Watch同步到Strava再同步到Garmin，然后同步到数字心动，再到上马来获取积分。 那么签到呢？在我签过几次到之后我想能否实现一个自动化的签到程序，从而避免自己天天手动签到呢？虽然积分很少，但是日积月累也是相当可观的，一年也有365积分，相当于参加两次线下比赛了。 于是开始着手开始做，首先要研究上马的API，最简单的想法就是，获取Cookie，然后调用签到接口直接签到即可，或者使用OAuth认证拿到Token即可。嗯，想法确实不错，事实上也的确如此，只不过上马所有的API都有加密，然后后端验签，因此我使用Python写的脚本根本不能用，因为没有找到加密的方法以及密钥。所以我打算转而使用Javascript来实现，因为所有的Client加密应该都能拿到加密方法以及密钥，所以我在混淆过后的js代码debug，找到了sign的方法，直接将几个参数拼接，然后调用sign方法即可。当然，这样必须依赖Cookie，然而第一个版本是可以正常work的。 接下来要进行优化的就是使用用户名和密码进行登录签到，这样就涉及到了加密，于是我又仔细的debug了Login时的js代码，发现加密过程中的的nonstr是不变的，nonstr就是用来生成加密时的Key和初始向量（IV），有了它们，加解密也就可以轻松完成了。， 加解密代码： export function encrypt(word) var srcs = CryptoJS.enc.Utf8.parse(word) var encrypted = CryptoJS.AES.encrypt(srcs, key, iv: iv, mode: CryptoJS.mode.CBC, padding: CryptoJS.pad.Pkcs7 ) const encryptTxt = encrypted.ciphertext.toString() const hexString = CryptoJS.enc.Hex.parse(encryptTxt) return CryptoJS.enc.Base64.stringify(hexString)export function decrypt(encryptWord) var wordArray = CryptoJS.enc.Base64.parse(encryptWord) const encryptedCiphertext = CryptoJS.enc.Hex.stringify(wordArray) const encrypted = CryptoJS.lib.CipherParams.create( ciphertext: CryptoJS.enc.Hex.parse(encryptedCiphertext) ) var decrypt = CryptoJS.AES.decrypt(encrypted, key, iv: iv, mode: CryptoJS.mode.CBC, padding: CryptoJS.pad.Pkcs7 ) var decryptedStr = decrypt.toString(CryptoJS.enc.Utf8) return decryptedStr.toString()","tags":["跑步"],"categories":["工具效率"]},{"title":"将Apple Watch跑步数据同步到Garmin","path":"/2023/07/08/apple-watch-to-shuzixindong/","content":"起因是这样的，上马有个积分的功能，他可以影响正常的抽签（虽然是黑盒，但是有人反馈关系很大）的权重，而积分只能通过，签到，线下比赛，以及跑步获取，前两种好理解，第三种，跑步记录换取积分，需要上马官方合作伙伴数字心动APP来提供数据，然而，数字心动APP只能通过Garmin设备通过，并不支持Apple Watch直接上传（如果支持了，那么也没有这个项目了），于是我想是否能够曲线救国，将记录上传到Garmin，然后再通过Garmin同步到数字心动，这样就可以正常获取积分了。 首先我需要做的是验证可行性，于是我研究了一下Garmin开发者平台^1，发现Fit文件中包含了设备信息的，Garmin设备应该都是上传的Fit文件，所以，理论上可以通过将GPX转换为Fit文件，同时将设备信息写入Fit文件就可以伪装成Garmin设备上传的记录。 然后我花了一下午做了一个简单的POC，把我导出的GPX文件转换为Fit（当然也可以直接用Fit文件，Apple Watch导出的也是Fit文件）文件，然后通过Garmin Fit的SDK工具将文件decode成csv，然后把设备信息加上重新打包成fit上传Garmin Connect，跑步记录中就有设备信息了，经测试，这个伪造的运动记录可以正常从Garmin同步到数字心动了，于是上马APP上也就有了跑步的里程信息。 于是接下来就是将这个过程自动化了，刚好发现一直在用的跑步主页项目Running page中的Strava脚本有backup到Garmin的功能，因此我就想，能否通过这个修改脚本加入默认的Garmin设备，这样就可以将健身记录通过Garmin间接的同步到其他APP中，不仅仅是数字心动,实现的效果如下图：Strava_to_garmin 于是就开干了，改动不是很大，主要就是将原来的Fit文件decode，然后加入Fake的Garmin信息，然后重新打包成新的Fit文件， 最终的PR在这里：https://github.com/yihong0618/running_page/pull/435","tags":["跑步"],"categories":["工具效率"]},{"title":"也许你该试试双拼输入法","path":"/2023/06/30/how-i-learn-shuang-pin/","content":"这周最大的收获是学习了双拼输入法，而且带动了一个同事也开始学习双拼输入法了，还跟我说怎么不早告诉他😂。学习的过程也踩了不少坑，感觉有必要写出来，让后人少走弯路。 为何入坑？最初开始学习双拼是在twitter TL上看到一条双拼的推： 它让我想起了大学时候学习半途而废的经经历，于是想既然这么有价值，我也许应该重新捡起来，毕竟以前vim对我来说也是一座高山，现在也被我征服了。 可能会有小朋友要问了，打字效率对于一个程序员来说真的那么重要吗？ 不重要。它只是一个工具，不使用完全没有什么影响，它能帮你做的仅仅是提高一些效率，但是对于大多数人来说可能还不到拼效率的地步，大部分人来说全拼输入法够了，VSCode也够了。你可以举很多例子来反驳，但是都不如亲自试一试，这和学习vim一个道理，而且有反驳的时间，键位也都记住了。 这里，我也想用道德经里的一段话来说明： 上士闻道，勤而行之；中士闻道，若存若亡；下士闻道，大笑之。 假如你是一个想尝试新鲜事物的人，恰巧你也是一个“懒人”，那么我觉得你可以尝试一下双拼输入法，虽然它不能帮你摆脱重码率的困扰，但是至少能比全拼少敲几次键盘，记忆曲线也没五笔那么陡峭，基本上可以做到：1小时记忆键位，1周熟练双拼节奏，1月恢复到全拼的打字速度。 哪种方案？由于以前学了半吊子搜狗的方案，我决定选继续使用搜狗的方案（坑），练了大概一个下午，记住了键位，基本上能够写作和聊天了，只是有些慢，不过没关系，基本上楞个几秒钟就想出来了，这个过程是挺痛苦的，就是那种手跟不上大脑思考的速度的感觉，不过，假如你坚持几天，你会佩服自己的。 后来我发了一个即刻状态：一大堆人给我安利：小鹤方案，然后我意识到可能sogou的方案可能没有小鹤的好，于是我在网上搜了小鹤的方案，发现小鹤的零声母的处理比sogou更加优雅。 sogou的方案默认使用 o + 对应的韵母来实现打字，背诵起来是轻松不少，但是打字的时候感觉不是特别顺手。小鹤的零声母方案把韵母的首字母当作声母 ： 单字母韵母，零声母 + 韵母所在键，如： 啊＝aa 哦oo 额ee 双字母韵母，零声母 + 韵母末字母，如： 爱＝ai 恩en 欧ou 三字母韵母，零声母 + 韵母所在键，如： 昂＝ah 小鹤方案更加符合直觉，虽然需要记忆，但是要比其他方案顺手。比如，打一个 西安，sogou是xioj，小鹤是xian ， 除了零声母的方案，其他的键位相对于sogou来说也顺手不少，对于刚熟悉了sogou的双拼方案的我来说又是一次挑战，不过还好，一大半的键位都是一致的，虽然经历了一些波折，最终还是归于小鹤，毕竟小鹤是广大双拼爱好者们共同摸索出来的，所以如果你要学习双拼一定直接选择小鹤，不要走弯路了。 键位如何记忆？可以参考官方的记忆口诀：小鹤入门 如何练习？ 在 小鹤入门 记忆口诀 建议直接在双拼练习 @ BlueSky 练习即可，键位掌握半天时间就够了 记住了键位之后，就可以把系统的输入法切换成双拼输入法了，macOS，windows，ios都是自带的有双拼输入法的，而且有多种方案可以选择。 也许你该找个人聊聊天？ PS. 全篇文章使用macOS自带的双拼输入法（小鹤方案）写作完成。 Reference 双拼练习 @ BlueSky 小鹤入门","tags":["双拼输入法"],"categories":["工具效率"]},{"title":"自动分组chrome标签页","path":"/2023/05/05/autogroup-your-chrome/","content":"Chrome的标签功能在管理多个标签页时非常好用，但是在标签量更大一些的时候，手动的管理这些标签页就不太方便了，这个时候可以考虑使用chrome扩展来完成这一自动化的操作，特别是对于工作的场景，基本上每天打开的网站都是特定的场景。 Auto-Group Tabs是一个Chrome浏览器插件，用于自动对用户打开的多个标签进行分组，以使它们更容易管理和组织。这个插件还支持配置的导入和导出，可以方便的在多个设备上同步。 安装通过chrome商店：Auto-Group Tabs - Extensions 打开此链接，点击安装即可，如果在商店搜索安装的时候，有多个类似的扩展，注意选择下面这个。 配置和使用 基础配置对于我工作的电脑，我的标签： gitlab：主要是管理一些打开的gitlab repo，MR、pipeline等链接 wiki：主要是管理confluence上面的文档之类的，包括自己写的文档， Release check list等链接 jira：主要包含，自己的 dev：主要是在开发环境相关的一些页面，包括，开发环境的，kibana、argocd、pipeline等链接，管理后台等。 live：主要包含一些monitoring的相关页面，比如grafana、argocd、kibana等，还有一些业务使用的页面，比如管理后台等 search：主要是管理自己google search的结果，从search标签里查询出来的结果，如果没有被自动Group到其他的标签就会自动在当前的search标签中。 我的插件配置如下： 使用时添加配置完成之后，如果以后我们在打开某些网站的时候也可以很方便的添加到我们的规则里，比如在逛京东的时候，可以把京东 *.jd.co添加到我们的shopping规则中，然后京东就会自动添加到我们的shopping标签中。","tags":["效率","chrome扩展"],"categories":["工具效率"]},{"title":"认识布鲁姆分类学","path":"/2023/02/05/bloom-taxonomy/","content":"布卢姆分类学 (Bloom’s taxonomy) 是美国教育心理学家本杰明·布鲁姆于1956年在芝加哥大学所提出的分类法，此方法将认知层次分为六个，从低到高依次是：记忆（Remember）、理解（Understand）、应用（Apply）、分析（Analyze）、评估（Evaluate）、创造（Create）。 整个认知层次结构呈金字塔分布，记忆、理解、应用三个低阶思维水平的目标位于塔的底层，而分析、评估、创造三个高阶目标位于塔尖部分，因为它们都需要更高水平的思维技能。 第一层记忆（Remember）记住特定知识，包括一些具体事实、基础概念、术语等，不需要理解所学内容的内在含义，也就是通常说的死记硬背。这类一般是死知识，比如河南省的省会，世界有哪几个大洲构成等等 理解 （Understand）理解所学内容并可以清晰的描述它，而且可以使用自己的话准确复述材料的内容。 这里面包含了三种形势来表明自己对材料的理解：转换：也就是使用自己的话，或者使用和原文不同的方式来阐述它。解释：可以使用自己的理解对它进行说明或者概述，这里需要有一定的抽象能力。推断：预测发展的趋势和后果。 著名的费曼学习法就是通过输出倒逼输入的例子，如果你完全理解了一个内容，那么你就完全可以用非常浅显的语言解释给完全不懂的人听。换句话说，我们应该减少晦涩专业词语的使用，就算使用也要解释清楚其含义，如果我们无法用通俗语言来描述，大概率是自己没有真正理解它。 应用（Apply）举一反三，通过前面的记忆和理解把先前学到的知识迁移到新的情境中去解决一定的实际问题。 对于大部分人来说，可能是卡在这一步，上课时，老师讲得也都听懂了，也听的津津有味，但是老师布置的作业，下课一看傻眼了，根本做不出来。这也是很正常的，因为，对于大部分知识来说，它们并不是死的，而是互相关联的，考察的是综合能力，复杂的知识需要更多的相关的背景知识以及有逻辑思维的大脑。 而且这也要依赖前面的理解，如果理解不够透彻，那么一定做不好这一步。 第二层前面的记忆、理解、应用只是知识的表面部分，一般中小学对知识的考察程度一般都在这一层级。到了第二部分，我们就到了更加高级的阶段，一旦认知进入了这个层次，那也就是到了一个较为专业的层次了，需要掌握知识背后的原理以及原则。 分析（Analysis）将事物拆解成若干部分，认清他们之间的关系，明确它们的每个部分之间是如何关联的。复杂的事物往往是由非常多的部件构成的，比如汽车，手机等，表面上看它们知识一个工具，但是实际上，它们的内部及其复杂，每一个小的组件背后可能都是无数专利，特别是半导体芯片，集成电路等技术。 这就是以微观的视角来分析问题，并且能够根据一定的事实进行推断，这属于高级的大脑皮层活动。 评价（Evaluation）这里的评价指的是使用标准、理论或过程来评价价值评估价值，这一层级属于较高层级的的目标了，这一层次我们需要通过一定的准则对事物的价值做出判断。知乎上经常遇到的问题就是，如何评价XXX？ 创造 （Create）将之前所有的信息进行深度加工，使用新的方式重新组合起来创造新的事物，比如写作，设计等等，创新也发生于这一层级。 这是认知层次的最高境界，在学习一个新的知识的时候，写下来确实是倒逼自己思考的一个非常好的途径，因为写作一个创造的过程，这个过程需要不断回忆我们所学的知识，这个时候，他们可能是一个个的碎片，我们在写作的时候才能一点点把他们之间的关系捋清楚，这里面包含了（理解、应用、分析、评价）等步骤。 布鲁姆分类法可以作为我们的学习框架，它有助于我们思考所学内容，以及确定我们对于知识的掌握程度。此外，它也可以帮助我们提出更有价值的问题。 Reference https://zh.wikipedia.org/zh-hans/布鲁姆分类学 https://cft.vanderbilt.edu/guides-sub-pages/blooms-taxonomy","tags":["布鲁姆分类学","Bloom-Taxonomy","方法论"],"categories":["散文随笔"]},{"title":"再见2022","path":"/2022/12/31/bye-2022/","content":"2022年可以说是非常魔幻的一年了，这一年我刚好三十而立，女儿一岁了，这一年经历了很多，经历了四五月份的封城，经历了十二月份的疫情放开，经历了失望，无意义，还有一些成长，感觉认识自己更多一点了。 可能人的一辈子就是一个逐渐认识到自己是一个普通人，然后接受自己的一个过程，一晃眼，一年就过去了，想要回忆这一年都发生了什么还是有些困难，大部分的事情都在时间的中褪色了，不过还是有一些事情，值得开心的。 一些值得记录的事情第一件事情，自学了Typescript写了一个Obsidian微信读书插件。这件事情纯属偶然，因为平时读书都是微信读书，然后记笔记的软件是Obsidian，自己导出笔记然后再copy到Obsidian着实有些麻烦，心想Obsidian的插件市场又那么大，以为肯定会有人已经写了这个插件，结果并没有，于是有了自己写插件的想法，去github找相关的微信读书API，然后找obsidian开发的example等，五一假期刚好是上海封城时期，自己就在家哼哧哼哧写出来了，那时候真的是精力旺盛，那几天基本上都是早上4点起床，开始写代码，因为我感觉代码就在我脑子里要倾泻下来，现在回想起来，感觉整个人是陷入到了一种人码合一的状态了，我把自己做的Obsidian插件做成了视频【学了3天typescript写了一个微信读书的Obsidian插件-哔哩哔哩】放到了B站，结果还有不少人使用，自己做的工具能帮到别人，真的是一种莫大的肯定，现在，插件的Github star数已经到了431，远远超出了我的预期。 第二件事情，和朋友一起翻译一本关于MATLAB和Python的英文技术书籍，一个博士朋友问我有没有兴趣一起翻译一本技术书籍，我接受了这个挑战，刚开始的时候，翻译的真的是一言难尽，好在朋友的慢慢引导和建议，后面章节翻译的越来越好了，同事对自己的英文水平有很大提升，雅思的单词词汇量基本上没问题了，技术方面，自己也学会了MATLAB的一些基础知识，感觉收货还是很大的。 第三件事情，学会了双拼输入法。发现了自己的学习能力还是有的，主要就是刚开始的一个星期到两个星期，感觉打字怎么打怎么别扭，随着时间增长，我发现双拼变成了肌肉记忆。可能会有人说打字那么快干啥，我自己用全拼也能好好的，其实，学习双拼主要是我感觉它比较简单，是的就是简单，比五笔简单，然后还能满足打字速度的需求，期间还从搜狗方案切换到了小鹤方案。不过现在最大的问题是，在需要输入拼音的地方，忍不住要打双拼，比如在iphone上搜索app的时候🤣，这可能就是肌肉记忆了吧。 第四件事情，开上了自己的第一辆车：比亚迪宋plus DM-i，虽然并不是什么豪车，但是自己感觉挺满意，就是等车的时间有些长，从6月等到了11月，不过为了上海的绿牌我忍了。有了车之后还是方便一些，去超市购物，周末去周边的地方玩一玩都很方便，充电也很方便，感觉很满意。 关于生活女儿磕磕绊绊长到了一岁，第一次抬头，第一次翻身，第一次爬行，第一次坐，第一次站，第一次叫爸爸，我都在场。有了好几次大半夜往医院赶的经历，随着女儿一点点的长大，感受到了自己身上的作为父亲的责任也越来越大，也更能感受到身为父母的不易，家庭关系也慢慢磨合得和谐很多。 这一年由于疫情，跑步耽误的比较多，一年也就跑了六百多公里，整个四五月份上海封城了两个月，期间一次都没跑过，三月份疫情开始蔓延，不敢出去跑步，十二月份阳了，虽然一周就转阴了，也不敢出去跑步，因为看到了太多的阳康因为运动而丧命的。 这几年跑步的次数明显下降了，通过我的Running Page也能看出来这个趋势，处于年年下降的状态，一方面是心态发生了变化，想跑的时候就多跑一点，兴致来的时候跑个半马，不想跑的时候也不强求自己，从图中能够看出来，基本上每周都会有跑步，除非特殊情况，至少两次跑步。一方面不至于让自己懈怠，另一方面也不至于让自己很累。 这一年，也定一个新的跑步目标吧，年度1000km，如果没有疫情的话，我感觉应该能够完成。 关于阅读这一年，基本上读的书不多，其中对我影响最大的应该是 塔勒布的《非对称风险》 周濂的《打开：》 傅高义的《邓小平时代》 《西游记》 史景迁的《太平天国》 黑塞的《悉达多》 看的出来，我比较喜欢哲学，以及文史，今年技术书籍读的比较少，因为基本上技术学习主要靠的是官方文档，优秀的Blog等等。随着年龄的增长，或许是自己的天性使然，感觉更原因向内探索，这也和悉达多一样，要拜自己为师，尝试理解自己，在物理世界和内心世界之间达到某种平衡，这个世界是物质的，但也是精神的，两者必须保持自洽，人才不至于分裂。 阅读是一种单向的沟通，不是最高效的，但是作者依然可以通过文字把他的所思所想告诉读者，能不能理解作者的想法，那就靠天分了。现在我非常认同悉达多的那句话： 知识可以分享，智慧无法分享，它可以被发现，被体验。智慧令人安详，智慧创造奇迹，但人们无法言说和传授智慧。 一些展望新的一年，希望自己能多爱这个家一点，多爱父母，多爱爱人一点，多爱女儿一点，让她们都开心一点，这个家也就立起来了，我要做的就是守护，让一切都保持和谐的状态。 新的一年，我会坚持读书，去书中寻找自我和超我，也会继续跑步，或长或短，或快或慢，无所谓，要做的是跑步本身，跑步让我冷静，让我能够切换角色，沉浸到跑步本身，感受到心流。 新的一年，也希望自己能够不断去开始，去发现，去学习，去探索，去经历。开始比完美重要，行动比言语重要。不断充实自己的大脑，然后让头脑中的点点知识，转化为实实在在的智慧，通过自己的智慧去影响这个世界。 未来拥有很大的不确定性，我也没有什么远大的志向，新冠让我意识到人很渺小，希望自己能够过好当下，践行好每一个瞬间就已足够。","tags":["疫情","Obsidian","2022","Github"],"categories":["年终总结"]},{"title":"以父之名","path":"/2022/11/08/as-a-father/","content":"不知不觉，成为父亲已经一年有余，这一年，从一个懵懂的小男生变成了一个奶爸，这一年真的经历了太多。肺炎，呕吐，腹泻，还有疫情，买奶粉等等，辛苦是真的辛苦，不过这个小家，多了一些欢声笑语，多了一些不一样的颜色，感觉自己一下子变得柔软起来。 当然，带娃是一件非常累的事情，喂奶，洗澡换尿布是基本操作，从刚开始的纸尿裤穿反，到后面的轻车熟路，都是时间的馈赠。有的时候还真是很怀念二人世界，多的是自由时间。 宝宝的到来，是一个神奇的礼物，我们都是时间的旅行者，像罗翔老师说的那样，开始意识到自己是有限的，而宝宝的到来，让我们意识到，虽然对一个人来说，人是有限的，但是繁衍让人变得无限。当然这就有些扯远了，其实就是生物的筑巢本能吧。 人这种生物，很奇怪的一点就是要寻找意义，很多时候，找不到意义，也就找不到继续生活下去的理由，世俗生活是大部分人的生活，我承认自己是一个俗人。 有的时候，我想人是孤独的，就像一场聚会，就算再热闹，也最终要散场。但是我们需要的不是结果的落寞，也需要过程的热烈。烟花的美在于它盛开的过程的绚烂，而不是一地烟灰。 正如和菜头说的： 正午时分看人间烟火，夜半时分看月亮如水，各有各的风景。该举杯时举杯，该独行时独行，那么就总是感觉轻安自在，没有那么多一定，也没有那么多必须，更没有那么多不得不，这就是自由。 对于我来说，家庭角色一下子从原来一个变成了三个，丈夫，儿子，父亲。如何在这三者角色之间切换是一个技术活，一旦处理不好，就是一地鸡毛。 如果不是自己当父亲，自己永远无法体会一个父亲的感受，别人说的永远只是一些文字，只有自己体会了才懂，这可能这就是时间的馈赠吧。","tags":["育儿","感悟"],"categories":["散文随笔"]},{"title":"Spring静态Bean的原理","path":"/2022/09/21/spring-static-bean/","content":"最近遇到一个spring static bean的坑，我们知道使用Java Config的方式定义一个Bean 非常简单，只需在Configuration的method上加上 @Bean 注解即可。 但是这里有个例外，假如你的Bean不是一个普通的Bean，而是一个BeanFactoryPostProcessor就需要使用static方法来定义这个Bean。 否则你会得到一个警告： @Bean method TestConfig.customEditorConfigurer is non-static and returns an object assignable to Springs BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the methods declaring @Configuration class. Add the static modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details. 也就是说，如果你的bean是一个BFPP，必须定义为static，否则，使用@Autowired, @Resource and @PostConstruct 会有问题。 来看 @Bean注解源码里的注释： Special consideration must be taken for @Bean methods that return Spring BeanFactoryPostProcessor (BFPP) types. Because BFPP objects must be instantiated very early in the container lifecycle,they can interfere with processing of annotations such as @Autowired, @Value, and @PostConstruct within @Configuration classes. To avoid these lifecycle issues, mark BFPP-returning @Bean methods as static. For example: @Bean public static PropertySourcesPlaceholderConfigurer pspc() // instantiate, configure and return pspc ... By marking this method as static, it can be invoked without causing instantiation of its declaring @Configuration class, thus avoiding the above-mentioned lifecycle conflicts. Note however that static @Bean methods will not be enhanced for scoping and AOP semantics as mentioned above. This works out in BFPP cases, as they are not typically referenced by other @Bean methods. As a reminder, a WARN-level log message will be issued for any non-static @Bean methods having a return type assignable to BeanFactoryPostProcessor. 因为BFPP都需要在在Spring容器的早期进行实例化，因为他们会干扰正常的Bean实例化中处理 @Autowired @Value @PostConstruct ，这篇Blog尝试寻找一下Static Bean背后的原理。 问题重现我尝试简化一下模型来重现一下问题： SpringBoot项目里有一个TestConfig类，在里面定义了一个特殊的Bean：customEditorConfigurer因为CustomEditorConfigurer是一个BFPP，它的作用是注册自定义的类型转换器，Spring可以把String 转换为相对应的类型，这里我注册一个UserEditor，它的作用是将String转换为User对象，这样在使用@Value的时候就能实现自动类型转换，将配置文件里的字符串自动转换为一个User对象。 @Configuration @Data public class TestConfig @Value($test.user:hank) private User user; @Bean public CustomEditorConfigurer customEditorConfigurer() final CustomEditorConfigurer customEditorConfigurer = new CustomEditorConfigurer(); MapClass?, Class? extends PropertyEditor customEditors = new HashMap(); customEditors.put(User.class, UserEditor.class); customEditorConfigurer.setCustomEditors(customEditors); return customEditorConfigurer; @AllArgsConstructor @Data class User private String name; class UserEditor extends PropertyEditorSupport @Override public void setAsText(String text) throws IllegalArgumentException User user = new User(text); super.setValue(user); 在一个Bean里依赖TestConfig 获取 user将会是null，假如我们把customEditorConfigurer()方法改为static将会能正确得拿到user信息： ==== get test user:User(name=hank) @SpringBootApplication public class BootDemoApplication implements ApplicationRunner @Autowired TestConfig testConfig; public static void main(String[] args) SpringApplication.run(BootDemoApplication.class, args); @Override public void run(ApplicationArguments args) System.out.println(==== get test user: + testConfig.getUser(); 为什么BFPP需要定义成Static Bean？Static @Bean Definition注册先来看下static bean和normal bean在BeanDefinition注册的有何不同，这个时候我们就需要看Spring源码了，@Bean BeanDefinition的注册是在ConfigurationClassBeanDefinitionReader#loadBeanDefinitionsForConfigurationClass中的： private void loadBeanDefinitionsForConfigurationClass( ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) //... for (BeanMethod beanMethod : configClass.getBeanMethods()) loadBeanDefinitionsForBeanMethod(beanMethod); 仔细看下loadBeanDefinitionsForBeanMethod private void loadBeanDefinitionsForBeanMethod(BeanMethod beanMethod) if (metadata.isStatic()) // static @Bean method if (configClass.getMetadata() instanceof StandardAnnotationMetadata) beanDef.setBeanClass(((StandardAnnotationMetadata) configClass.getMetadata()).getIntrospectedClass()); else beanDef.setBeanClassName(configClass.getMetadata().getClassName()); beanDef.setUniqueFactoryMethodName(methodName); else // instance @Bean method beanDef.setFactoryBeanName(configClass.getBeanName()); beanDef.setUniqueFactoryMethodName(methodName); 区别在于如果是static bean 会设置BeanClass而普通的Bean设置FactoryBeanName，这个在后面createBean的时候会用到。 BeanPostProcessor Bean 的实例化PostProcessorRegistrationDelegate的invokeBeanFactoryPostProcessors发生在所有Bean实例化之前 在BeanFactory中搜索所有BeanFactoryPostProcessor的beanName（就是上一步添加到bean dedefinition map） String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); 然后给BFPP排序，按照实现 PriorityOrdered Ordered 一般 BFPP，这个时候会实例化BFPP beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class) 实例化步骤和普通的Bean一样，先使用 BeanFactory.getBean(beanName) 获取Bean，这一步会触发createBean的操作 doCreateBean中直接调用createBeanInstance创建实例 createBeanInstance中instantiateUsingFactoryMethod 根据Factory Method来创建实例,委托给ConstructorResolver来进行创建，下面是关键代码： String factoryBeanName = mbd.getFactoryBeanName(); if (factoryBeanName != null) if (factoryBeanName.equals(beanName)) throw new BeanDefinitionStoreException(mbd.getResourceDescription(), beanName, factory-bean reference points back to the same bean definition); factoryBean = this.beanFactory.getBean(factoryBeanName); if (mbd.isSingleton() this.beanFactory.containsSingleton(beanName)) throw new ImplicitlyAppearedSingletonException(); this.beanFactory.registerDependentBean(factoryBeanName, beanName); factoryClass = factoryBean.getClass(); isStatic = false; else // Its a static factory method on the bean class. if (!mbd.hasBeanClass()) st throw new BeanDefinitionStoreException(mbd.getResourceDescription(), beanName, bean definition declares neither a bean class nor a factory-bean reference); factoryBean = null; factoryClass = mbd.getBeanClass(); isStatic = true; 如果factoryBeanName 不为空，说明是普通的Bean实例化, 需要先创建FactoryBean 可以理解成宿主Bean，如果是static factory method创建的Bean则不需要。 创建Bean之前需要先创建Factory Bean实例，在这里FactoryBean就是testConfig 这个实例，在创建testConfig实例的时候发现需要有依赖的@Value dependency，这个时候会去使用TypeConverter来将String转换为User，这个时候就有问题了，我们的UserEditor还没注册完成呢，testConfig是在customEditorConfigurer实例化的时候被创建的，所以这个 创建customEditorConfigurer 发现customEditorConfigurer不是static所以先要创建FactoryBean也就是testConfig testConfig中依赖@Value，populateBean的时候需要调用UserEditor来做转换 UserEditor没有注册，因为customEditorConfigurer还没创建完成 所以User就没有初始化，user就是null 如果是Static Bean的话就没有这个问题了，因为static bean 不需要依赖factoryBean来创建实例，而是直接调用的构造器来进行初始化的。 References Core Technologies","tags":["java","spring"],"categories":["源码解析"]},{"title":"Spring 事件驱动的原理","path":"/2022/09/03/spring-event-driven/","content":"Spring事件驱动Spring 事件驱动的代码都位于spring-context 模块的event包中，主要包括：事件(Event)发布者() Publisher) ,订阅者(Listener)组成。 事件ApplicationEventjava的所有事件对象一般都是java.util.EventObject的子类，Spring的整个继承体系如下: Publisher 发布者ApplicationEventPublisherAbstractApplicationContext实现了ApplicationEventPublisher接口 publishEvent ApplicationEventMulticasterApplicationEventPublisher实际上正是将请求委托给ApplicationEventMulticaster来实现的。其继承体系: Listeners 监听者所有的监听器是jdk EventListener的子类，这是一个mark接口。继承体系: 可以看出SmartApplicationListener和GenericApplicationListener是高度相似的，都提供了事件类型检测和顺序机制，而后者是从Spring4.2加入的，Spring官方文档推荐使用后者代替前者。 初始化前面说过AppjlicationEventPublisher是通过委托给ApplicationEventMulticaster实现的，所以refresh方法中完成的是对ApplicationEventMulticaster的初始化: // Initialize event multicaster for this context.initApplicationEventMulticaster(); initApplicationEventMulticaster则首先在BeanFactory中寻找ApplicationEventMulticaster的bean，如果找到，那么调用getBean方法将其初始化，如果找不到那么使用SimpleApplicationEventMulticaster。 ApplicationEventPublisher 接口AbstractApplicationContext.publishEvent核心代码: protected void publishEvent(Object event, ResolvableType eventType) getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); SimpleApplicationEventMulticaster.multicastEvent: @Overridepublic void multicastEvent(final ApplicationEvent event, ResolvableType eventType) ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); for (final ApplicationListener? listener : getApplicationListeners(event, type)) Executor executor = getTaskExecutor(); if (executor != null) executor.execute(new Runnable() @Override public void run() invokeListener(listener, event); ); else invokeListener(listener, event); 监听器获取获取当然还是通过beanFactory的getBean来完成的，值得注意的是Spring在此处使用了缓存(ConcurrentHashMap)来加速查找的过程。 同步异步可以看出，如果executor不为空，那么监听器的执行实际上是异步的。那么如何配置同步异步呢? 全局task:executor id=multicasterExecutor pool-size=3/bean class=org.springframework.context.event.SimpleApplicationEventMulticaster property name=taskExecutor ref=multicasterExecutor/property/bean task schema是Spring从3.0开始加入的，使我们可以不再依赖于Quartz实现定时任务，源码在org.springframework.core.task包下，使用需要引入schema： xmlns:task=http://www.springframework.org/schema/taskxsi:schemaLocation=http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-4.0.xsd 开启注解支持: !-- 开启@AspectJ AOP代理 -- aop:aspectj-autoproxy proxy-target-class=true/ !-- 任务调度器 -- task:scheduler id=scheduler pool-size=10/ !-- 任务执行器 -- task:executor id=executor pool-size=10/ !--开启注解调度支持 @Async @Scheduled-- task:annotation-driven executor=executor scheduler=scheduler proxy-target-class=true/ 在代码中使用示例: @Component public class EmailRegisterListener implements ApplicationListenerRegisterEvent @Async @Override public void onApplicationEvent(final RegisterEvent event) System.out.println(注册成功，发送确认邮件给： + ((User)event.getSource()).getUsername()); References https://www.iteye.com/blog/jinnianshilongnian-1902886 https://github.com/seaswalker/spring-analysis/blob/master/note/Spring.md#applicationeventmulticaster","tags":["java","spring"],"categories":["源码解析"]},{"title":"和焦虑做朋友","path":"/2022/08/08/how-to-deal-with-anxious/","content":"焦虑的产生焦虑产生来自于恐惧，恐惧是对当下刺激的应激反应，焦虑是对未来刺激的应激反应。当我们在碰到一些严重刺激我们感官的事情时，杏仁核会接收到恐怖和惊惧，那么海马体会把这些感受记录下来。紧接着交叉神经也会启动，血压飙升、心跳加速都可以让你牢牢记住这个经历，如果它是足以对人身造成危险的情况，那么你下次很大概率会自动躲避。 换句话说也就是说，焦虑是保护自己的。 现代社会中，我们不需要再面对大量的恐惧了，但是筑巢本能依然存在，海马体依然保存了相关的能力，今年年初上海的疫情，让我们对基本的衣食住行感到焦虑，因为，平时唾手可得的食物，在疫情期间获取是如此的困难，这些恐惧让我们的海马体记录下来，很长时间内，我们会对未来产生焦虑，这些焦虑是良性的，保证我们生存的本能，在漫长的进化过程中，没有焦虑的人很可能因为没有储存过冬的食物而灭绝，我们能延续到现在，很大程度上是因为祖先适度的焦虑。 焦虑不可能完全消除焦虑的本质是恐惧的提前，是对未来的不确定性的担忧，这就意味着它是不可能被消除的。它不是现代人特有的， 物质极大丰富的年代反而更加剧了这种焦虑，我们看似拥有很多东西，世纪上都是空中楼阁，我们过于依赖外界，这让一切变得不确定，不确定产生焦虑。 面对现实，承认焦虑的存在，我们才有可能和焦虑做朋友。坦诚是一个人最好的品质。特别是对自己坦诚，大部分时候，我们喜欢自欺欺人，坦诚可以让我们面对问题本身，一旦承认了问题的存在，我们才有解决问题的可能，我们才能变得更好，这也是实事求是的来源。 一个焦虑的消失会伴随着另一个焦虑的诞生，就像叔本华说的，人是在无聊和痛苦之间摇摆的动物。 如何缓解焦虑必须要找到焦虑产生的根源。很多时候，焦虑来自于我们的拖延，这个时候，我们需要做的就是面对需要解决的问题，然后尝试break down，大的难题往往不好解决，所以我们需要将大的问题拆解成小问题，制造一个足够小的切入点，三分钟原则，一旦我们开始了三分钟，就很容易坚持下去。 也有的时候，焦虑来自无法改变的事物，焦虑未来发生的事情，比如第一次演讲，第一次出远门等，就算我们准备再充分，都会不可避免的焦虑，这个时候可以做一些其他事情转移注意力，不要让焦虑拖垮我们，一旦我们开始了，焦虑自然就消散了，很多人应该都会有这样的体会，在很多人面前发言的时候，上台前是最害怕的时候，真到了讲台上，反而没有那么紧张了。 寻找心流心流是让焦虑暂时离开我们的最佳方法，也就是达到忘我的状态，我们的内心像一个容器一样，一旦装下了一些事物，就不能再容纳下其他的事物，所以，最佳的方法是让我们的心被那些好的事物占据，心流就是这样一种状态。我们沉醉于我们正在做的事情，并且忘记了时间，在这个状态里，我们不愿意被打断，并且会有非常充实且愉悦的感受。 想达到心流状态，有两个重要指标： 挑战性目标 即时反馈 这两个目标缺一不可，打游戏可能是最容易进入心流的事情了，因为游戏的难度往往会匹配等级，让我们能够获得即时正向反馈，大扫除也是，我们看到凌乱的房间变得越来越整洁，会产生很大的正反馈。 专注于做每一件事情，就算事情再小，只要符合这两个条件，就会很容易达到心流的状态，比如： 自己（或者和伴侣）去菜市场或者超市，去挑选水果蔬菜和肉类，看到新鲜的蔬菜和水果还带着水珠，心情会变得很好，自己采买的蔬菜也会更加有成就感。就算你自己一个人住，也不要经常点外卖，买一个雪平锅电饭煲 可以做出非常多的美味佳肴。 打扫卫生，把一个乱糟糟的空间变得井井有条也是一件非常有成就感的事情。 看一部电影，短视频留下的当下，能坚持看完一部电影绝对是一种能力，如果看的投入，会极大的放松，如果对新电影没有兴趣，可以看看老电影，重温老电影也是一件非常浪漫的事情，不管是一个人看，还是和爱的人一起。 徒步旅行，就在自己的城市里，寻常巷陌内转转也是非常不错的选择，感受城市的烟火气，我经常一个人绕着巨大的环城绿道徒步，呼吸着湿润的风，负氧离子也会让自己的心情变好。 跑一个步吧，没有什么事情是一场跑步解决不了的，如果10km不够那就一个半马。运动可以极大的缓解抑郁情绪，大量的流汗可以促进血液循环，让我们更加神情气爽。 和焦虑做朋友拒绝完美主义，完美加上了主义就说明了它不再完美，完美主义在我看来是一个贬义词而风褒义词，完美主义者往往拒绝开始，一旦开始，遇到一些错误又马上否定全部，不能接受自己犯错，攻击自己。 这个世界是无限的，知识是无限的，学习永远没有尽头，因此，享受过程才能让我们走的更远，我们能把握的也仅仅只有过程而已。 既然焦虑是不可能消除的，是和我们如影随形的，我们就必须和平接受它，并且和它化敌为友，让它驱动我们不断进步，不断成长。 大部分时候我们会被束缚，我们被欲望裹挟，欲望满足了便开心，不满足便失落，但是即便是在焦虑和失望中也不要丧失对生活的信心，就像苏东坡在承天寺和张怀民一起月光庭下散步的一样坦然和宁静。 References 《心流：最优体验心理学》-米哈里·契克森米哈赖 《伯恩斯焦虑自助疗法》-戴维·伯恩斯","tags":["思考","焦虑","心流"],"categories":["散文随笔"]},{"title":"Spring @Transactional是如何工作的？","path":"/2022/08/06/spring-transaction-source-code/","content":"Spring事务使用Spring配置事务还是挺简单的，第一步创建事务管理器TransactionManager，然后在配置中增加一个@EnableTransactionManagement就可以启用Spring事务了，所以关键类就是@EnableTransactionManagement @Bean public DataSourceTransactionManager transactionManager() return new DataSourceTransactionManager(dataSource()); 我们可以看到@EnableTransactionManagement 上实际上是import了TransactionManagementConfigurationSelector类，在这个Selector中实际import了两个配置类： AutoProxyRegistrar ProxyTransactionManagementConfiguration @Override protected String[] selectImports(AdviceMode adviceMode) switch (adviceMode) case PROXY: return new String[] AutoProxyRegistrar.class.getName(), ProxyTransactionManagementConfiguration.class.getName(); case ASPECTJ: return new String[] determineTransactionAspectClass(); default: return null; 下面我们来根据这个入口来分析一下Spring是如何处理事务的： AutoProxyRegistrar 导入AutoProxyRegistrar主要的作用是向Spring容器中注册了一个InfrastructureAdvisorAutoProxyCreator的Bean。这一步位于spring aop包下面的 AopConfigUtils#registerAutoProxyCreatorIfNecessary方法中 InfrastructureAdvisorAutoProxyCreator继承了AbstractAdvisorAutoProxyCreator，所以这个类的主要作用就是开启自动代理的作用，也就是一个BeanPostProcessor，会在初始化后步骤中去寻找Advisor类型的Bean，并判断当前某个Bean是否有匹配的Advisor，是否需要利用动态代理产生一个代理对象。 这里InfrastructureAdvisorAutoProxyCreator会扫描到事务处理的BeanFactoryTransactionAttributeSourceAdvisor SpringAOP实现原理代理对象的生成类是：AbstractAutoProxyCreator 实现了BeanPostProcessor接口，会在Bean初始化完成之后通过postProcessAfterInitialization生成代理对象。来看postProcessAfterInitialization方法： public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) if (bean != null) Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) return wrapIfNecessary(bean, beanName, cacheKey); return bean; 主要代码就是wrapIfNecessary, 主要作用是生成Proxy Bean protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) ... // Create proxy if we have advice. Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) this.advisedBeans.put(cacheKey, Boolean.TRUE); Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; 这里 getAdvicesAndAdvisorsForBean 为当前的Bean寻找合适的Advices，这个方法是Abstract方法，因此需要子类去实现。 主要实现代码在AbstractAdvisorAutoProxyCreator中 protected Object[] getAdvicesAndAdvisorsForBean( Class? beanClass, String beanName, @Nullable TargetSource targetSource) ListAdvisor advisors = findEligibleAdvisors(beanClass, beanName); if (advisors.isEmpty()) return DO_NOT_PROXY; return advisors.toArray(); protected ListAdvisor findEligibleAdvisors(Class? beanClass, String beanName) ListAdvisor candidateAdvisors = findCandidateAdvisors(); ListAdvisor eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) eligibleAdvisors = sortAdvisors(eligibleAdvisors); return eligibleAdvisors; findEligibleAdvisors 会通过一个工具类在BeanFactory中查合适的Advisor，findAdvisorsThatCanApply会过滤可以被Apply的Advisor, 主要是看目标类和Advisor之间的关系来判断，这里主要由AOP的代码来实现。 ProxyTransactionManagementConfiguration导入ProxyTransactionManagementConfiguration 是一个配置类，它又定义了另外三个bean： BeanFactoryTransactionAttributeSourceAdvisor：一个Advisor AnnotationTransactionAttributeSource：相当于BeanFactoryTransactionAttributeSourceAdvisor中的Pointcut TransactionInterceptor：相当于BeanFactoryTransactionAttributeSourceAdvisor中的 Advice AnnotationTransactionAttributeSource 就是用来判断某个类上是否存在@Transactional注解， 或者判断某个方法上是否存在@Transactional注解的。TransactionInterceptor就是代理逻辑，当某个类中存在@Transactional注解时，到时就产生一个 代理对象作为Bean，代理对象在执行某个方法时，最终就会进入到TransactionInterceptor的 invoke()方法。 Spring事务拦截PlatformTransactionManager @Transactional处理Transactional 解析@Transactional的处理主要是交给TransactionAttributeSourceAdvisor完成的，TransactionAttributeSourceAdvisor实现了Advisor接口，因此在Spring创建Bean的时候查找Advisor的时候，只要classpath中有加载到tx相关的jar包，并且Enable相关Transactional的配置了就会执行执行这个Advice增强功能。 TransactionAttributeSourceAdvisor中包含了一个TransactionInterceptor,也是一个Advice，因此最终 @Transactional就会最终实现事务的增强功能。事务执行原理 一个Bean在执行Bean的创建生命周期时，会经过 InfrastructureAdvisorAutoProxyCreator 的初始化后的方法，会判断当前当前Bean对象是否和 BeanFactoryTransactionAttributeSourceAdvisor 匹配。 匹配逻辑为判断该Bean的类上是否存在 @Transactional 注解，或者类中的某个方法上是否存在 @Transactional注解，如果存在则表示该Bean需要进行动态代理产生一个代理对象作为Bean对象。 该代理对象在执行某个方法时，会再次判断当前执行的方法是否和BeanFactoryTransactionAttributeSourceAdvisor匹配，如果匹配则执行该Advisor中的 TransactionInterceptor的invoke()方法，执行基本流程为： 利用所配置的PlatformTransactionManager事务管理器新建一个数据库连接 修改数据库连接的autocommit为false 执行MethodInvocation.proceed()方法，简单理解就是执行业务方法，其中就会执行sql 如果没有抛异常，则提交 如果抛了异常，则回滚 TransactionInterceptor构造函数传入了一个TransactionManager 来管理事务 public TransactionInterceptor(TransactionManager ptm, TransactionAttributeSource tas) setTransactionManager(ptm); setTransactionAttributeSource(tas); 调用Advice的 invoke方法之后最终调用的是父类TransactionAspectSupport的invokeWithinTransaction来进行实际处理 public Object invoke(MethodInvocation invocation) throws Throwable // Work out the target class: may be @code null. // The TransactionAttributeSource should be passed the target class // as well as the method, which may be from an interface. Class? targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); // Adapt to TransactionAspectSupports invokeWithinTransaction... return invokeWithinTransaction(invocation.getMethod(), targetClass, new CoroutinesInvocationCallback() @Override @Nullable public Object proceedWithInvocation() throws Throwable return invocation.proceed(); @Override public Object getTarget() return invocation.getThis(); @Override public Object[] getArguments() return invocation.getArguments(); ); References https://zhuanlan.zhihu.com/p/54067384 https://juejin.cn/post/7018541168635936775","tags":["java","spring"],"categories":["源码解析"]},{"title":"使用chezmoi管理dotfiles","path":"/2022/08/05/use-chezmoi-manage-dotfiles/","content":"为什么要管理dotfiles？dotfile是对自己的软件配置文件的总称，如果有多台开发设备的话，我们需要在不同的电脑上保持同样的配置，我们对工具的使用不是一成不变的，而是随着时间不断演进的，日常使用的过程中，会不断修改dotfile让工具越来越顺手，这时同步dotfile就变得非常重要了，你的工具的行为在多个平台上应该是一致的，就像VSCode自带的setting 同步功能一样。 dotfiles管理的痛点 dotfile总是分布在不同的位置，想把他们汇总在同一个位置非常不方便，使用软连接之后，用github管理又非常不便。 配置文件的修改不能及时同步到github 多个设备可能跨平台，配置文件可能是不一样的 相同的平台，不同的设备也有差异化的配置，比如工作电脑和自己私人电脑，有一些配置肯定是不一样的 密码管理器，选择自己合适的密码管理软件（） 什么是chezmoi？chezmoi是一款使用go语言编写的跨平台的的dot配置管理器，它是一个法语单词，意思是家，读作 ʃeɪ mwa (shay-moi) chezmoi的工作原理很简单： 它使用一个working copy来管理dotfiles，chezmoi负责对working copy和home directory 进行同步，然后使用git来管理 working copy和remote repo的差异。 chezmoi基本使用安装非常简单，我使用mac 直接 brew install chezmoi 就行了，如果你使用其他的平台，可以参考：Install - chezmoi 初始化如果是初次使用的话，先使用chezmoi init会在~/.local/share/chezmoi创建一个git仓库，这个是local的repo，我们还需要一个remote的repo，我们可以在github上创建一个名字为：dotfiles的Repo来存储自己的dotfiles，dotfiles名字是chezmoi的使用惯例，使用起来更方便，参考### 在其他设备上使用dotfiles 这一章节。 添加dotfile添加dotfile到chezomi管理 ，例如 chezmoi add ~/.zshrc 就会把我们的.zshrc文件copy到~/.local/share/chezmoi 中去，并且改名字为：dot_zshrc ，它是和.zshrc 一一对应的，是.zshrc的一份working copy。 编辑dotfile一旦添加到chezomoi，编辑.zshrc的时候我们就需要使用 chezmoi edit ~/.zshrc来编辑zshrc文件，这个命令会自动帮我们mapping到 dot_zshrc文件进行修改，当然你也可以直接到~/.local/share/chezmoi 直接编辑dot_zshrc文件，效果是一样的。编辑完成之后，可以使用 chezmoi diff 来查看修改的部分。比如我使用 chezmoi edit ~/.zshrc在文件最后加上alias cm=chezmoi ，然后使用 chezmoi diff 命令，可以看到:然后我们执行chezmoi -v apply 来使dotfile生效，如果你不想每次都chezmoi apply可以在~/.config/chezmoi/chezmoi.toml加上下面的配置文件： [git] autoCommit = true autoPush = true 同步dotfile到github我们所做的编辑都只是在本地的working copy，想要在其他的设备上使用，首先要同步到github上，chezomi 把这个权利交给了git，我们可以首先 chezmoi cd 进入到 working copy的文件夹，然后就和普通的git操作一致了： git status 来看working copy 工作区的文件状态 git add 来把修改过后的dotfile添加到git缓冲区 git commit push 提交dotfile 和push dotfile到github 当然你也可以直接使用chezmoi git 来进行git的相关操作而不用进入文件夹。 在其他设备上使用dotfiles我们维护了dotfiles repo之后，以后我们到其他的设备上初始化的时候直接 chezmoi init --apply username即可，chezmoi会自动到github名字为username的repo下寻找dotfiles的repo来进行初始化，叫这个名字是为了使用方便，也可以使用其他名字，在其他设备上初始化的时候，需要指定github repo的全地址：chezmoi init https://github.com/username/dotfiles.git 管理可执行Script除了dotfiles 我们一般在开发的过程中会有一些script需要，在各个设备上运行，这个时候就可以设置script，chezmoi的script是在source 文件夹（~/.local/share/chezmoi）以 run_ 开头的文件，chezmoi会以按照字母顺序执行，其中，run_once_开头的会执行一次，run_onchange_会在每次文件内容有变化的时候执行。具体参考：Use scripts to perform actions - chezmoi 结语这篇文章只是简单的介绍基本使用，除此之外，还支持 template操作，它可以帮你管理设备之间的差异，还支持多种密码管理器，支持外部文件（比如.oh-my-zsh 以及插件等），可以参考：Command overview - chezmoi 获取更多信息。 最后放上我的dotfile仓库：Hank’s dotfiles Reference chezmoi - chezmoi [[使用chezmoi管理dotfiles]]","tags":["dotfiles","chezmoi"],"categories":["工具效率"]},{"title":"理解Jvm Class文件结构","path":"/2022/07/31/java-hello-world-in-byte/","content":"理解Jvm Class 文件结构Class 文件结构如下： ClassFile u4 magic; //Class 文件的标志\tu2 minor_version;//Class 的小版本号\tu2 major_version;//Class 的大版本号\tu2 constant_pool_count;//常量池的数量\tcp_info constant_pool[constant_pool_count-1];//常量池\tu2 access_flags;//Class 的访问标记\tu2 this_class;//当前类\tu2 super_class;//父类\tu2 interfaces_count;//接口\tu2 interfaces[interfaces_count];//一个类可以实现多个接口\tu2 fields_count;//Class 文件的字段属性\tfield_info fields[fields_count];//一个类可以有多个字段\tu2 methods_count;//Class 文件的方法数量\tmethod_info methods[methods_count];//一个类可以有个多个方法\tu2 attributes_count;//此类的属性表中的属性数\tattribute_info attributes[attributes_count];//属性表集合 下面的这个图更加直观： 使用010 Editor 打开 Hello.class 可以更加直观的查看 首先创建一个简单的Hello Word程序： public static void main(String[] args)\tSystem.out.println(Hello World); 然后使用 javap -v Hello.class 来将字节码文件生成反汇编文件如下： Classfile /Users/xuan/IdeaProjects/learn-spring/target/classes/Hello.class Last modified 2022年7月31日; size 548 bytes SHA-256 checksum eaba6958496d3a0d5605df6adb13ad3af4d3c5939bf1244f38b255637eec3c89 Compiled from Hello.javapublic class Hello minor version: 0 major version: 52 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #5 // Hello super_class: #6 // java/lang/Object interfaces: 0, fields: 0, methods: 2, attributes: 1Constant pool: #1 = Methodref #6.#21 // java/lang/Object.init:()V #2 = Fieldref #22.#23 // java/lang/System.out:Ljava/io/PrintStream; #3 = String #24 // Hello World #4 = Methodref #25.#26 // java/io/PrintStream.println:(Ljava/lang/String;)V #5 = Class #27 // Hello #6 = Class #28 // java/lang/Object #7 = Utf8 init #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 LHello; #14 = Utf8 main #15 = Utf8 ([Ljava/lang/String;)V #16 = Utf8 args #17 = Utf8 [Ljava/lang/String; #18 = Utf8 MethodParameters #19 = Utf8 SourceFile #20 = Utf8 Hello.java #21 = NameAndType #7:#8 // init:()V #22 = Class #29 // java/lang/System #23 = NameAndType #30:#31 // out:Ljava/io/PrintStream; #24 = Utf8 Hello World #25 = Class #32 // java/io/PrintStream #26 = NameAndType #33:#34 // println:(Ljava/lang/String;)V #27 = Utf8 Hello #28 = Utf8 java/lang/Object #29 = Utf8 java/lang/System #30 = Utf8 out #31 = Utf8 Ljava/io/PrintStream; #32 = Utf8 java/io/PrintStream #33 = Utf8 println #34 = Utf8 (Ljava/lang/String;)V public Hello(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.init:()V 4: return LineNumberTable: line 1: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this LHello; public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: (0x0009) ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=1, args_size=1 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #3 // String Hello World 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 3: 0 line 4: 8 LocalVariableTable: Start Length Slot Name Signature 0 9 0 args [Ljava/lang/String; MethodParameters: Name Flags argsSourceFile: Hello.java Reference The Java® Virtual Machine Specification","tags":["jvm"],"categories":["技术随笔"]},{"title":"SpringBoot是如何启动的？","path":"/2022/06/05/spring-bootstrap-source-code/","content":"Spring Boot 启动SpringBoot的启动类很简单，只需要调用SpringApplication的run方法即可，这篇文章来分析一下SpringBoot的启动类SpringApplication初始化的过程。 public static void main(String[] args) SpringApplication.run(Application.class, args); 在SpingApplication 中 初始化了一个SpringApplication, 参数是当前SpringBoot启动的类 public static ConfigurableApplicationContext run(Class?[] primarySources, String[] args) return new SpringApplication(primarySources).run(args); SpringApplication初始化 从classpath推断 webApplicationType 设置Initializers 设置Listeners 推断main class,主要用于log print以及banner print public SpringApplication(ResourceLoader resourceLoader, Class?... primarySources) this.resourceLoader = resourceLoader; Assert.notNull(primarySources, PrimarySources must not be null); this.primarySources = new LinkedHashSet(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); 推断webApplicationType从classpath推断 webApplicationType , 主要有三种，NONESERVLETREACTIVE默认情况下是SERVLET，也就是说Springboot会默认启动一个embed的tomcat服务器，用的也是最广泛的。 设置Initializers和Listeners设置Initializers和设置Liteners 都是通过spring.factories来加载的 从源码中分析 getSpringFactoriesInstancesprivate T CollectionT getSpringFactoriesInstances(ClassT type, Class?[] parameterTypes, Object... args) ClassLoader classLoader = getClassLoader(); // Use names and ensure unique to protect against duplicates SetString names = new LinkedHashSet(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); ListT instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; SpringFactoriesLoader.loadFactoryNames主要作用是从Springboot的jar包中加载 spring.factories文件 public static final String FACTORIES_RESOURCE_LOCATION = META-INF/spring.factories;private static MapString, ListString loadSpringFactories(@Nullable ClassLoader classLoader) MultiValueMapString, String result = cache.get(classLoader); if (result != null) return result; try EnumerationURL urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); result = new LinkedMultiValueMap(); while (urls.hasMoreElements()) URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry?, ? entry : properties.entrySet()) String factoryTypeName = ((String) entry.getKey()).trim(); for (String factoryImplementationName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) result.add(factoryTypeName, factoryImplementationName.trim()); cache.put(classLoader, result); return result; catch (IOException ex) throw new IllegalArgumentException(Unable to load factories from location [ + FACTORIES_RESOURCE_LOCATION + ], ex); 使用Classloader 从FACTORIES_RESOURCE_LOCATION加载Resource，然后根据resource来解析成为Properties文件，然后再解析成Map. createSpringFactoriesInstances这一步的目的是根据上一步load出来的Class来创建Factory实例，使用反射的方式进行创建 private T ListT createSpringFactoriesInstances(ClassT type, Class?[] parameterTypes, ClassLoader classLoader, Object[] args, SetString names) ListT instances = new ArrayList(names.size()); for (String name : names) try Class? instanceClass = ClassUtils.forName(name, classLoader); Assert.isAssignable(type, instanceClass); Constructor? constructor = instanceClass.getDeclaredConstructor(parameterTypes); T instance = (T) BeanUtils.instantiateClass(constructor, args); instances.add(instance); catch (Throwable ex) throw new IllegalArgumentException(Cannot instantiate + type + : + name, ex); return instances; 默认的Spring boot包中的spring.factories中有5个initializer，spring boot autoconfig 中有2个initializer 推断包含main方法的主类主要是根据StackTrace遍历当前的方法调用栈拿到主类。 SpringApplication Run 方法解析public ConfigurableApplicationContext run(String... args) long startTime = System.nanoTime(); DefaultBootstrapContext bootstrapContext = createBootstrapContext(); ConfigurableApplicationContext context = null; configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(bootstrapContext, this.mainApplicationClass);\ttry ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] ConfigurableApplicationContext.class , context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); listeners.started(context); callRunners(context, applicationArguments); catch (Throwable ex) handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); return context; createBootstrapContextBootstrapContext的主要作用是在ApplicationContext prepared之前提供singletons的lazy access活着是共享给其他类访问。 在ApplicationContext prepared完成 [[Spring Boot 初始化#prepareContext]]之后BootstrapContext就会被close掉，然后广播一个BootstrapContextClosedEvent给到其他Bean prepareEnvironment 根据webApplicationType创建Environment 配置Environment attach ConfigurationPropertySource也就是ConfigurationProperties到environment 给SpringApplicationRunListener 广播environmentPrepared的Event Bind Environment to Spring Application private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) // Create and configure the environment ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); ConfigurationPropertySources.attach(environment); listeners.environmentPrepared(environment); bindToSpringApplication(environment); if (!this.isCustomEnvironment) environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); ConfigurationPropertySources.attach(environment); return environment; create Environment根据applicationType来判断初始化哪个Environment private ConfigurableEnvironment getOrCreateEnvironment() if (this.environment != null) return this.environment; switch (this.webApplicationType) case SERVLET: return new StandardServletEnvironment(); case REACTIVE: return new StandardReactiveWebEnvironment(); default: return new StandardEnvironment(); Create ContextSpringBoot默认创建的是 AnnotationConfigApplicationContext protected ConfigurableApplicationContext createApplicationContext() Class? contextClass = this.applicationContextClass;\tif (contextClass == null) try switch (this.webApplicationType) case SERVLET: contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); catch (ClassNotFoundException ex) throw new IllegalStateException( Unable create a default ApplicationContext, please specify an ApplicationContextClass, ex); return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass); 初始化AnnotationConfigApplicationContext的过程中做了这么几件事情： 初始化DefaultListableBeanFactoryAnnotationConfigApplicationContext继承了GenericApplicationContext ，所以默认构造器会自动创建DefaultListableBeanFactory的实例，以供后面register beanDefinition和生成bean使用。 初始化 AnnotatedBeanDefinitionReader 处理 @Conditional 注解 AnnotationConfigUtils.registerAnnotationConfigProcessors() 注册几个处理注解Processors的BeanDefinition到BeanFactory的BeanDefinationMap中，这个是为了在refresh的过程中处理Configuration Class，也就是常说的配置类，这几个Processor分别是： ConfigurationClassPostProcessor 用来解析带有@Configuration的类，这个可以参考我之前的文章：ConfigurationClassPostProcessor处理BeanDefinition解析 AutowiredAnnotationBeanPostProcessor 用来解析Autowired注解，InstantiationAwareBeanPostProcessor，这个特殊的BPP几乎就是在Spring框架内部使用的接口，主要用来处理代理对象或者需要Lazy init的对象的场景使用。 CommonAnnotationBeanPostProcessor，也是一个InstantiationAwareBeanPostProcessor，这个BPP主要用来解析JSR-250注解，比如@PostConstruct,@PreDestry等等 PersistenceAnnotationBeanPostProcessor也是一个InstantiationAwareBeanPostProcessor,主要是支持JPA的 @PersistenceContext和@PersistenceUnit注解 EventListenerMethodProcessor 主要功能把注册在方法上的@EventListener生成独立的ApplicationListener实例，实现Spring的事件驱动。 DefaultEventListenerFactory 结合上面的EventListenerMethodProcessor一起来看，主要是为生成ApplicationListener实例提供默认的工厂方法。 初始化 ClassPathBeanDefinitionScanner set environment set Resource loaders prepareContext 准备springboot应用的上下文 set environment 绑定environment到Context postProcessApplicationContext registerBeanNameGenerator 可以自定义Bean名字 set resource loader set conversion Service 这里用到了DCL 单例模式 applyInitializers Add boot specific singleton beans springApplicationArguments spring bootBanner 处理lazy-initialization load beanDefinition到context中 这里面最重要一步是创建BeanDefinitionLoader，BeanDefinitionLoader是springboot的一个加载BeanDefinition的Loader，它可以加载各种各样形式的source，比如package, Configuration class, xml文件,groovy bean等 BeanDefinitionLoader(BeanDefinitionRegistry registry, Object... sources) Assert.notNull(registry, Registry must not be null); Assert.notEmpty(sources, Sources must not be empty); this.sources = sources; this.annotatedReader = new AnnotatedBeanDefinitionReader(registry); this.xmlReader = new XmlBeanDefinitionReader(registry); if (isGroovyPresent()) this.groovyReader = new GroovyBeanDefinitionReader(registry); this.scanner = new ClassPathBeanDefinitionScanner(registry); this.scanner.addExcludeFilter(new ClassExcludeFilter(sources)); BeanDefinitionLoader的作用就是循环各个 sources 然后创建对应的BeanDefinition然后load到applicationContext 中，解析注解配置的类可以参考之前的文章Spring加载BeanDefinition源码解析 | Hank’s Blog refreshContext上面的阶段只是把bean Definition加载进了context，到了refresh阶段了才会真正生成bean实例，这里spring boot做的工作基本上就结束了，接下来就要交给spring 底层了。 refresh的主要代码在AbstractApplicationContext的refresh方法中，这个后面会专门再写一篇文章。 References GitHub - spring-projectsspring-boot: Spring Boot GitHub - spring-projectsspring-framework: Spring Framework Core Technologies","tags":["java/spring","源码分析"],"categories":["源码解析"]},{"title":"Spring是如何加载BeanDefinition的？","path":"/2022/06/02/spring-load-bean-definition/","content":"Spring Bean生命周期中，BeanDefinition是最重要的部分，在初始化和实例化Bean之前，首先要把所有的需要Spring管理的Bean对应的BeanDefinition加载到Spring容器中，这一步非常关键，因为BeanDefinition是Bean关联的元数据，这一篇文章就以AnnotationConfigApplicationContext来分析一下Spring容器是如何加载BeanDefinition的。 第一阶段：扫描Class文件加载BeanDefinitionpublic AnnotationConfigApplicationContext(String... basePackages) this(); scan(basePackages); refresh(); 我们先以package的方式来分析，初始化AnnotationConfigApplicationContext的时候会scan对应的包路径，然后进行refresh scan的动作是在ClassPathBeanDefinitionScanner的doScan方法中完成的,主要任务是查找classpath下面的Class文件，判断是否为Bean，然后生成BeanDefinition。 主要源码为： protected SetBeanDefinitionHolder doScan(String... basePackages) SetBeanDefinitionHolder beanDefinitions = new LinkedHashSet(); for (String basePackage : basePackages) SetBeanDefinition candidates = findCandidateComponents(basePackage); for (BeanDefinition candidate : candidates) ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); if (candidate instanceof AbstractBeanDefinition) postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); if (candidate instanceof AnnotatedBeanDefinition) AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); if (checkCandidate(beanName, candidate)) BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); registerBeanDefinition(definitionHolder, this.registry); return beanDefinitions; 查找候选Component的BeanDefinition集合这部分代码主要在ClassPathScanningCandidateComponentProvider 将包名转换为path, 通过ResourcePatternResolver来解析得到Class文件的Resource列表， 这里使用了Strategy模式来解析不同类型的资源。 遍历Resource List通过ASM技术将Resource封装为MetadataReader, 这里不使用反射是为了减少内存占用，使用反射必须先将Class文件Load进JVM中，这里使用了Factory模式 来获取MetadataReader 判断是不是候选Component, 首先判断是不是在excludeFilters里，如果在excludeFilters里直接返回false 判断是不是在includeFilters里，如果在includeFilters里，返回true，否则返回false 在创建AnnotationConfigApplicationContext的时候默认加载几个DefaultIncludeFilter, 也就是有@Component注解或者JSR-250注解 @javax.inject.Named 或者javax.annotation.ManagedBean, 在这里@Service 和@Controller都是有@Component，所以也都会被扫描到。 创建ScannedGenericBeanDefinition 它的作用是 保存ASM 扫描出来的注解元数据信息 根据AnnotatedBeanDefinition判断是不是一个Component 独立类，不能是内部类，可以是嵌套类 非抽象类或者接口 有Lookup方法的抽象类 遍历符合条件的Component的BeanDefinition集合 解析ScopeMetadata,默认是Singleton,ScopedProxyMode是NO，ScopedProxyMode主要是非单例的Scope上使用，可以配置使用CGlib代理或者JDK动态代理 使用BeanNameGenerator生成BeanName，这里使用了Singlenton模式, 如果注解上有beanName就使用注解上的，没有的话就根据类名生成一个BeanName 如果是AbstractBeanDefinition则给BeanDefinition设置默认属性 如果是AnnotatedBeanDefinition则解析Component上的注解比如@Lazy，@Primary等属性到BeanDefination中 检查Component, 判断容器中是不是已经存在这个Bean,如果存在，则判断对象是不是相等，如果不相等说明不合法，Spring抛出ConflictingBeanDefinitionException中断加载。 创建BeanDefinitionHolder，主要是为了保存alias，默认alias为空 将beanDefinition注册到容器中，如果alias不为空，给bean注册alias，这里默认不注册 第二阶段：refresh过程中加载BeanDefinitionscan这一步，加载了classpath中的BeanDefinition，但是这一步只是最基础的，Spring容器在refresh阶段也留给用户一个hook方法，让用户在生成Bean之前能够自己操作BeanDefinition，这个hook就是BeanDefinitionRegistryPostProcessor我们可以自己自定义一个类实现它来自定义处理BeanDefinition。Spring内部也有一些内置的BeanDefinitionRegistryPostProcessor，比如处理@Configuration的ConfigurationClassPostProcessor，Configuration Class中一般都会包含不少配置信息，比如@Import，@Bean等，我们就需要在bean实例化之前加载进Spring容器。 那么Configuration Class是什么时候处理的呢？ 答案是在 refresh阶段的invokeBeanFactoryPostProcessors中，主要源代码在下面PostProcessorRegistrationDelegate中的invokeBeanFactoryPostProcessors方法中。 因为ConfigurationClassPostProcessor实现了BeanDefinitionRegistryPostProcessor接口，所以会在这一步被调用，进而对ConfigurationClass进行解析。 ConfigurationClassPostProcessor处理BeanDefinition解析 public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) int registryId = System.identityHashCode(registry); if (this.registriesPostProcessed.contains(registryId)) throw new IllegalStateException( postProcessBeanDefinitionRegistry already called on this post-processor against + registry); if (this.factoriesPostProcessed.contains(registryId)) throw new IllegalStateException( postProcessBeanFactory already called on this post-processor against + registry); this.registriesPostProcessed.add(registryId); processConfigBeanDefinitions(registry); 其中processConfigBeanDefinitions 来处理ConfigBean，最重要的逻辑代码在 ConfigurationClassParser的parse ConfigurationClassParser 解析 和doProcessConfigurationClass方法中, 这个方法会处理main class上面的annotation，比如Component，ComponentScan等 processConfigBeanDefinitions在ConfigurationClassPostProcessor#postProcessBeanDefinitionRegistry里面主要就是扫描BeanDefinitionRegistry 处理里面的有@Configuration的类。 public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) for (String beanName : candidateNames) BeanDefinition beanDef = registry.getBeanDefinition(beanName); //1. 校验是不是@Configuration标注的Class，是的话放入configCandidates中 if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) configCandidates.add(new BeanDefinitionHolder(beanDef, beanName)); //2. 创建 ParserConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry);do//3. parse Config类parser.parse(candidates); parser.validate(); SetConfigurationClass configClasses = new LinkedHashSet(parser.getConfigurationClasses());//4.加载BeanDefinitionthis.reader.loadBeanDefinitions(configClasses); while(!candidates.isEmpty()); 主要抽象成4步 校验是不是@Configuration标注的Class，是的话放入configCandidates中 创建 ConfigurationClassParser parse ConfigurationClass 加载BeanDefinition 加载BeanDefinition源码在ConfigurationClassBeanDefinitionReader#loadBeanDefinitionsForConfigurationClass 主要步骤为 TrackedConditionEvaluator判断是否应该skip 注册import的class的BeanDefinition 注册@Bean标注的method 注册imported的resources的BeanDefinition, 比如说 importXML等 注册ImportBeanDefinitionRegistrar ，比如说各种@EnableXXX private void loadBeanDefinitionsForConfigurationClass( ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) if (trackedConditionEvaluator.shouldSkip(configClass)) String beanName = configClass.getBeanName(); if (StringUtils.hasLength(beanName) this.registry.containsBeanDefinition(beanName)) this.registry.removeBeanDefinition(beanName); this.importRegistry.removeImportingClass(configClass.getMetadata().getClassName()); return; if (configClass.isImported()) registerBeanDefinitionForImportedConfigurationClass(configClass); for (BeanMethod beanMethod : configClass.getBeanMethods()) loadBeanDefinitionsForBeanMethod(beanMethod); loadBeanDefinitionsFromImportedResources(configClass.getImportedResources()); loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars()); 这里就看到了Spring boot中常见的ImportBeanDefinitionRegistrar的身影， 一般搭配XXXAuthConfiguration，@ConditionalOnClass 实现Springboot的自动装配功能。 References Spring Reference Core Technologies GitHub - spring-projectsspring-framework: Spring Framework","tags":["java/spring","源码分析"],"categories":["源码解析"]},{"title":"微信读书Obsidian实现二维码扫描登录","path":"/2022/05/24/weread-qrcode-login-in-obsidian/","content":"背景前几天写了个Obsidian微信读书的插件GitHub - zhaohongxuanobsidian-weread-plugin，在B站上发了一个视频学了3天typescript写了一个微信读书的Obsidian插件_哔哩哔哩，最初版本是需要手动从控制台复制Cookie设置到设置界面才能使用的，很多B站网友给我私信说获取Cookie有问题，虽然在readme里已经写的很清楚了，但是对小白来说可能这也是个比较困难的步骤，所以我在想是否可以实现二维码扫码登录呢？ 思路因为Obsidian其实也是个浏览器，所以理论上是可以打开浏览器窗口来展示扫码登录界面的。只要load到微信读书的扫码登录界面，然后intercept到请求的header拿到Cookie就可以了，然后后续只要被动刷新Cookie有效期即可。 所以问题就被分成了三部分： 展示二维码扫码框 intercept 登录操作获取到Cookie 将Cookie设置到setting 中 步骤那么如何load微信读书扫码登录页面呢？用electron的BrowserWindow 然后loadURL打开https://r.qq.com#login界面即可展示扫码框。 如何intercept获取到Cookie呢？在上篇微信读书Cookie分析 [[2022-05-16-how-to-relong-cookies-in-weread]]的文章里，我已经把微信读书Cookie的机制研究了一遍。在登录之前，本地已经有Cookie了，只不过关于用户相关的字段都是空的： 在登录完成的时候，[初始化会话](https://weread.qq.com/web/login/session/init) 只会获取到4个set-cookie的值，然后调用 https://weread.qq.com/web/user?userVid=xxx 再去查一次用户信息把用户信息放入Cookie中。 所以解法变成了intercept用户信息api拿到用户信息自己组装Cookie，但是在实战过程中发现使用eletron的webRequest获取到网络请求的body非常困难，还需要开启debugger才能使用，所以我放弃了。 换个思路，从request header头上找到Cookie不就行了吗？ 但是在扫码登录的session里面，请求任何页面Cookie都是不完整的，除非等到加载用户信息完成之后Cookie才会被补充完整，这个时候再去请求接口的时候Cookie就是完整的。所以解题思路就来了，我们再扫码完成回调之后 reload下页面不就好了吗？ 代码比我想想中的要简单太多了： const session = this.modal.webContents.session;\tconst filter = urls: [https://weread.qq.com/web/user?userVid=*]\t;\tsession.webRequest.onSendHeaders(filter, (details) = const cookies = details.requestHeaders[Cookie]; const cookieArr = parseCookies(cookies); const wr_name = cookieArr.find((cookie) = cookie.name == wr_name).value; if (wr_name !== ) settingsStore.actions.setCookies(cookieArr); settingTab.display(); this.modal.close(); else this.modal.reload(); ); 在intercept https://weread.qq.com/web/user?userVid= 的时候判断下Cookie中wr_name字段是不是有值就可以了，没有值说明是第一次加载，就原地reload一次，第二次request header里Cookie就是完整的了，这个时候就可以关掉登录窗口了，登录完成。 这个过程中，在登录窗口关闭之前会有一次刷新操作，不过因为时间非常短，所以这个过程对用户是几乎无感的。 Reference BrowserWindow | Electron Class: WebRequest | Electron 微信读书Cookie自动延期机制分析 | Hank’s Blog GitHub - zhaohongxuanobsidian-weread-plugin","tags":["obsidian","二维码登录","electron","BrowserWindow"],"categories":["obsidian"]},{"title":"微信读书Cookie自动延期机制分析","path":"/2022/05/16/how-to-relong-cookies-in-weread/","content":"HTTP Cookie（也叫 Web Cookie 或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的HTTP协议记录稳定的状态信息成为了可能。 分析Cookie登录之前在进入到weread.qq.com的时候，就已经存在Cookie信息了，只不过一部分的Cookie信息是空的，下面是扫码登录之前的Cookie信息： 扫码登录微信读书网页版获取Cookie的流程 获取用户uid ，https://weread.qq.com/web/login/getuid，前端js生成一个uid，这个机制不清楚。 获取登录用户扫码信息，https://weread.qq.com/web/login/getinfo，这个请求会一直pending，直到你扫码，然后获取到用户信息。 网页登录，https://weread.qq.com/web/login/weblogin，使用第二步的获取到网页信息之后会立即进行登录。 session初始化，https://weread.qq.com/web/login/session/init，根据登录的信息初始化session，然就返回4个httpOnly的cookie信息，httpOnly的cookie信息不能通过`document.cookie` 这个也解释了之前在console中获取的cookie无法正常使用的问题。可以看到wr_skey的有效期只有5400秒，过了这个有效期，调用API接口会响应401，所以关键信息也就是如何更新这个wr_skey是关键。 获取用户信息， https://weread.qq.com/web/user?userVid=xxx 这里会根据uid查询用户的基本信息，然后放入Cookie中。 延长Cookie在cookie过期的时候刷新一下网页发现服务器都会自动返回set-cookie字段来更新wr_skey字段以及有效期。 解决方案根据时间刷新 在middle server中增加代理/refresh，重定向https://weread.qq.com用来刷新Cookie 设置完Cookie的时候，保存Cookie的存储时间 点击同步按钮的时候校验Cookie的存储时间，超过1个小时，则调用refresh刷新Cookie，超过一个小时会请求一次首页，获取set-cookie中新的cookie字段。 const app = express(); this.app.use(\t/refresh,\tcreateProxyMiddleware( target: https://weread.qq.com, changeOrigin: true, pathRewrite: ^/refresh: / , onProxyReq: function (proxyReq, req, res) const cookie = getEncodeCookieString(); proxyReq.setHeader(Cookie, cookie); , onProxyRes: function (proxyRes, req, res: ServerResponse) proxyRes.headers[Access-Control-Allow-Origin] = *; proxyRes.headers[Access-Control-Allow-Methods] = *; const respCookie: string[] = proxyRes.headers[set-cookie]; if (respCookie) updateCookies(respCookie); )); 使用axios来访问/refresh endpoint,这里使用head方法就够了，只需要获取head里的set cookie字段而已，不需要使用get方法获取整个html文档，使用get会降低请求速度。 async refreshCookie() try await axios.head(this.baseUrl + /refresh); catch (e) console.error(e); new Notice(刷新Cookie失败); 根据401报错重试如果在使用Obsidian的过程中，又在其他浏览器里刷新了微信读书的页面，会导致Obsidian的Cookie提前失效，这个时候Obsidian中在进行同步会发生401报错。 这里我在middle server中代理返回401的时候刷新cookie，同时在获取getNotebook的时候设置401重试，这样就算在别的浏览器里登录，Obsidian也会自动进行Cookie刷新，不让用户察觉到Cookie的存在。 const app = express();this.app.use( /, createProxyMiddleware( target: https://i.weread.qq.com, changeOrigin: true, onProxyReq: function (proxyReq, req, res) try const cookie = getEncodeCookieString(); proxyReq.setHeader(Cookie, cookie); catch (error) new Notice(cookie 设置失败，检查Cookie格式); , onProxyRes: function (proxyRes, req, res: ServerResponse) if (proxyRes.statusCode == 401) refreshCookie(true); else if (proxyRes.statusCode != 200) new Notice(获取微信读书服务器数据异常！); proxyRes.headers[Access-Control-Allow-Origin] = *; proxyRes.headers[Access-Control-Allow-Methods] = *; )\t); Reference HTTP cookies","tags":["obsidian","微信读书","cookie"],"categories":["obsidian"]},{"title":"使用Middle Server解决浏览器CORS跨域问题","path":"/2022/05/12/How to resolve CORS problem/","content":"问题产生最近学了Typescript写了一个Obsidian微信读书的插件Obsidian Weread Plugin，在写插件的过程中需要跨域请求r.qq.com来获取微信读书的书摘和想法。 使用axios在vscode中运行api测试的时候是好的，在obsidian中产生了CORS的问题，这是因为Obsidian本质上是一个Electron的app，本质上也是一个浏览器，所以才会出现跨域问题。 关于CORS的文章已经很多了，推荐参考Mozila CORS，作为一个后端开发，CORS 并不陌生，，对于Spring全家桶用户来说，就是几行@CrossOrigin的配置问题，但是这一篇文章提供的是前端视角来解决CORS的思路，也就是说对服务端不可控时如何处理？ 解决思路我们都知道CORS本身只是对浏览器才会限制，所以可以跳出来使用代理服务器来解决问题，这里刚开始，我建立了一个Springboot的Web项目专门转发来自Obsidian的请求，将请求转发到r.qq.com，这样能够正常工作，但是也印出来了另外一个问题： 每次使用Weread插件的时候，我都需要把SpringBoot项目启动起来，显然不够优雅。特别是后面插件上架了Obsidian的社区市场之后肯定更不行，你不可能要求用户自己再额外下载一个服务器来运行。 那么是否可以找到一个可以在前端使用的middle server呢？ 答案是可以！那就是http-proxy-middleware 解决方法Http Proxy Middleware它是基于node开发的简单的中间层代理，搭配express使用非常简单，完全服务我的需求：在Obsidian中启动Weread Plugin同步任务的时候，首先启动server，绑定一个端口 当用户在obsidian里点击同步的时候，实际上在所有的网络请求之前我会启动一个middle server，然后绑定到一个端口，这里写的是12011，然后实现onProxyRes方法，将服务器返回的Access-Control-Allow-Origin设置为*，然后插件认为没有跨域，所以能够正常和微信阅读服务器进行通讯。 这里由于微信读书API只能通过cookie的方式来进行认证，所以将setting中的cookie设置到proxyReq上面，这样就模拟了网页端的请求。 async startMiddleServer(app: any): PromiseServer const cookie = this.settings.cookie; if (cookie === undefined || cookie == ) new Notice(cookie未设置，请填写Cookie); const escapeCookie = this.escapeCookie(cookie); app.use( /, createProxyMiddleware( target: https://i.weread.qq.com, changeOrigin: true, onProxyReq: function (proxyReq, req, res) try proxyReq.setHeader(Cookie, escapeCookie); catch (error) new Notice(cookie 设置失败，检查Cookie格式); , onProxyRes: function (proxyRes, req, res: ServerResponse) if (res.statusCode != 200) new Notice(获取微信读书服务器数据异常！); proxyRes.headers[Access-Control-Allow-Origin] = *; ) ); const server = app.listen(12011); return server; 在进行API调用的时候绑定到上面的代理端口12011上。 readonly baseUrl: string = http://localhost:12011;async getWereadNotebooks() try let noteBooks = []; const resp = await axios.get(this.baseUrl + /user/notebooks, ); noteBooks = resp.data.books; return noteBooks; catch (e) new Notice( Failed to fetch weread notebooks . Please check your Cookie and try again. ); 在同步任务结束的时候，调用server的close方法，关闭掉代理服务器，这样就完成了一次同步。 async startSync(app: any) new Notice(start to sync weread notes!);\tthis.startMiddleServer(app).then((server) = console.log(Start syncing Weread note...); this.syncNotebooks.startSync().then((res) = server.close(() = console.log(HTTP server closed , res, server); ); new Notice(weread notes sync complete!); );\t); 这样代理服务器仅仅会在程序运行的时候启动，不会一直在后台耗着占用我们的CPU资源，算是一种比较完美的解决方案。 References https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS https://github.com/chimurai/http-proxy-middleware","tags":["obsidian","cors","http","midderServer"],"categories":["obsidian"]},{"title":"10款插件让你的Obsidian更加好用","path":"/2022/05/05/Awesome Obsidian plugins I use/","content":"Obsidian 是一款非常优秀的双链笔记软件，用它可以很方便的来管理自己的笔记，打造自己的数字花园（Digital Garden），虽然和Roam等纯粹的Outliner型笔记不太一样，它基于纯文本md文件，且支持文件夹，给了一些用户选择的自由，最重要的是启动速度很快（特别是和Notion相比，虽然是基于Electron的，不知道用了什么黑魔法） 同时Obsidian也是一款非常好用的写作软件，支持Live Preview的模式，类似于Typora的效果，个人感觉体验很好。 Obsidian是以Plugin化的形式设计的，很多核心的功能也都是以Plugin的形式出现的，这给了用户自由定制的空间，当然这也提高了上手的难度，无形中劝退了不少人，但是Plugin的形式会让这个软件生命力得到释放，社区的优秀的插件数量很多，用户可以根据自己的喜好自己定制自己的Obsidian，我想这也是Obsidian最吸引人的地方之一。 下面就介绍10款我平时用的最多的第三方插件，可以让你的Obsidian更加易用。 外观插件 HiderObsidian官方主题是在是有点丑，我这边使用排名第一个主题 Minimal Theme 简约大气，使用Hider搭配这个主题可以隐藏掉界面上不想看到的元素，比如vault name， title bar等，搭配Minimal Theme简直完美 Obsidian File Explorer Count顾名思义，就是在Obsidian的文件管理器上显示笔记的数量，很直观建议安装。 绘图插件ExcaliDraw免费的手绘白板软件，一些简单的绘图可以用它来画，很有质感，搭配Obsidian很有质感，间接省了一个ipad和还有一支笔。 DiagramDiagram是在Obsidian上的drawio1 ，drawio是我最喜欢的开源流程图工具，使用jira的人肯定对这个工具不陌生， 图片是svg格式的，在Obsidian里可以直接使用![[]] 引用在正文中显示。 PlantumlPlantuml2 是开源的文本绘图工具，可以直接使用代码块来进行绘图，搭配上面的drawio来说基本上已经满足所有的绘图需求。 效率提升插件QuickAdd这个插件，可以让我们预定义一些快捷的指令来记录一些具体格式的内容，也可以用它可以capture内容到指定文件，这个功能应该是借鉴于 Emacs 的 org-mode。可以用它来记录闪念笔记，也可以指定模板来快速生成Blog，可以用它来帮你配置更多高级的功能。 可以点击How to use QuickAdd for Obsidian - with examples进一步学习使用。 Tasks可以使用query来查询散落在各个页面中的task也就是todo，这样就可以无拘束的在各个页面写下自己要做的事情，心智负担为0 比如可以展示出来我的write的tasks Image auto upload Plugin这个插件配合Picgo3 很方便的在Obsidian里插入图片，自动上传到图床，让markdown配图变成一件简单的事情，尤其是对写Blog而言。 笔记插件Random Note这个经常用到，在复习笔记的时候很有用，点击之后会随机打开一篇笔记，类似维基百科的随机条目，对于庞大的笔记系统来说可以说是必备的插件。 Hypothsis主要用来管理网页上的标柱信息，能够很方便的将网页上的高亮文本同步到Obsidian中，还可以自己写备注信息，添加标签等，可以很有效的捕捉上网的时候的灵感。 Reference https://github.com/jgraph/drawio https://github.com/plantuml/plantuml https://github.com/Molunerfinn/PicGo https://github.com/chhoumann/quickadd https://sspai.com/post/69375 https://catcoding.me/p/obsidian-for-programmer/","tags":["tools/obsidian"],"categories":["obsidian"]},{"title":"在Obsidian中写Hexo Blog","path":"/2022/05/03/how-to-write-blog-in-obsidian-using-hexo/","content":"背景Obsidian目前是我的主力笔记软件，Hexo是我的Blog的Github Pages引擎。孟子曰： 鱼，我所欲也；熊掌，亦我所欲也。二者不可得兼。 虽说二者不可兼得，但是程序员思维总是会指导我：必定有一个方案可以解决这个问题，如果没有那那就创造一个。 在没有Obsidian之前我写Blog的流程是直接在VSCode中打开zhaohongxuan.github.io文件夹，然后编辑md文件，提交到Github然后自动生成Github Pages. 在使用Obsidian之后我会现在Obsidian中建立相关的页面，然后编辑完成之后copy到zhaohongxuan.github.io文件夹，提交到github, 这就导致了一个心智负担：每次都得做重复的工作，copy文件，然后提交代码，间接导致了我不想写Blog（逃。 如何才能在愉快的一边在Obsidian里写笔记一边还能无缝发布Blog呢？ 我的想法是通过同步Obsidian的Blog目录里的文件sync到我们的Github Pages Blog目录，然后在git commit push来间接达到我们的目的。 这里sync操作可以使用rsync命令1来解决，rsync是一个非常厉害的命令，这里只是用到了最基本的操作，也就是覆盖式同步。 优点：只使用git管理 GitHub Pages, 其他的md文件还是通过云盘来同步，虽然拉跨，但是在iPhone和iPad上使用省心不少。 缺点：需要在每个电脑上配置一个脚本来进行rsync操作，Mobile端一般也不会写Blog，所以不需要配置这个脚本。所以这里选择了第二个思路来达到我的目的。 同步Obsidian的Blog文件夹到Hexo Blog的_post文件夹使用rsync命令，一般的linux发行版上都会自带这个命令的，需要注意的是如果要覆盖是更新，记得要加上--delete 2 rsync -avu --delete ~/Library/Mobile\\ Documents/iCloud~md~obsidian/Documents/xuan/Blog/ ~/VSCodeProjects/zhaohongxuan.github.io/source/_posts/ 将变化的post提交到github这一步需要进入到Github Page的目录，我这里用的是Hexo blog，然后添加所有的md文件，提交到Github cd ~/VSCodeProjects/zhaohongxuan.github.io/git checkout src --forcecd source/_postsgit add .git commit -m Commit from Obsidiangit push 编写sh脚本预览Blog编写一个预览Blog的脚本sync-commit-obsidian.sh 同步blog文件到Blog文件夹 hexo server启动本地预览 打开浏览器预览blog #!/bin/shrsync -avu --delete ~/Library/Mobile\\ Documents/iCloud~md~obsidian/Documents/xuan/Blog/ ~/VSCodeProjects/zhaohongxuan.github.io/source/_posts/cd ~/VSCodeProjects/zhaohongxuan.github.iohexo serveropen http://localhost:4000 这个脚本可以放在一个固定文件夹里，我这里放到~/Developer/scripts/里，等下面Obsidian配置shell command的时候会用到。 发布Blog将脚本写入到一个sh文件里，sync-commit-obsidian-posts.sh 然后存放在一个目录里，我这里存放在~/Developer/scripts/下面 #!/bin/shrsync -avu --delete ~/Library/Mobile\\ Documents/iCloud~md~obsidian/Documents/xuan/Blog/ ~/VSCodeProjects/zhaohongxuan.github.io/source/_posts/cd ~/VSCodeProjects/zhaohongxuan.github.io/source/_posts/git add .git commit -m Commit from Obsidiangit push 在Obsidian中执行Shell命令在Community Plugins中搜索Shell Command插件，install 之后记得enable，在Shell Command的设置页面增加pub来进行blog publish，这里要记得绑定到你使用的shell上，比如zsh。 我这里会增加两个快捷命令 第一个是preview 第二个是publish 直接使用快捷键Command+P唤出command pelette输入preview即可本地预览，输入pub即可发布Blog，当然也可以绑定快捷键直接操作，在github上就能看到Github Page相关的action已经执行了，博客成功发布。 Reference rsync 用法教程 How to sync two folders with command line tools? https://forum.obsidian.md/t/mobile-setting-up-ios-git-based-syncing-with-mobile-app-using-working-copy/16499","tags":["linux/rsync obsidian"],"categories":["obsidian"]},{"title":"使用Yt-dlp高效下载Youtube的视频","path":"/2022/03/14/use-yt-dlp-download-youtube-videos/","content":"代理如果没有全局梯子的话，在命令行里就需要使用代理来下载。使用--proxy来指定代理，支持HTTP/HTTPS/SOCKS 等协议。 下载默认下载的视频格式是webm格式，如果需要转换可以使用--merge-output-format mp4 来转换，mp4可以指定为其他格式，比如mkv等，下载的文件名格式是 %(title)s [%(id)s].%(ext)s ，通过--output可以指定输出的文件名格式。 文件名的Template语法参考：https://github.com/yt-dlp/yt-dlp/blob/master/README.md#output-template 下载1080P视频+音频并合并yt-dlp -f bv[height=1080][ext=mp4]+ba[ext=m4a] https://www.youtube.com/watch?v=WHSoSAqOyPY 下载4K视频+音频合并yt-dlp -f bv[height=2160][ext=mp4]+ba[ext=m4a] --embed-metadata https://www.youtube.com/watch?v=WHSoSAqOyPY 下载列表默认输入视频URL带上list的话会自动下载list的 设置--playlist-start 1 来指定开 始的index，设置 --playlist-end 指定结束的index，--playlist-items 1,2,5-8 指定某一些item进行下载 yt-dlp -f bv+ba --embed-metadata --merge-output-format mp4 --playlist-items 1,2,6-10 -o %(playlist_index)s-%(playlist)s-%(title)s.mp4 https://www.youtube.com/watch\\?v\\=rY-7DtUFiEI\\list\\=PLJVKAfvqjvcofezOxMQaSHnO6HV84isXO 字幕操作--write-subs 把字幕写到磁盘上--sub-langs zh-Hans,en 多个语言使用逗号隔开，all下载全部语言--write-auto-subs 把自动生成的字幕写到磁盘上--embed-subs 把字幕嵌入视频文件中 通过--write-subs 把字幕写到磁盘上，--sub-langs zh-Hans,en 多个语言使用逗号隔开，all下载全部语言，--write-auto-subs 把自动生成的字幕写到磁盘上，--embed-subs 把字幕嵌入视频文件中下载视频带中英文字幕文件： yt-dlp https://www.youtube.com/watch?v=XiGk6PXt38wt=18s --sub-langs zh-Hans,en --write-subs --write-auto-subs --embed-thumbnail --write-thumbnail --write-link 综合操作下载最佳分辨率视频+音频+下载中英文字幕文件+转换为mp4+视频链接+缩略图 yt-dlp \\--format bv+ba \\ --write-auto-subs \\--sub-langs zh-Hans,en \\--write-link \\--write-thumbnail \\--embed-metadata \\--merge-output-format mp4 \\--output %(playlist_index)s-%(playlist)s-%(title)s.mp4 \\https://www.youtube.com/watch\\?v\\=rY-7DtUFiEI\\list\\=PLJVKAfvqjvcofezOxMQaSHnO6HV84isXO References https://github.com/yt-dlp/yt-dlp","tags":["tools/dlp"],"categories":["工具效率"]},{"title":"Spring Environment体系分析","path":"/2021/12/28/Spring Environment Analysis/","content":"Spring Environment 体系 Environment Interface representing the environment in which the current application is running. Models two key aspects of the application environment: profiles and properties. Methods related to property access are exposed via the PropertyResolver superinterface. Environment 继承自PropertyResolver 定义了应用运行环境的两大关键要素： profiles 和properties，其中properties接口通过父类的PropertyResolver 暴露接口. ApplicationContext负责将Environment给后面创建Bean来使用 public void setEnvironment(ConfigurableEnvironment environment) super.setEnvironment(environment); this.reader.setEnvironment(environment); this.scanner.setEnvironment(environment); 在对Bean进行操作的过程中，如果需要进行一些解析，会调用Environment对象进行操作。 SpringBoot 中会在run方法中创建默认的 ConfigurableEnvironment, 在prepareContext中设置到Context中 public ConfigurableApplicationContext run(String... args) ... ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); ConfigurableEnvironment environment = prepareEnvironment(listeners, bootstrapContext, applicationArguments); context = createApplicationContext(); context.setApplicationStartup(this.applicationStartup); prepareContext(bootstrapContext, context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); ... catch (Throwable ex) handleRunFailure(context, ex, listeners); throw new IllegalStateException(ex); return context; 根据类型创建environment private ConfigurableEnvironment getOrCreateEnvironment() if (this.environment != null) return this.environment; switch (this.webApplicationType) case SERVLET: return new ApplicationServletEnvironment(); case REACTIVE: return new ApplicationReactiveWebEnvironment(); default: return new ApplicationEnvironment(); ConfigurableEnvironment先来看ConfigurableEnvironment源码中的注释： Configuration interface to be implemented by most if not all Environment types. Provides facilities for setting active and default profiles and manipulating underlying property sources. Allows clients to set and validate required properties, customize the conversion service and more through the ConfigurablePropertyResolver superinterface.Manipulating property sources ConfigurableEnvironment提供两大功能，设置profile和操作委托对象[[Spring PropertySource]] 来实现对Property的操作 AbstractEnvironmentAbstractEnvironment 实现了大部分ConfigurableEnvironment的功能，包含了一下委托对象 private final SetString activeProfiles = new LinkedHashSet(); private final SetString defaultProfiles = new LinkedHashSet(getReservedDefaultProfiles()); private final MutablePropertySources propertySources = new MutablePropertySources() 子类通过customizePropertySources 的hook来操作propertySources public String getProperty(String key) return this.propertyResolver.getProperty(key); PropertyResolver 的设计PropertyResolver是Environment的顶层设计接口 Interface for resolving properties against any underlying source PropertyResolver是为了解析Properties而生的, 接口主要定义了如何从根据一个key来获取一个value, 可以是String类型的也可以是给定的Class类型 PropertyResolver提供了两类操作 getProperty() resolvePlaceholders() ，给外界暴露出一个能力来解析诸如$的Placeholder 其他的操作都是这两个操作的变身。 ConfigurablePropertyResolverConfigurablePropertyResolver 定义了一个配置化的PropertyResolver，主要是为了解析占位符， 默认是${} 的property，比如[[Spring @Value的实现机制]] 中就用到了这个Resolver 同时，ConfigurablePropertyResolver定义了[[ConversionService]] 的接口用来将value转换为目标类型 AbstractPropertyResolver[[AbstractPropertyResolver]] 中提供了一个方法来很方便的把value转换为目标类型 protected T T convertValueIfNecessary(Object value, @Nullable ClassT targetType) if (targetType == null) return (T) value; ConversionService conversionServiceToUse = this.conversionService; if (conversionServiceToUse == null) // Avoid initialization of shared DefaultConversionService if // no standard type conversion is needed in the first place... if (ClassUtils.isAssignableValue(targetType, value)) return (T) value; conversionServiceToUse = DefaultConversionService.getSharedInstance(); return conversionServiceToUse.convert(value, targetType); AbstractPropertyResolver 中定义了，Placeholder的prefixsufix以及valueSeparator还有resolvePlaceholders的策略(严格或者非严格)，严格模式不能解析的placeholder会抛出异常。 PropertySourcesPropertyResolver主要目的是通过遍历PropertySources中的key来 protected T T getProperty(String key, ClassT targetValueType, boolean resolveNestedPlaceholders) if (this.propertySources != null) for (PropertySource? propertySource : this.propertySources) if (logger.isTraceEnabled()) logger.trace(Searching for key + key + in PropertySource + propertySource.getName() + ); Object value = propertySource.getProperty(key); if (value != null) if (resolveNestedPlaceholders value instanceof String) value = resolveNestedPlaceholders((String) value); logKeyFound(key, propertySource, value); return convertValueIfNecessary(value, targetValueType); if (logger.isTraceEnabled()) logger.trace(Could not find key + key + in any property source); return null; PropertySourcePropertySource代表了Key-value的Property来源： Environment的默认实现StandardEnvironment就用到了SystemEnvironmentPropertySource, 默认将操作系统中的环境变量加载到Environment中去。 如果我们需要魔改Spring容器中的配置文件属性的值，比如配置中心在运行时动态刷新key的value，这个时候就需要自己操作PropertySource，自定义一个PropertySource，然后优先级设置在系统propertySource之上，这样就可以实现动态刷新了。 PropertySourcesPropertySources此接口是PropertySource的容器，默认实现MutablePropertySources实现内部含有一个CopyOnWriteArrayList来存储PropertySource。 EnvironmentAwareSpring的Aware组件是Spring容器给应用提供的一个钩子方法，实现了Aware接口，就可以在对应的组件里面设置对应的功能，比如实现了EnvironmentAware可以在组件里获得Environment的能力，实现了BeanFactoryAware就可以在组件里获得容器的BeanFactory，方便用户来进行一些自定义处理。 References https://github.com/seaswalker/spring-analysis/blob/master/note/Spring.md https://docs.spring.io/spring-framework/docs/current/reference/html/overview.html","tags":["java/spring","源码分析"],"categories":["源码解析"]},{"title":"这本书可能改变你的习惯","path":"/2021/09/27/The 7 Habits of Highly Effective People/","content":"人的行为总是一再重复。因此卓越不是一时的行为，而是习惯。 ——亚里士多德（Aristotle）｜古希腊哲学家、文艺理论家 柯维博士的《高效能人士的七个习惯》让人一看就以为是地摊成功文学的感觉，实际上确实是一本含金量不低的书，对于个人成长有很大的帮助，特别是让我们能够更好的领导自己，领导自己做正确的事，以及正确的做事。 这本书让我能够静下心来思考，从内而外的思考，更多的考虑我自己内心的感受，自己内心的各种想法，但是这本书太高屋建瓴了，我想能够完全做到并实践的人并不多。读完这本书并不能改变你的习惯，他只能帮助你思考自身，知行合一才能让你变得更加有效能，不再让别人影响情绪，反而更能接受改变，秉承着自己的价值标准，最终找到内心的平静。 在这本书中他把人类成熟模式把人分为三个阶段：依赖期，独立期，互赖期。 依赖期：完成一件事情需要依赖他人的帮助，他人对自己负责 独立期：自己一个人完成一件事情，自己对自己负责。 互赖期：意识到很多事情不可能自己一个人完成，开始和他人合作。 个人习惯积极主动这一章最重要的概念就是提出来两个圈，关注圈和影响圈，顾名思义，我们每天都会关注很多事情，如果关注的事情可以被我们掌握，比如工作中分配的任务，锻炼身体等属于这一类，那么就说明这部分事情在影响圈内，其余的则不能被掌握，比如股票，战争等等，这些事情可能不能被我们所左右。 看一个人的时间和精力集中于哪些事物，也能大致判断他是否积极主动，按照《影响力》这本书说的，这一步其实就是把关注圈扩大到影响圈，把自己的能量不断扩大。被动的人往往全神贯注于关注圈，抓住环境问题、他人的弱点以及超出个人能力范围的事情不放，结果越来越怨天尤人。 积极的做法应该是，由内到外自发的改变，先改变自己的个人行为，让自己变得更充实和更加有创造力，然后才能进一步去影响环境。 以终为始这个习惯让我们朝正确的方法前进，如果我们的梯子搭错了墙，那么就算我们怕的再高都没有用。 我要成为一个什么样的人吧？ 这可能是一个很复杂的问题，但是他非常有助于我们理解我们做的事情，我们需要找到一些原则来支撑我们的工作和生活，这些原则是不会随着时间变化的法则，靠着原则我们才不会在这个随波逐流的社会上迷茫。 对我而言，我的价值观也很简单： 家庭第一 保持健康的身体 态度积极 保持幽默感 对他人真诚 保持礼貌 关注当下 换位思考 多请教别人 多聆听少说话 要事第一 根据英语词源学，“自律（discipline）”是由“信徒（disciple）”一词衍生出来的。通常情况下，信徒指的是信奉某种哲学或者某种学说、原则、价值体系的人，他们信奉某种高尚目标或这种目标的代表人物。 换言之，如果你能够成为高效率的自我管理者，那么你的自律就是由内而外形成的，是独立意志的具体表现，你所信奉与追随的就是内在的价值观及在此基础上形成的人生要旨。有了独立意志和诚信人格，你就可以控制自己的感情、冲动以及情绪，服从这些价值观的约束。 《卓有成效的管理者》说过这一个习惯，有效的管理就是要事第一，领导者首先要决定的，就是哪些事情是重要的，管理者要做的事情就是把事务按照优先级排序，先做最重要的事情，自我管理的本质是自律和条例是对计划的实施。 需要注意的是不要陷入第三和第四象限事务，不管是紧急的还是非紧急的他们都不是很重要的事情。 按照彼得·德鲁克（Peter Drucker）的观点，高效能人士的脑子里装的不是问题，而是机会。他们不会在各种各样的问题上浪费时间和精力，他们的思维方式是预防型的，总是能够做到防患于未然。当然，他们也有真正意义上的危机和紧急事件需要马上处理，但是这类事件的数量相对来说很少。他们能够平衡产出和产能的关系，将时间和精力集中在重要但是并不紧急的事务上，即第二象限事务，完成这些活动能够提高个人的处事能力。 通过优化第二象限的事情来减少第一象限的事情数量，比如对于工程师而言，平时做好代码review以及Unit test，那么线上出现紧急故障的概率就会大大降低。 公共习惯接下来是是公共领域的成功三个习惯，这一部分让我们从独立期走向互赖期。在现代生活中，人不可能单打独斗的，需要和他人进行合作。 对于大多数人而言，独立期的门槛已经够高了，独立期只是让我们发生改变的原因，向上追求必然会进入到公共领域，进一步依赖他人。 双赢思维从长远来看，双赢是人际交往中的唯一可行的模式，不是双赢就是两败俱伤。把这个世界看做是一个合作的舞台而不是角斗场，事情并不是非此即彼的。双赢思维代表自己的心智逐渐走向成熟。 知彼解己在表达个人观点之前，先理解别人，这是互相依赖关系中最有用的习惯。不要太过心急，要有耐心，更要尊重对方，在你能感同身受之前，人们往往不会主动吐露心声，多听少说，警惕好为人师和自以为是，因为一旦你觉得自己是对的，你就很难听进去别人的话。 统合综效综合综效的本质是尊总差异，建立优势，弥补弱点。基本心态是：如果一个聪明人跟我的意见不同，那么对方的主张一定有我尚未体会的奥妙，值得加以了解学习。 了解了彼此，甚至还称赞彼此的差异，欣赏对方解决问题及把握机会的手法。个人的力量是团队和家庭统合综效的基础，能使整体获得一加一大于二的成效。实践统合综效的人际关系和团队会扬弃敌对的态度（1+1＝12），不以妥协为目标（1+1＝112），也不仅仅止于合作（1+1＝2），他们要的是创造式的合作（1＋1＞2）。 不断更新习惯七就是个人产能，它保护并优化你所拥有的最重要的资产——自己。 它从四个层面更新你的天性，那就是：身体、精神、智力、社会/情感。不断更新意味着要兼顾这四种要素对自己进行投资，在这四个层面“磨刀”。 就如同锻炼身体一样，锻炼身体的优点几乎都在最后阶段产生，想要增强力量就必须等到肌肉纤维断裂，神经纤维感到疼痛，这个时候自然机制会予以过度补偿，肌肉纤维会在48小时后变得更加坚韧。 越是积极主动（习惯一），就越能在生活中有效地实施自我领导（习惯二）和管理（习惯三）；越是有效管理自己的生活（习惯三），就能从事越多的第二象限事务的更新活动（习惯七）；越能先理解别人（习惯五），就越能找到统合综效的双赢解决方案（习惯四和习惯六）；越是在培养独立性的习惯方面加以改进（习惯一、二、三），就越能在相互依赖的环境下提高效能（习惯四、五、六）； 而自我更新则是强化所有这些习惯的过程（习惯七）。 谁也无法说服他人改变，因为我们每个人都守着一扇只能从内开启的改变之门，不论动之以情或晓之以理，我们都不能替别人开门。–弗格森 改变只能由内而外的发生，而不能由外向内，外部只能引导，就像谚语说的，你可以把马牵到河边，但你不能强迫它喝水。 也像阿德勒的积极心理学一样，更多的时候去考虑自己能改变的事情，而不是只会怨天尤人，把所有的问题归因到原生家庭，归因于社会，归因于他人。 Reference https://weread.qq.com/web/reader/56d325907203e8a856def7fkc81322c012c81e728d9d180","tags":["习惯"],"categories":["散文随笔"]},{"title":"技术人如何面向晋升编程？","path":"/2021/01/28/promotion-orient-programming/","content":"这一篇文章不谈技术，以一个过来人的身份谈一谈大厂技术打工人的生存问题（逃 ，其实不仅国内大厂有这种问题，诸如Google、Facebook等国外大厂也有同样的问题 ，只要你在这个体系里面生存就一定要遵循这个规则。 为什么要面向晋升编程？所有不能被写进晋升PPT里的工作都是打黑工！！！ 重要的事情加粗显示，不是不让你打黑工，有些时候打黑工是必须的，业务通常会有一些很紧急的需求，你一定不要不假思索地答应，最起码也要挑战一下TA，这个任务的价值在哪里？ 就算最后还是确定了一定要做，也一定要让TA知道，这个是非常难做的，而且一定要让自己老板知道，千万不要顺嘴就答应了，仿佛你所做的是理所应当的。 刚进大公司的时候，往往很天真，对每个人都毕恭毕敬的，仿佛伺候好了每一个人，你的前途就一片光明，然而事实很残酷，我举一个真实栗子： 之前在阿里时候，隔壁Team的一个同事，经常钉钉上看在半夜1点多还在群里处理业务问题，调试代码，处理工单等等，他的工作非常勤恳，哼哧哼哧地干活，结果一年到头，被领导打了个3.25，他的另外一个同事（都是P6），平时没见写过代码，就在内网上看到过几篇对项目的总结，结果后面拿了3.75去晋升了（虽然最后也没过）。 我们之间也打过交道，我向他请教过问题，代码水平一流，但是太沉迷于处理事情本身了，只做一个没有思想的工人，做一些没有办法被量化的工作，就算解决再多的Bug，处理再多的工单都没用，做事情一定要抓重点，小错可以随便犯，框架性的错误一定不要犯。 如何量化工作？在大公司里面，晋升都是由一群你不认识的人来决定的，也就是所谓的晋升委员会。 如果你所做的事情很难被量化，那么就很难被晋升委员会通过。 一般情况下，你越是努力地干活，你就越没有时间反刍，没有时间记录，你越是拿不到晋升资格。所以在做事情之前一定要考虑事情是否可以被量化。 什么叫可量化，就是说现状可改变的价值可以被衡量。举一个非常简单的例子，你做了一个XX系统，在上线前是是什么渣渣水平，你的系统上线之后，会达到xxx水平，这个不仅仅在大厂适用，在所有的公司都适用。 这个套路是： 设置度量，监控现状，记录当前数据。 建立新系统，优化现状。（不要尝试优化以前的平台，除非你认为你是大牛） 记录优化后的数据，做出对比。 基本上就是三步走，如果你做的事情是积极的，比如交易额等，那就得制造出上升的曲线，如果是成本类的事情，就需要制造出下降的曲线。 举一个我自己的例子，做了一个配置中心。需要的是 监控当前因为配置问题导致的发版，记录次数，以及所花费的时间 开发配置中心项目，完成并上线 记录上线完成后，配置中心的使用次数，估算人力成本，机器成本等，并画出完美的下降趋势的曲线，这就是你晋升的时候最大的。 当然这种大项目可能不仅仅是你一个人做的，所以你一定要留意在做项目时候中间遇到的各种问题，不要只埋头处理问题，记录问题同样重要，记录下来的资料，后面将会是你晋升乃至面试的重要一手资料。 独立开发者 OR 打工人大公司都有相似的弊病，从Google、Facebook、Microsoft到国内的腾讯、阿里、字节等无一幸免，虽然高工资、高福利，但是想要真正实现自己的价值，在大公司其实很难做到，就氛围算再怎么像社区、大学也无法改变公司是由商业驱动的事实。 团队做的事情一旦上面不好看，很快就会被砍掉，也就意味着你所有的付出全都付诸东流。所以大公司，主要还是看自己的选择和运气，其次才是你的个人努力。 在大公司，出了个别骨干，大部分人都是螺丝钉，很大程度上，你做的事情不会是你真正想去做的事情，很大意义上不会感受到自我实现的价值，所以往往过得并不开心。你所做的事情就是向他人证明自己，通过做事情、展示数据来向领导、晋升委员会展示自己。 所以如果你心中有远大的理想，成为一名独立开发者，做自己喜欢的产品也许是一个不错的选择，但是我相信大部分人就算心里有光也不会选择冒险。特别是结了婚有了娃之后。 如果你选择了做打工人，就一定要想明白你所做的每一件事情都是你的业绩，那么就一定不要打黑工，不妨让你做的事情高效一点，面向晋升绩效编程，让领导能够看到你的产出（量化图表就是非常好的成果）。另一方面，量化的数据也更容易让你找到工作的意义，以及自己的人生价值。","tags":["晋升"],"categories":["散文随笔"]},{"title":"你会使用 git zsh alias 吗？","path":"/2021/01/02/zsh-git-alias/","content":"Git 可以说是每个开发者必备的技能了，使用source tree之类的图形工具的同时，最好能修炼一下git命令行技能，在某种程度上可以让你更加高效的操作，也能在你ssh到远程机器上操作的时候能够临阵不慌，同时在工作中也能体会到git + zsh操作的方便之处。 alias是命令行下非常重要的一个功能，能够大大减少我们击键的次数，符合Don’t Repeat Yourself 的哲学。在oh my zsh 内置了很多使用的alias，默认git插件是启用的，所以这些alias也会启用，省去了自己配置的步骤，只需要记忆使用即可。 接下来我会从软件开发的场景来分享一下常用git命令的alias，重点部分用加粗字体标注，覆盖的不是很全，但绝对是常用的命令，当然也可以使用grep命令来检索相关alias。 初始化项目 clone远程项目的副本，在你的项目文件夹下执行 gcl [repo-url] = git clone [repo-url] 2.如果你本地已经有项目了，需要关联到远程repo 可以执行 关联到一个远程仓库 gra = git remote add origin 设置远程仓库的url，一般用于将ssh模式改为https或者反过来https转换为ssh模式grset = git remote set-url origin [repo-url] 分支操作列出分支： 列出本地所有分支，*号代表当前分支gb = git branch 列出远程所有分支gbr = git branch --remote列出本地和远程所有分支gba = git branch -a 创建分支 创建新的分支, 分支还停留在当前分支gb [branch name] = git branch [branch name]\t删除现有分支gbd = git branch -d [branch name]\t删除远程分支gbD = git push origin --delete [branch name] 切换分支 创建一个本地分支，并且切换到该分支gcb = git checkout -b [branch name]克隆一个远程分支并且切换到这个分支gcb = git checkout -b [branch name] origin/[branch name]\t切换到一个本地分支gco = git checkout [branch name]切换到主分支，一般是master分支gcm = git checkout $(git_main_branch) 切换到上一个checkout的分支gco - = git checkout - 重新命名分支 重新命名本地分支gb -m = git branch -m [old branch name] [new branch name] 缓冲区文件操作（必备）显示变更的文件，最常用的操作，类似于命令行下的ls 展示缓冲区文件的状态gst = git status 添加文件进缓冲区 添加文件进缓冲区ga = git add [filename.txt] 添加所有变化的文件进缓冲gaa = git add -A 提交变更，我最常用的操作是gca 提交变更并输入message gcmas = git commit -m [commit message]\t在编辑器（默认是vim）中展示所有的变更行，在行首输入message保存后将提交所有变更gca = git commit -v -a 添加变更到缓冲区兵提交所有的变更gcam = git commit -a -m 修改最后一次的提交messagegc! = git commit -v --amend 删除变更文件 git rm -r [filename.txt] 将文件/文件夹移除缓冲区 更新工作区远程仓库（必备）更新本地工作区，gl和ggpull最常用 更新本地工作区gl = git pull\t从远程仓库更新变更ggpull = git pull origin $(current_branch) 获取变更，使用rebase操作来处理变更，默认是mergegup = git pull --rebase 从upstream更新变更，fork仓库是更新源仓库代码用到glum = git pull upstream $git_main_branch 推送缓冲区变更到远程仓库，其中ggpush最常用 gp = git push 推送一个分支变更到远程仓库ggpush = git push origin $git_current_branch 推送本地分支到远程仓库，并关联该分支，一般用在初始化仓库gp -u = git push -u origin 推送远程分支，兵设置upstreamgpsup = git push --set-upstream origin $(git_current_branch) reset本地工作区至HEAD 将当前代码重置为HEADgrh = git reset HEAD grhh = git reset HEAD --hard 查看日志查看日志，我常用的是 glg和glog 展示commit历史，以及commit的情况glg - git log --stat --max-count=10 展示commit 历史，在单行展示messageglo - git log --oneline --decorate --color 展示commit历史，以terminal图形展示glog - git log --oneline --decorate --color --graph 统计代码提交人的commit次数（常用）： gcount - git shortlog -sn Merge Rebase合并操作 将这个分支合并进当前active的分支，比如git merge master 合并master分支到当前分支gm = git merge [branch name]\t将源分支合并进目标分支gm = git merge [source branch] [target branch]\t终止当前merge，丢弃所有变更gma = git merge --abort 变基操作（经常使用，牢记）： [numbers~HEAD]或者[SHA] rebase 代码到某个commitgrbi = git rebase -i 继续rebase，一般在rebase有冲突的时候，你resolve所有冲突之后，需要进行这一步 grbc = git rebase --continue 终止rebasegrba = git rebase --abort 参考文档： https://git-scm.com/book/zh/v2 https://github.com/ohmyzsh/ohmyzsh/wiki/Cheatsheet","tags":["tools/git"],"categories":["技术随笔"]},{"title":"一个基于Git Rebase的高效Workflow","path":"/2020/12/06/better-git-workflow-with-git-rebase/","content":"你是否还在经历合并代码的痛苦？你是否经历过刚合并完代码，又提示合并反复多次？ 这个时候你可能需要使用git rebase了，我会通过这篇文章来告诉你一个基于rebase的高效git workflow，学习成本很低，但是学会了受益无穷。 如果不想看文章正文可以直接滑到末尾，我总结了整篇文章的重点，直接用就可以了。 为什么要用Git rebase很多公司在使用git的时候没有一套规范，自己想怎么提交就怎么提，rebase和merge乱用，最后导致git log非常的混乱，commit全是各种小补丁，看起来就像狗皮膏药一样。比如下面的gitlog，能够看到代码分支纵横交错，看起来非常的费力： 而一个整洁的git log应该是下面这样的，master是一条直线，历史的提交非常整洁。 背景介绍正常的软件开发流程是： 首先你接到一个开发需求，比如说是，你就首先建立一个分支 假如你在自己的dev branch中提交了5次commit，很多都是调试性的gitlog，比如增加配置、添加log，或者直接就是一个update，这些commit你都已经push到repo了，因为代码push到Dev环境才能让测试介入测试。 当测试到一半的时候，突然有一个同事的feature上线了，这个时候你就需要重新更新master的代码。 如果使用不当，那么在你rebasemerge master分支的时候简直就是一个灾难现场，假如你有5次提交，你需要不停的处理5次基本上相同的git 代码冲突，处理到你怀疑人生。 使用Git rebase来优化整个workflow3.1 Squash自己branch的commit 在和master代码进行交互之前，首先在自己的branch上使用 rebase squash自己的commit。 git rebase -i [SHA] 或者git rebase -i HEAD~[NUMBER OF COMMIT] 这两者是等价的，如果使用zsh的话可以使用，grbi来代替git rebase -i这个命令. git rebase -i HEAD~5 等价于 grbi HEAD~5 假如我要squash下面的5个commit到9a86d1c（当然需要根据你的代码情况来判断，我这里只是举一个例子）的提交上面。 那么我们, git rebase -i HEAD~5就会出现下面的rebase 交互界面, 仔细观察会发现这个顺序其实是和gitlog相反的，最上面的是最早的commit，最下面的最近的commit。 我们把除了第一个的commit前面pick改成s就好了，这里的s代表squash。保存之后会弹出编辑commit message的页面，在这里面更改你的commit message，结束之后保存， 我这里是成功了，假如有冲突的话，需要手工进行冲突解决。由于是自己的分支上进行的rebase，所以一般不会起冲突，所以用起来很方便。 rebase squash完成之后，如果你之前已经push过origin的话，那么需要你执行 git push origin branchName --force 如果你安装了zsh，可以用ggpush -f 来强制更新你的代码到origin，当然，你也可以rebase了master之后再进行这一步。 3.2 从自己的branch rebase master代码 squash了自己的branch之后就可以rebase master代码了，方法也非常简单： git checkout mastergit pull 或者 git fetch origin master:master 这个时候一般来说不会有太多的冲突，大部分时候就是release的版本号会冲突，这个时候只需要简单处理就好了。 rebase master完成之后就可以把自己的代码push 到origin了，方法同3.1。 总结一下整个git workflow是这样的： 一、从master最新代码 checkout 新的分支进行开发 git checkout -b featurebranch_name 二、中间随意进行代码提交即可，不要想着会污染git log，待所有的单元测试都完成之后，就可以使用rebase squash来合并commit，这个数量可从git log中算出来。 git rebase -i [SHA] 或 git rebase -i HEAD~[合并commit的数量]， 三、如果你之前push过 origin，可能需要force push（自己的分支不用担心）， git push origin branchName –force或者ggpush -f（zsh） 四、更新master代码 git checkout master git pull 或者 git fetch origin master:master 五、在你的feature branch rebase master代码，然后处理冲突（这时只需要处理一次冲突，因为之前做过squash） git rebase master 六、重新force push代码到remote，如果你有CI的话，那么这里就结束了，因为CI会帮你从feature到master的步骤 七、如果你没有CI的话，那么需要你把feature branch merge（从feature到master用merge）到master，然后git push origin master，整个workflow就结束了。 这样一套 git workflow下来，你的代码提交日志将会非常整洁，看起来一点也不凌乱，如果你学会了，记得要向同事推荐，这将大大降低协作的成本。当然也要注意由于使用了 git force push，所以使用起来要小心一点，不过只要不用在自己的分支以外就没有问题。","tags":["tools/git"],"categories":["工具效率"]},{"title":"我的Mac上都有什么？","path":"/2020/04/19/what-on-my-mac/","content":"子曰： 工欲善其事必先利其器 从论语的这句话我们能得出「 器 」的重要性， 工具的重要性自然不言而喻，用好一个软件，你的效率可以提升得到巨大的提升，俗话说的好，磨刀不误砍柴工，那么你准备好开始磨你的刀了么？ 系统软件MacOS和Windows在使用上有不少差异，本身Mac就有不少令人诟病的缺陷，下面的几款软件可以让你更好的使用这个系统，让你少走弯路。 iStat Menus 「 iStat Menus 」是一款可以在状态栏显示系统信息的软件，可以让你试试的了解系统运行的各个状态，非常直观的查看系统资源的消耗情况，而且显示非常优雅可以根据自己的喜好配置，比如下图就是内存的使用情况： 推荐指数：★★★★★ Magnet 「 Magnet 」是一款快速分屏的软件，也是我在Mac上第一个付费购买的软件，价格是6元，几乎每天都会用到分屏的快捷键，比如将两个软件快速分成左、右或者上下两部分，假如你是多个屏幕的话，还可以将一个软件快速从一个屏幕移动到另外一个屏幕，总之这6块钱花的非常值。 Alfred 「 Alfred 」是Mac上面一款非常有名的效率软件，可以实现诸如文件搜索（类似于Windows上的Everything）、程序启动切换、热键搜索、计算器、词典、音乐播放、休眠锁屏以及自定义搜索功能，比如我经常需要查询订单信息，那么我就自定义一个URL来查询订单 对我而言，免费版的已经够用了，如果还需要更加强大的Workflow的功能那么就需要掏腰包了。 开发软件Intellij IDEA 作为一个开发狗，工作上的大部分时间其实都是花在了开发软件上面，下面就来介绍下我在用的一些开发软件。 「 Intellij IDEA」是一款Java集成开发环境工具， 作为一只阿里后端狗，基本上用的语言就是Java了，所以首要的开发软件就是intellij idea，优点当然是多，但是也有一个致命的缺点就是：贵。如果你们公司不支持的话就只能用社区办，不过对于大部分人来说社区版本足够了还可以配合Plugin以获得更加强大的特性。 比如安装了idea-vim就可以在编辑器使用vim了，虽然很多特性用不上，但是一些基础的操作还是可以用的，效率上也能够提升。安装了其他语言的Plugin之后还可以在idea里面写Python，scala等其他语言也足够用了。 推荐程度：★★★★★ Visual Studio Code 「 VSCode」是微软一款基于electroic的开源编辑器，一经开源便席卷了整个开源街，并且广泛流行起来，我最早使用的是sublime和atom最后转投了VSCode，其中sublime最大的有点是快，和基于electroic的Atom和VSCode比起来简直就是吊打，但是Atom和VSCode比起来插件没有VSCode多，速度也没有VSCode快，特别是当Github被微软收购了之后更是惨遭抛弃，VSCode越来越优秀，在github上更是有将近9w的star。 VSCode的插件市场更加丰富，功能也更加丰富，基于VSCode你甚至可以搭建一套IDE了，谁说免费的没有精品，VSCode就是一个例外。 推荐指数：★★★★★ iTerm2 「 iTerm2」是一款免费的命令行工具，程序员离不开console，好的命令行终端自是必不可少，功能比自带的终端强太多了，比如设置背景壁纸，快捷键分屏，输入历史回放等。当然也可以配合zsh+tmux配置更加强大的命令行功能。 推荐指数：★★★★★ Sequel Pro 「 Sequel Pro」虽然软件的名字带着Pro但是却是一个免费的软件，如果你觉得不错可以捐赠作者。在阿里基本上都是用DMS网页版本的，用不到本地的mysql客户端，但是偶尔也是要连阿里云的mysql也是会用到数据库客户端，Sequel Pro虽然免费但是完全能够胜任，相比较Navicat来说也不差。 推荐指数：★★★★☆ Visual Paradigm「 Visual Paradigm 」是一款非常强大的工具可以用来画原型图、画流程图、数据库关系图、工作流图以及项目管理等，当然收费也很贵，对于程序员来说一般都是用来画UML图以及数据库图，除了价格贵其他的没毛病，不过一般大公司都会有买集中授权，只要申请使用就好了。 推荐指数：★★★★☆ 效率软件效率软件就像是催化剂，不能改变我们做事情的结果，但是可以加快我们的做事情的速度，达到事半功倍的目的。 iSlide「 iSlide 」是一款基于PPT的插件工具，可以方便的使用模板，图标等素材可以帮助你画出更加优雅的PPT，也许你会说我是程序员PPT这种东西太虚了，我的建议是越早准备越好，PPT画得好你才能升职加薪，代码写得好则不一定，除非你是大神级别的。 此前iSlide只在windows平台上才有，现在支持MacOS就更加香了，会员需要的话就买一个毕竟跟工资比，这点小钱这不算什么。 推荐指数：★★★★☆ Xmind Zen「 Xmind Zen 」是一款强大的思维导图工具，思维导图可以让你更加有条理的去思考问题，Xmind Zen相比较之前的版本更加的轻量（直接在App Store就可以搜索下载），更加的优雅，当然图标也更加好看了，这些都是次要的，免费版本的也够用了，平时在Mac上编辑的导图保存在iCloud上面，在iPhone或者iPad上可以轻松打开查看编辑方便的很。 推荐指数：★★★★★ Trello「 Trello 」是一款基于看板的项目管理软件，基于看板能够很清晰得看到项目的进度，目前存在的问题，以及截至日期等。Trello 上面的看板就相当于一块白板，卡片就相当于是白板上面便签的抽象，大家一起基于一块白板来进行协作。 在跟踪一个项目的时候，一般会有一个开始日期和结束日期，卡片代表需要完成的任务，列表通常代表一系列步骤，列表的结构可以非常简单，例如「TODO 」「 DOING 」和「DONE 」，也可以根据流程需要非常详细，卡片在从开始到完成期间从左向右移动，在移动完成之后也代表项目结束了。 不仅在工作中可以使用Trello，在日常生活中有时候也可以使用，因为很多事情都不是一下子就能完成的，比如学会一门技术，跳一次槽等，可以逐步分解项目最终完成你的目标。 软件虽然很好，但是在国内由于不能说的原因，导致登录同步不太好用， 推荐指数：★★★★☆ 滴答清单「 滴答清单 」是一款GTD软件，可以帮你更加有效的管理任务且完成任务，滴答清单的优点在于全平台，包括Apple Watch以及Chrome插件等应有尽有而且基础功能是免费的，而且有标签等功能，虽然升级到Catalina之后MacOS上面的待办事项更加强大了实际上还是有些简陋，我还是倾向于使用滴答清单，毕竟以后可能叛逃回安卓。 滴答清单和Trello的区别就在于Trello更加关注一个项目的进度，而滴答清单更加侧重于单个时间，当然用Trello也可以完成TODO任务，他们之间是有交集存在的。 推荐指数：★★★★★ 总结 上面列举到的软件都是我平时用的非常多的软件，还有一些小众软件或者用的频率低的软件就暂时不列了，这些软件都非常的强大。上面只是一个引子，接下来的实践还要靠自己不断的摸索了。 周易云：形而上者谓之道，形而下者谓之器。想要用好这些工具并不容易，必须多学多用多思考，让「 器 」能够更好的为「 道 」服务，也让「 道 」更好的指导「 器 」产生更大的价值。","tags":["tools/mac"]},{"title":"2019年终总结","path":"/2020/01/15/summary-2019-final/","content":"​10年代的最后一天过去了，时光来到2020年，突然莫名的感伤，毕竟最早的90后已经步入了30岁，仿佛必须要写点什么才能抓住过去的时间，然而时间如流去的沙子划过指尖便再也无踪迹，只能从旧照片或者文字中才能找到一丝丝的温度，过去的一年发生了很多事情，这一年读了很多书，这一年跑了好多步，这一年经历了太多的迷茫，承受了很大的压力也备受焦虑，这一年也收获满满。 关于工作 四月份的时候公司搬到了杭州，原来的魅力惠渐渐的消失了，随之而来的是新的天猫奢品中心，我也做出了一个可能改变了人生命运的决定，我选择来杭州拼一把，在上海的时候公司当然也很符合当时上海互联网公司的调性，虽然有加班但是完全在承受范围内。在来之前已经听同事们说起过杭州的阿里加班有多恐怖，心里已经做好了思想准备，但是真正融入到了这个地方之后才会发现真的是特别拼命，能够当天下班的日子都屈指可数，处处充满着挑战，工作和思考招聘占据了大部分的时间，属于个人的时间几乎被榨干，但是我还是没有后悔这个选择。 到了杭州这边才算真正的融入了阿里的文化，同时也明白了一个道理：世界是残酷的，结果导向的。不要因为我们自己选择了一条对自己更难的路，就自我怜悯觉得这条路我们能走到这，已经非常不容易了。同一条路我们自己难走，换一个人可能走得很轻松。所以客观来讲，因为自己的选择而导致的难度的放大，引发的我们期望别人对我们的不容易而渴望好评的过程，是一厢情愿的自我怜悯。 9月份的阿里巴巴20年会，老马正式隐退江湖，全球的阿里人回家，我有幸去了现场，场面很壮观，当you raise me up音乐响起的时候，老马托着逍遥子缓缓上升，也差点落泪，大家一起打开手机的闪光灯挥舞，在那一刻，感受到了阿里人的力量。阿里在外界被戏称福报厂，因为老马说996是福报，在阿里外部的人可能并不是很理解为什么有那么多的人会为了公司拼命，老阿里人知道是组织文化的力量，随着司龄的不断增加你会逐步认同阿里的价值观，价值观考核也是属于绩效考核的一部分，所以大部分人就会被公司同化，同化不了的便离开，所以在招聘的时候能感受到很有趣的现象，很多人听到是阿里的立刻就挂掉电话，而有的人挤破头皮也进不来。 关于读书 今年读了很多书《原则》、《金字塔原理》、《苏东坡传》、《被讨厌的勇气》、《对赌》、以及《曾国藩嘉言钞》等等，将近50本书，当然去掉小说之类的真正的的干货书加技术类书籍的话也就三十几本吧，干货如《原则》、《金字塔原理》等书虽然看完做了批注总结，但是依然有一些东西不能很好的在实践中运用，属于没有完全掌握，或者说没有开窍。但是要说影响最大的要数林语堂的《苏东坡传》了。这本书带有林语堂强烈的个人色彩，有褒苏贬王的意思，可能林语堂太爱苏东坡了吧，看完苏东坡传，我也完全被苏东坡的人格魅力所征服，人生有浮有沉，但是能洒脱如苏轼的少见，苏轼的名篇也大都出自最为愁苦郁闷的黄州时期，我们有幸能以上帝视角快速浏览完他的一生，这也给我一些启发，每个人都会遇到自己的苦闷的时期，这个时候需要能够耐得住寂寞，守得住自己的初心，并学会在苦中作乐，做自己的英雄。 今年也读了很多哲学方面的书，哲学从某种程度上说属于无用之书，因为并不能产生什么价值，技能上也不会有什么进步，但是哲学能够让自己更加了解自己，发现自己的局限性，重新与这个世界连接，让自己的思想体系逐步自洽，这也是一辈子的目标。 关于生活 和恋爱六年，订婚三年，领证两年的老婆在老家结婚了，我们自己买婚纱，自己用相机拍了自己的写真集，可能并不是很完美，但是两个人在一起想怎么拍就怎么拍的感觉是在是太棒了，不用被摄影师逼迫摆各种各样尴尬的造型，从恋爱走向婚姻是一个从激情走向责任的过程，用心去体会生活，体会到对方的爱，一方面要学会被爱，一方面也要学会爱对方。 年底在魔都买了房，虽然不大好歹也是一个小窝，孟子曰：有恒产者有恒心。也算是完成一个小目标吧，在外漂泊的心总算可以收一收了，但同时压力也大了，怕工作不稳定，怕未来的不确定性，生活也多了一些焦虑，人生不就是这样的么，人总是要朝着美好的生活前进不是么？ 今年把相机卖掉了，可能是因为在杭州的缘故，相机几乎已经很少拿出来拍了，周末回到家只想休息、看书、运动，拿出去拍拍拍的动力没了，但是我发现了手机摄影的乐趣，用手机也能拍出很好看的照片，难得在于多拍，多练，多思考而不在于器材有多好。 今年感觉还是挺克制的，并没有买买买乱七八糟的东西， 能拿得出手的也就是苹果全家桶了，Apple watch ，airpods，iphone ，以及和mac配套的trackpad2 ,其实算下来也不少钱了，初衷是因为想跑步所以买了表，因为买了表所以必须换iphone，又因为跑步太单调买了airpods，这一切仿佛都是cook设计好的套路，但是就运动上面来讲，我觉得我并没有花冤枉钱。 年初的时候我给自己定下了一个小目标，每个月跑一个半马，回头看一下，今年总共跑了2600多公里，跑步已经成为了一个习惯，每个月跑一个马拉松也成为了一个约定，我完成了，所有的生命体都会逐渐适应来自外界的刺激，这个过程称为习惯，清晨闹钟响起，就起床带上手表出门跑步，或者大夏天的时候夜晚在操场吹着万丰尽情的奔跑。人都是习惯的奴隶。自律能让人获得更加长久的自由，慎独则能让我们变得更加知行合一。 关于思考 人，认清形势容易，认清自己难。今年可能是思考最多的一年，读书多了自然思考也就多了，更多的是思考自我与世界的关系，逐步的建立自己认知体系以及做事的章法规则等。形而上的问题可能是没有答案，但是只要能多了解自己一点，我就会开心一点，毕竟谁不想与自己做朋友呢。 这一年好像突然明白了很多道理，明白了为什么上课老师要让回答中心思想，明白了为什么大家要背诵全文，小时候不能设身处地的想象，等长大了处在了一定的位置和境地会发现古人以前也经历过。 这个世界一直在变，这是熵增定律的体现没有谁能够撼动，当我们回看历史的时候，我们也在变成历史，不要为了外物而过分影响自己的内心，寻找自己内心的真实，珍惜生命中的点滴美好，毕竟一辈子很短，放眼未来，把握当下就好。","tags":["总结"],"categories":["年终总结"]},{"title":"深入理解PRC之RPC基本原理","path":"/2019/12/27/learn-rpc-in-hard-way/","content":"什么是RPC？RPC的定义维基百科对RPC的定义是： 在分布式计算，远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一个地址空间（通常为一个开放网络的一台计算机）的子程序，而程序员就像调用本地程序一样，无需额外地为这个交互作用编程（无需关注细节）。RPC是一种服务器-客户端（ClientServer）模式，经典实现是一个通过发送请求-接受回应进行信息交互的系统。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用，例：Java RMI。 如下图： RPC的步骤 服务消费方（client）调用以本地调用方式调用服务； client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体； client stub找到服务地址，并将消息发送到服务端； server stub收到消息后进行解码； server stub根据解码结果调用本地的服务； 本地服务执行并将结果返回给server stub； server stub将返回结果打包成消息并发送至消费方； client stub接收到消息，并进行解码； 服务消费方得到最终结果。 RPC解决了什么问题？让分布式或者微服务系统中不同服务之间的调用像本地调用一样简单。 RPC都有哪些框架？开源框架： Dubbo: Dubbo是 阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。目前 Dubbo 已经成为 Spring Cloud Alibaba 中的官方组件。 gRPC ：gRPC是可以在任何环境中运行的现代开源高性能RPC框架。它可以通过可插拔的支持来有效地连接数据中心内和跨数据中心的服务，以实现负载平衡，跟踪，运行状况检查和身份验证。它也适用于分布式计算的最后一英里，以将设备，移动应用程序和浏览器连接到后端服务。 Hessian： Hessian是一个轻量级的remotingonhttp工具，使用简单的方法提供了RMI的功能。 相比WebService，Hessian更简单、快捷。采用的是二进制RPC协议，因为采用的是二进制协议，所以它很适合于发送二进制数据。 Thrift： Apache Thrift是Facebook开源的跨语言的RPC通信框架，目前已经捐献给Apache基金会管理，由于其跨语言特性和出色的性能，在很多互联网公司得到应用，有能力的公司甚至会基于thrift研发一套分布式服务框架，增加诸如服务注册、服务发现等功能。闭源框架： HSF ：HSF是阿里巴巴内部使用的框架，诞生于淘宝，比诞生于B2B团队的Dubbo要早个3年，目前在阿里内部已经是HSF的天下了。 Motan: 微博内部使用的rpc框架，底层支持java,生态圈往service mesh发展以支持多语言 Pigeon：Pigeon是一个分布式服务通信框架（RPC），在美团点评内部广泛使用，是美团点评最基础的底层框架之一。和阿里的Dubbo类似，在微服务的场景下，提供高性能和透明得如同本地化调用的RPC调用服务。 RPC和HTTP的比较其实两者没有没有什么可比较之处，只不过经常被人拿出来比较而已，RPC是远程过程调用，包含了传输协议和编码协议，只不过大部分RPC框架都用TCPIP来当做传输协议，当然HTTP也可以被当做出传输协议，比如gRPC大部分人其实想问的是为什么大部分RPC框架都用TCPIP来当做传输协议？可以思考一个问题：http和tcp之间的差异是什么？学过网路的人都知道http是建立在tcp协议所在的传输层纸上的应用层的，而在应用层就会比传输层要多很多的头部信息比如下图：发送一个请求到百度，可以看到HTTP1.1协议的报文包含太多在传输过程中可能无用的信息：使用自定义 TCP 协议进行传输就会避免上面这个问题，极大地减轻了传输数据的开销。 这也就是为什么通常会采用自定义 TCP 协议的 RPC 来进行进行服务调用的真正原因。此外，成熟的 RPC 框架还提供了 服务自动注册与发现、负载均衡、服务治理、等等高级功能，这些就是后话了，我们下一次再唠。","tags":["java/rpc"]},{"title":"理解docker-compse中的网络连接","path":"/2019/01/29/docker-compose-network/","content":"读《Docker从入门到实践》https://yeasy.gitbooks.io/docker_practice/compose/usage.html 中的docker-compose一章，在遇到下面一段代码： from flask import Flaskfrom redis import Redisapp = Flask(__name__)redis = Redis(host=redis, port=6379)@app.route(/)def hello(): count = redis.incr(hits) return Hello World! 该页面已被访问 次。 .format(count)if __name__ == __main__: app.run(host=0.0.0.0, debug=True) 这是一段很简单的代码,但是我写的时候不小心用host=localhost代替了，这段代码在本地运行的很好，打开http://localhost:5000时能正常计数，但是在用docker-compse up 启动之后会报 redis.exceptions.ConnectionError: Error 111 connecting to localhost:6379. Connection refused. 很明显是flask的应用无法访问redis的服务，但是我打开了本地的redis-cli也显示无法连接docker-compose 日志中，很明显redis的服务是启动在了6379端口，所以肯定是hostname的问题，在docker服务内部无法找到locahost到底是谁，因为localhost是在宿主机里的host文件里面配置的，所以app里面访问locahost来连接redis失败了，这时候要找到redis启动的真正的hostname是redis 使用docker-compose ps命令发现在docker-compose up启动的时候，自动创建了2个镜像实例counter_web_1,counter_redis_1 ➜ docker-compose ps Name Command State Ports---------------------------------------------------------------------------------counter_redis_1 docker-entrypoint.sh redis ... Up 6379/tcpcounter_web_1 python counter.py Up 0.0.0.0:5000-5000/tcp 由于我们在docker-compose.yml文件里面将counter_web_1从docker端口映射到外部网络的5000端口，因此我们才能通过localhost:5000来访问页面，所以加入我们在redis里面也加上port version: 2services: web: build: . command: python counter.py ports: - 5000:5000 volumes: - .:/code redis: image: redis:alpine ports: - 6379:6379 这样的话 我们就能从宿主机来访问docker里面的redis实例了。","tags":["Python Docker"],"categories":["技术随笔"]},{"title":"2018年终小结","path":"/2018/12/31/2018-summarize/","content":"春夏秋冬，四季变迁，轮回更迭，无人能阻挡时间的脚步，留下些许文字聊表慰藉。 技能开发技能1.学习并学会使用React 作为一个后端开发者，前端的知识其实算是有点壁垒的，期初学起来并不容易，奈何工作中需要用到fusion，而fusion是基于React的（现已开源），所以硬着头皮学了下来，目前也写一点简单的组件，太复杂的也不太行，以后还有提升空间。 2. 跟着 Andrew NG学习机器学习网易云课堂上面的免费公开课地址：吴恩达机器学习不得不说吴恩达老师讲的是特别的好，连我这种菜鸟都能听得懂，高数、线性代数、概率论这一众知识算是重新捡回来了，从简单的线性回归到逻辑回归，正规方程到梯度下降等，从分类算法到神经网络算法等，但是感觉依然只是皮毛，能实际应用还有点距离。 3.看HSF的源码HSF是集团没有开源的，比起Dubbo和gRPC性能要高出很多，源码啃起来很难，尤其是在业余时间不多的情况下，深入到轮子内部才知道原来轮子这么复杂。 ###生产力工具 PhotoShop的简单使用，简单的修图 Illustrator的使用，绘制简单的矢量图，图标。 Lightroom调色 运动跑步 千里之行，始于足下 每天最艰难的其实不是跑步本身，而是早晨挣脱温暖的被窝的那股勇气。在打败早起的拦路虎后，挡在你面前的是极点，几乎每个跑者都会遇到，长里程跑遇到极点会极其难受，脚步很重，感觉就像背着大石头在跑，但是只要你克服了它接下来终将会赢得这个挑战。遇到极点的时候，我经常是在想，再跑100米，再跑100米，给自己打气，在跑完结束时的成就感和放松的感觉真的是没有体会过的人无法体会的。使用Keep来记录跑步，记录心情，现在看来 新年的第一次跑步真的是元气满满。 从元旦那天的跑步开始算起，今年已经跑了1800公里了，平均每个月跑量150km,也就是平均每天5km。 买了两双跑鞋，一双亚瑟士 kayano 24，一双阿迪达斯 ultra boost4，总结 ub穿起来比亚瑟士要舒服，亚瑟士偏硬，ub踩屎感更强。 完成1个全程马拉松–苏州马拉松，完成3个半程马拉松，第一个是端午节在马路上跑的，第二个是在泰国普吉岛跑的，第三个是在跑步机上跑的。 还没有跑步机的时候下雨天不能出去跑步心里会很痒痒，自从买了跑步机之后每一天都跑步，感觉已经和跑步分不开了。 骑行 完成一次滴水湖骑行，总里程126km 完成一次淀山湖骑行，总里程153km 今年骑行距离达到了1013km 健身 累计平板撑时间达到10h，累计俯卧撑达到1000个，不完全统计有很多没有计算。 累计健身时间达到了15883分钟,相当于264个小时 摄影自从18年1月份买了相机以来，基本上算是入坑了，花在摄影上的时间确实多了，18年的每个月都有照片留下，买相机的初衷就是要留下时间的痕迹，基本都在记录静物，拍人的比较少，还是应该多拿起相机走走。 阅读 《菜场经济学》 《许三观卖血记》 《乌合之众》 《流畅的Python》 《了不起的盖茨比》","tags":["总结"],"categories":["年终总结"]},{"title":"让Alfred3支持iterm2","path":"/2018/11/19/mac-alfred3-iterm2/","content":"alfred设置中选择Terminal/Shell，Application选择custom 然后在下面的框中填入下面代码： -- This is v0.7 of the custom script for AlfredApp for iTerm 3.1.1+-- created by Sinan Eldem www.sinaneldem.com.tron alfred_script(q)\tif application iTerm2 is running or application iTerm is running then run script on run q tell application \\iTerm\\ activate try select first window set onlywindow to true on error create window with default profile select first window set onlywindow to true end try tell the first window if onlywindow is false then create tab with default profile end if tell current session to write text q end tell end tell end run with parameters q\telse run script on run q tell application \\iTerm\\ activate try select first window on error create window with default profile select first window end try tell the first window tell current session to write text q end tell end tell end run with parameters q\tend ifend alfred_script","tags":["tools/iterm2"],"categories":["工具效率"]},{"title":"React 组件参数传递","path":"/2018/09/06/react-tranfer-variable/","content":"一、父组件向子组件传值父组件向子组件传值直接使用props进行传值，比如下面Root想要传值给Left,父组件Root里面直接引用子组件Left，并且通过组件的属性name传递给子组件，子组件在自己的内部，直接使用this.props.name来获取传递过来的值。 class Left extends React.Component construct(props) super(props); render() return h1Hello, this.props.name/h1; class Root extends React.Component construct(props) super(props); greeting(msg) this.setState( msg ); render() return ( div Left msg=I came From Left / /div ) ReactDOM.render( Root /, document.getElementById(root)); 代码演示地址：https://codepen.io/javaor/pen/dqzRvQ 二、子组件向父组件传值子组件向父组件与父组件给子组件传值类似，假如组件Right要传值给Root,Root将传递一个函数greeting给子组件Right，子组件Right调用该函数，将想要传递的信息，作为参数，传递到父组件的作用域中。函数将保障子组件Right在调用 greeting函数时，其内部 this 仍指向父组件。 class Right extends React.Component componentDidMount() this.props.greeting(Hello From Right) render() return h1Im right/h1; class Root extends React.Component state = msg: ; greeting(msg) this.setState( msg ); render() return ( div pMsg From Right: this.state.msg/p Right greeting=msg = this.greeting(msg) / /div ) ReactDOM.render( Root /, document.getElementById(root)); 代码演示地址：https://codepen.io/javaor/pen/WgEOdG?editors=1011###三、兄弟节点之间的传值假设Right想要向Left传递参数，因为他们之间没有之间关联的节点，只有一个公共的父组件Root，所以只能通过Right先向Root传值，然后在通过props从Root向Left传值。基本第二个基本上一致，代码如下： class Left extends React.Component render() return h1Hello, this.props.msg/h1; class Right extends React.Component componentDidMount() this.props.greeting(Hello From Right) render() return h1Im right/h1; class Root extends React.Component state = msg: ; greeting(msg) this.setState( msg ); render() return ( div Right greeting=msg = this.greeting(msg) / Left msg=this.state.msg / /div ) ReactDOM.render( Root /, document.getElementById(root));","tags":["javacript/react"],"categories":["技术随笔"]},{"title":"使用Manjaro Linux + i3wm心得","path":"/2018/07/28/manjaro-i3wm/","content":"所有的熟悉都是从陌生开始的。 在使用3个月manjaro linux +i3wm之后我打算写一篇文章来记录一下心得,首先说一下，这篇文章并不是教程，只是分享一下使用心得。在这几个月使用期间，从刚开始的懵，到最后熟练使用效率大大提升，以至于使用gnome 或者windows桌面的时候各种不适应接下来会分成两部分来写，第一部分是manjaro linux，第二部分是i3wm。 一、基于arch的manjaro linux在使用Manjaro之前使用了大约1个月时间的Deepin Linux，界面确实很华丽漂亮，但是在Deepin的下面很多界面会有卡顿的感觉，比如启动器界面，以及多任务切换的时候，还有一个重要原因：我的蓝牙耳机 Fiil Diva 连上之后断断续续，基本不能用，而在Manjaro下面可以完美使用。 1.1 常用软件1.1.1 开发工具 java开发环境 使用yarout 终于可以拜托了debian系列繁琐的配置了，只需要无脑 yaourt intellij idea java开发必备 switchhosts 切换各个开发环境的hosts vscode postman sublime 基本上就使用vscode了，然而在编辑一些文本的时候vscode还是会卡顿，这个时候就要祭出sublime text了 xfce-terminal 我选择使用xfce-terminal 而不是uvxrt的原因是因为简单，而且字体展示更加优美，还可以方便的设置背景透明 1.1.2 日常使用 scrot 截屏软件 virtualbox 虚拟机，不管怎么样，在linux里面，虚拟机还是需要的，因为一些办公软件必须在windows下面才能使用。 1.2 命令行工具1.2.1 命令行文件管理：ranger 1设置代理作为一个程序员，命令行上面有些资源难免要出墙，如果不用代理网速有些资源可能是龟速，比如yaourt某些软件的时候。如果你使用ss作为代理，可以使用alias给命令行设置代理。使用setproxy给命令行设置全局代理，使用完成之后在使用unsetproxy来取消代理。可以把下面三句话放到你的 .zshrc里面，这样随时随地就都能使用了。 alias setproxy=export ALL_PROXY=socks5://127.0.0.1:1080alias unsetproxy=unset ALL_PROXYalias ip=curl -i http://ip.cn 二、 i3wm在使用i3wm之前，我知道的linux桌面有 gnome,cinnamon,kde,xfce等，对了还有国产的dde，这些桌面都有一个特点，就是和windows类似的，浮动窗口管理器，一个窗口可以浮在另外一个窗口上面，所以要在多个窗口间切换，则需要使用 alt+tab来回切换如果窗口少还好，如果窗口多的话，来回切换会非常繁琐，直到遇到了 平铺式窗口管理器i3wm。i3wm的所有窗口都平铺在桌面上，可以按照你的需求平铺或堆叠。初学起来可能配置麻烦，但是一点点熟悉下来会发现熟悉了根本离不开了，就如开头说的那样，所有的熟悉都是从陌生开始的。放一张截图： 关于i3wm的配置，就不写太多了，就推荐一个视频教程就够了教程地址：i3wm configuration附上我的配置文件地址：https://github.com/zhaohongxuan/dot_files/tree/master/i3","tags":["linux/manjaro"],"categories":["技术随笔"]},{"title":"年的味道","path":"/2018/02/23/new-year-2018/","content":"年越来越近，年味却越来越淡了。 上小学的时候，放寒假的那一天，全体师生总要开个大会，期末考试的颁奖礼仪结束后，校长会强调一下假期里的安全事项，然后大声宣布放假了，那一瞬间，年就开始了。 寒假总是比暑假要舒服，因为寒假作业要更薄一点，过年还能吃到平时不能吃的东西，穿崭新的衣服，崭新的球鞋，新衣服还一定要在大年初一穿，现在想来应该算是一种仪式吧。新衣服一般都是集市上十几块或者几十块一身的衣服，从一年级到五年级，从公安制服到警察制服到小西装，流行穿什么我们就买什么，一到过年，一到大年初一，大街上跑的都是穿公安或者警察衣服的小孩子。下面还必须配一双帅气的足球鞋，一般是十几块的样子，下跑起来倍儿快。 想起来最幸福的事情莫过于和爸妈一起去赶集了，倒不是说集上有多好玩，只不过是因为在路上可以奢侈一把，买一个很酥的油饼。还会买对联，买几挂鞭炮，一般叫精装大地红。一千响或者两千响，后来可能是五千响的。我呢就偷偷的把大地红上面的炮仗一个一个小心拆下来，不过我也不敢全拆，一挂鞭上拆点，然后收集起来，几百个揣到兜里面，然后点一根香，在野外的田地里，沟渠旁，一个一个的放，扔到水里，放到砖缝里，扔到酒瓶里。。。这一切现在看来毫无意义，当时能玩一天乐此不疲。 我一般都喜欢把寒假作业都写完了，再出去玩，因为这样玩的时候就不用想寒假作业的事情，才能痛痛快快的玩。天气好的时候就搬个凳子在太阳下面写寒假作业，冬天的阳光晒着很是舒服。 升初中之后，过年肯定不能像小学那样了，过年的时候会跑到游戏厅打游戏，过一把不良少年的瘾。 到高中的时候，过年也就十几天的样子，过完年得赶紧回到学校继续用功读书，生怕自己考不上大学。过年的时候会赶庙会，看烟火，唱唱KTV等。 有些时候，觉得过去的时间会永远湮没在尘埃里，但是偶尔一个瞬间，一些记忆片段会浮现在眼前，虽然飘渺，不能触摸，但是却让人热泪盈眶。因为我们再也不能回到从前，作一个风度翩翩的此间少年。","tags":["思考"],"categories":["散文随笔"]},{"title":"【程序员摄影】之世博公园","path":"/2018/02/06/photograpy-in-shanghai/","content":"立春这一天本程序狗带着相机出门采风了，因为刚买的相机有点小兴奋。出了门才发现上海的冬天真不是盖的，天上的太阳仿佛是假的一般，冻的人瑟瑟发抖。风有点大，公园人不多，偶尔来个人也是跑步的，拿着我的fijifilm xt20随手拍的，感觉我仿佛买的事是假相机，照片跟手机拍的一样。 下面的照片都是直出，没有经过后期处理，还需要多加学习呀。","tags":["摄影"],"categories":["散文随笔"]},{"title":"2017年总结","path":"/2018/01/09/summery-2017/","content":"业务上，从刚开始对供应链几乎没什么了解，到现在基本上熟悉了供应链的各个环节，包括订单的正逆向流转的各个环节，库存包括一件货物的生命周期整个流转过程，采购到退仓，一退二退三退等，供应商部分:供应商入住，框架合同，品牌授权等。业务上能够及时向相关接口人咨询相关问题，通过代码反推业务逻辑的方式来熟悉整个业务流程，总结沉淀了订单履约相关的文档，熟悉了scm审批流的开发，以及解决遇到的各种问题。 技术上，也没有懈怠过，在业余时间研究学习了tmf框架以及hsf框架的源代码，窥探框架的演变过程，以及里面所用到的设计模式，或者反模式，吸收良好的编程思想，当然这是个很复杂而又漫长的过程，而且学来为所用也需要假以时日，但是学习的过程是不能停止的。生命不止，编程不息。最近也有在看一些书，比如《Kafka技术内幕》，《Netty实战》，《Fluet Python》等都是很好的书，慢慢一点点的吃透。 生活上，最主要是规律的坚持运动，从一个160斤的胖子变了一个140多斤的胖子，参加了1次杭州马拉松，很享受运动的过程，以后还会一直继续。 个人的规划方面，最近几年肯定都是以技术为主，而且也喜欢技术，喜欢折腾，最近3年之内肯定都是增强自己的技术水平。当然也不只是全是技术，人生也不只是技术，大部分情况下，技术是靠业务驱动的，没有业务，技术一毛钱不值，必须是掺了业务的技术，虽然个人的努力在整个浪潮之下作用不大，而且无法改变整体局势。未来的方向一定是对某个业务很熟悉 ，然后对相关业务的，技术的整个架构，甚至底层都很熟悉，我觉得这样也很酷。追求程序的自动化，配置化，健壮性，高吞吐等，当然也要跟上时代的潮流学习AI技术，万一以后AI时机真的成熟了，说不定真的不需要一堆一堆的前后端程序员了呢，一切皆有可能，时常保留一点危机意识，大厂程序员是螺丝钉，小厂程序员干杂活，这话不假，当然如果一味的自己拧螺丝未免单调了些，如果能够发现拧螺丝的之外的过程，熟悉每一个步骤，在懂了how之后再问个what，最后在问个why，如果每个问题自己都能够这样的解决了，那么你就不只是一个螺丝钉了，环境会有一些因素，关键在个人。 对于scm团队的建议： 可以进行code review，互相review，能够尽可能少的降低低级bug的产生 技术分享，每隔一段时间，都准备一项技术或者一个功能展开一次分享活动，只有在讲述的过程中才会知道自己有哪些不足。 可以多组织活动，聚餐、烧烤、徒步旅行等，增强联络感情","tags":["总结"],"categories":["年终总结"]},{"title":"秋","path":"/2017/10/24/remember-autumn/","content":"昨天是二十四节气的霜降，这才感觉到秋天的已经快要离我而去，因为霜降接下来就是立冬了，晚上出去跑步已经不能穿短袖短裤了，秋天，这个收获的季节，我收获了什么果实，我在想… 最近工作上的事情把自己压得够呛，从国庆节过来开始到现在，每天都保持在基本后半夜才能回家，而且回家还得在电脑面前工作一段时间，得到2点多才能睡觉，感觉身心俱疲，好在每件事情都会有个结局，这半个月来的折腾也让自己学到了好多东西，包括整个供应链的业务流程，以及里面的一些技术上的细节，有些东西如果自己看的话没有那么容易就看会，但是如果有东西逼着你看，逼着你学，那时候可能就学会了。 这段时间自己还在一直坚持运动，Keep上连续运动已经2个多月了，这是我最想感谢自己的地方，下下周就要参加杭州马拉松了，争取这两周也要多跑几次热热身，每天的锻炼也是必不可少的。 从8月来体重大约减下去了大约10斤，因为是从8月开始坚持晚上吃少点，如果是在公司吃的话就吃沙拉，如果没有沙拉的话就只吃菜，不吃米饭，感觉挺好的，晚上也不会饿，如果晚上运动的话，可能运动完会吃一点水果，我也没有刻意去控制自己的饮食，周末的时候该吃肉还是会炖肉吃，但是体重确是实打实的减下去了，十一放假回家的时候，妈妈说我瘦了，脸瘦了一圈，希望自己能继续加油，把自己的小肚子减下去。 看了美剧《冰与火之歌》并且成功把女票拉下水和我一起看，还有《白夜追凶》，从来不看犯罪悬疑恐怖的女票也看得津津有味，感觉自己特别有成就感。 编程上面，Python学习感觉平时够用了，但是高阶的东西，还是掌握不够，Java方面学习了Netty这个框架，不过感觉需要再做个项目巩固一下，另一方面也是锻炼自己，Java编程思想快撸一遍了，里面有好多关于Java的细节，真的很好，也让自己对Java有更加深刻的认识。在公司可以接触到很多外接不能接触到的中间件技术，希望自己能够加把劲，在工作之余，多多研究技术的实现，以及源码，让自己的能力水平更进一步，以后才能独当一面。 2017年已经过去了297天，还剩下两个月的时间，不得不感叹时间真的很容易流失，注意力特别容易被乱七八糟的东西吸引，看看2017年年初定下的目标，还有相当一部分还没有实现，真的感觉特别打脸，计划如果不去实践又有什么意义。 种一棵树最好的时间是十年前，其次是现在，过去的日子都过去吧，从现在开始，一切都还不太晚。","tags":["思考"],"categories":["散文随笔"]},{"title":"Atom优秀package列表（持续更新）","path":"/2017/07/31/my-atom-packages/","content":"Atom,VSCode 都属于Electronic 构建的跨平台编辑器,Atom 属于Github，VSCode属于Microsoft，两个的开源软件在社区里都挺活跃，Sublime也挺好用的，特别是速度，完爆Atom，VSCode 速度要比Atom快不少，那为啥要用Atom呢因为Sublime在Windows上字体渲染惨不忍睹，特别是在25寸2k显示器上，字体大就发虚，所以在我的mac上sublime还是挺好用的，但是在windows上如果不是编辑大的文件（Atom打开大的文本兼职坑爹），在不讲速度的前提下，我也不用sublime，都用Atom，毕竟颜值即正义。 下面是我自己平时用的好用的Package列表： 工具file-icons让你的侧边栏和Tab更加美观，为每种文件类型都绘制了精美的图标，甩默认的好几条街。 Sublime Style Column SelectionAtom默认没有Block选择的功能，但是别怕，已经有包实现了这个功能，Sublime Style Column Selection 这个包可以让你像EditPlus一样编辑块文本，在windows下面按住alt然后鼠标选择就可以选择区块文件了 minimap预览所有的代码 pretty-json正如其名，美化json，比如你从服务器日志上copy下来的json报文，可以用它一键美化，也可以反向将Json压缩成一行。 highlight-selected双击的时候高亮你选择的单词，如果此单词在该文件中已经有了 也都会被高亮显示 语言script在Atom内运行代码，必备Package Python Autocomplete python自动提示，写python必备。 linter-pycodestyle记得先pip 安装pycodestyle插件然后再安装atom package 要不然一点击保存就会报错。安装的时候Atom会提示你其他的必须包，一起安装了就好。 pip install pycodestyle Python Tools快捷键ctrl+alt+u显示当前变量被调用的地方快捷键ctrl+alt+g显示定义的地方","tags":["tools/atom"],"categories":["工具效率"]},{"title":"2017年中总结","path":"/2017/07/14/summary-in-middle-year/","content":"如约而至的七月，空气里充满了茂盛的味道，狂风、暴雨、烈日、蝉鸣… 分外怀念有暑假的日子。2017年已经过了一半，白天时间开始变短，下半年也逐渐开始了，是时候给自己的上半年总结一下了。总结是为了更好的了解自己的途径，成长也许就在不经意之间就发生了，同时也让下半年的目标更加有动力。总共会在三个维度上总结一下。 工作毕业已满三年，都说三年是一个坎，五年又是一个，所以其实感觉也是挺焦虑的，怕自己能力达不到，其实，但是其实和过去的自己比的话，还是成长很多的。工作最重要的事情是成长，在爱屋的一年来，感觉收获了很多，特别是熟悉了很多互联网公司用的产品，以及相关技术，虽然经历了很多不愉快的事情，调了N次作为，换了N次领导以后，我觉得爱屋也许并不适合我，我只想安安静静的写代码，想和厉害的人一起做很好的产品。 在6月份，我经历了面试月，基本天天的节奏就是，复习-面试-总结，循环不断的进行，上海本地的大部分公司基本都被我面过了，饿了么，美团，B站，一号店等…有失误的地方，但是还是收到了不少offer，在总结中才能更好的进步。 魅力惠是属于阿里的一个BU，所以要学的东西还挺多，都是阿里的那一套，很多高性能的中间件，今年下半年的最重要的任务就是深入框架内部学习，在公司工作是一方面，个人成长则是更加重要的事情。 生活上半年搬了一次家，有了专属的小窝（之前是合租），在宜家买了拉克边桌、地毯、鞋柜、凳子、衣架等，让房间更加有质感，和女朋友一起拼装家具，打扫房间，贴纸等，很开心，看到一个乱糟糟的房间变成井井有条的房间，感觉很有成就感有木有。 今年剁了好多手，买的东西不少，3月份买了kindle，6月份买了MacBook pro，这两个东西基本都是常常在我身边的东西，kinde解决了在地铁上慢慢长路，mac则让我爱上了触摸板，爱上写作，爱上编程。 春天和爱人一起去周庄、锦溪玩了一圈，很喜欢一起出去玩的感觉，不过以后不能只留下图片，还得多谢谢旅行日记，记录下一些体会感想等。 今年跑步没怎么坚持，只是偶尔会跑跑，健身倒是还行，会跟着Keep进行一些训练，出出汗，感觉和跑步差不多，身体最重要。 书618期间又屯了好几本书，够下半年看的了，加上之前买的没看完的书，现在在kindle上已经不囤积很多书了，看完一本再买下一本。其实上半年基本没读什么新的技术书，都是看以前的旧书，有些经典值得读N遍，比如java并发编程，重构等… 看过的书 黑客与画家（kindle） Java高并发程序设计 必然 失乐园（kindle，上面好多性描写很直白，看的我在地铁上好尴尬） 大型网站系统与java中间件实践 未来简史(kindle) 巨婴国(kindle) 正在看的书 Netty实战 Java编程思想 数据结构与算法分析Java描述 Java虚拟机规范 Python核心编程 傲慢与偏见 思考的艺术 Java8实战 总结有的时候很焦虑，是因为不能沉下心来看一本书，看着好多东西要学，总是会发憷，如果不去想那么多，书一点一点看，不和别人比只和过去的自己比，只要能看到自己的进步，就好了，想得多自己还累，上半年看了一些书，去了一些地方，收获了一些东西。","tags":["总结"],"categories":["年终总结"]},{"title":"自律与健康","path":"/2017/06/29/health-and-self-discipline/","content":"自律给我自由 一直很喜欢Keep启动时splash上这句话，使用Keep这个软件也1年多了，想总结点东西。 其实最早用keep是2015年的8月，只不过那时候Keep还没有跑步的功能，而我也一直在用悦跑圈跑步，整个从2015年7月开始到2016年10月结束，总共运动了1200多公里，体重基本没怎么变化，应该是因为我不忌口的原因，运动量大吃的也多所以不会变瘦。 从16年10月开始从悦跑圈转到了Keep，报名了Keep的健身课程，练习了2个月，基本每天训练时间都大约30分钟，非常喜欢运动后大汗淋漓的感觉，但是跑步渐渐少了，早上起不来去跑步，晚上又要做健身，跑步就逐渐废掉了，2017年开始，渐渐捡起了跑步，虽然频率不高，但是每周总会运动几次，还是很喜欢运动过后的感觉，发发汗，洗洗澡，看书写代码的效率更高。 毕业已经三年，时间真的可怕，对于程序员来说，天天对着电脑，健康真的不能懈怠，该运动的时候就去运动吧，跑步也好，做plank也行，虐虐自己的身体后会爽的不亦乐乎。 仔细想想，习惯真的是很神奇的东西，比如上班，如果你刚开始通勤需要30分钟，那么如果换工作需要1个小时的话你会接受不了，但是如果适应几周之后你就习惯了，觉得自然了，习惯真的很重要，把运动当成一个习惯，而不是一个需要坚持的东西。 用心感受自我，去做每一个动作，去看每一行字，去写每一行代码，强大的自律是为了让自己更加自由的活。","tags":["思考"],"categories":["散文随笔"]},{"title":"开始自己的Mac人生","path":"/2017/06/18/start-programming-with-macbook/","content":"拥有一台mac应该算是从学生时代的愿望，但是苦于囊中羞涩，工作了之后想买但是自己又下不去狠心去买，618期间本来想入手15款的macbook pro，跟女朋友一说这个事情，她说要买就买最新款的，不差那几个钱，所以昨天就和她一起去南京东路苹果直营店买下了一台2017款的没有touch-bar的13寸MacBook Pro。随手拍两张图： 对于一个程序员，MacBook Pro绝对算是一个物超所值的生产力工具（赚钱工具），类unix的系统为开发提供了友好的开发环境，同时DE的稳定性又比Linux高出一大截。硬件方面，新款MacBook pro的第二代蝴蝶键盘感觉好像再敲击钢板，会有明显的反馈，所以手感还是不错的，但是如果要长期写代码的话，还是需要配一个机械键盘的。屏幕显示细腻，令人爱不释手。 晚上鼓捣了一晚上把电脑的开发环境搭好了，软件清单如下： 笔记：evernote+sublime-evernote插件可以在sublime中书写markdown文件并和evernote无缝集合 任务管理：滴答清单，谁用谁知道 命令行：iterm2 +zsh+homebrew+tmux+vim 词典：欧陆辞典，辞典中应该算很良心的了 软件开发：jdk 8+intellij idea+Datagrip+ Pycharm，基本都是Jetbrains家的，不过换了keymap之后又要重新适应了 编辑器：sublime+Atom 接口测试：postman 文档：Dash，海量离线文档API，异常强大,calibre用来管理电子书 云存储： 坚果云，国内最好用的云盘，存储日常生活的文档资料等绝对够用 下面是我安装好的软件截图：好的工具有了，接下来的事情就是用好这个工具创造价值，打怪升级了，程序员这条路并不好走，但是却很有趣，最后，感谢女票，很幸运有这么好的女朋友，在生活和工作中给我很多鼓舞和支持，马上就要领证了，希望能和她一起走下去。 就先写着么多吧\b，\b继续研究java虚拟机去了。 一些软件参考自这里：awesome-mac","tags":["tools/mac"],"categories":["散文随笔"]},{"title":"Java中final关键字总结","path":"/2017/04/17/final-in-java/","content":"final在java中的用法有很多，可以修饰field，可以修饰Method，可以修饰Class，而且final在多线程环境中保证了对象状态的不变性，下面就系统的总结一下Java中final关键字的用法 修饰Variablefield 修饰primitive变量，变量一旦赋值就不再可变。 final修饰基本数据类型变量和String类型时，类似于C++的const 3种变量会被隐式的定义为final：3.1. 接口中的field是final的3.2. Java7中出现的try with resource语句中的变量是隐式的final类型,如下面的代码，inputStream虽然未被声明为final，但是如果试图在try块里面重新对inputStream赋值的话，就会产生编译异常，不能给final变量赋值 try (FileInputStream inputStream = new FileInputStream(text.txt))inputStream = new FileInputStream(); catch (Exception e) e.printStackTrace(); 修饰引用实例类型变量，变量被赋值后，变量指向的引用的值可以变，但是不能重新指向新的引用，即final只关心引用本身，而不关心final引用的内容。 public static void main(String[] args) final User user = new User(xuan1,23); System.out.println(user.getAge()); //输出23 user.setAge(24); System.out.println(user.getAge()); //输出24 user = new User(xuan2,25); //编译错误，提示不能赋值给final变量 System.out.println(user.getAge()); 修饰实例成员变量时，必须在定义的时候初始化：直接赋值，构造器初始化，或代码块中初始化，或的意思是这三种方式只能选择一种，否则编译报错。 修饰静态成员变量时，必须在变量定义的时候初始化：直接赋值，静态代码块中赋值 Tips: 有一种特殊情况：System.in,System.out,System.err 是静态域但是没有在定义的时候或者静态代码块中初始化，而是使用了set方法来设置值。 JDK8以前内部类访问外部类的变量时要求变量为Final类型,JDK8之后，只要求外部类为事实不可变变量，不一定要加上final 关于事实不可变final的定义： variable or parameter whose value is never changed after it is initialized is effectively final 也就是说变量被初始化之后没有改变过即使没有final，jvm也会把这个变量解释为final类型来对待。 下面是官方文档的一个例子： 在内部类PhoneNumber中的构造器中使用外部的numberLength的时候，JDK8之前必须显示定义为final类型，否则编译器将会给出警告，而在JDK8之后并不需要显式声明为final，但是，如果变量在初始化之后被再次赋值的话，就会出现异常了，因为打破了事实不可变的条件，所以在构造器中再次给numberLength赋值为7的时候，JDK8的编译器也给出了错误提示。 同理，在printOriginalNumbers方法中方为外部类的变量phoneNumber1，phoneNumber2的时候JDK8以前的编译器给出错误提示。 package io.github.zhaohongxuan;/** * Created by zhaohongxuan */public class LocalClassExample static String regularExpression = [^0-9];\tpublic static void validatePhoneNumber(String phoneNumber1, String phoneNumber2) int numberLength = 10; // Valid in JDK 8 and later: // int numberLength = 10; class PhoneNumber String formattedPhoneNumber = null; PhoneNumber(String phoneNumber) // numberLength = 7; String currentNumber = phoneNumber.replaceAll(regularExpression, ); if (currentNumber.length() == numberLength) formattedPhoneNumber = currentNumber; else formattedPhoneNumber = null; public String getNumber() return formattedPhoneNumber; // Valid in JDK 8 and later: public void printOriginalNumbers() System.out.println(Original numbers are +phoneNumber1+ and +phoneNumber2); PhoneNumber myNumber1 = new PhoneNumber(phoneNumber1); PhoneNumber myNumber2 = new PhoneNumber(phoneNumber2); // Valid in JDK 8 and later:// myNumber1.printOriginalNumbers(); if (myNumber1.getNumber() == null) System.out.println(First number is invalid); else System.out.println(First number is + myNumber1.getNumber()); if (myNumber2.getNumber() == null) System.out.println(Second number is invalid); else System.out.println(Second number is + myNumber2.getNumber()); public static void main(String... args) validatePhoneNumber(123-456-7890, 456-7890); 修饰MethodJava语言规范中的描述如下： A method can be declared final to prevent subclasses from overriding or hiding it.It is a compile-time error to attempt to override or hide a final method.A private method and all methods declared immediately within a final class (§8.1.1.2) behave as if they are final, since it is impossible to override them.At run time, a machine-code generator or optimizer can “inline” the body of a final method, replacing an invocation of the method with the code in its body. The inlining process must preserve the semantics of the method invocation. In particular, if the target of an instance method invocation is null, then a NullPointerException must be thrown even if the method is inlined. A Java compiler must ensure that the exception will be thrown at the correct point, so that the actual arguments to the method will be seen to have been evaluated in the correct order prior to the method invocation. final修饰方法可以阻止子类覆盖，如果试图覆盖则编译报错 private 方法和final 类的方法表现的为final方法的属性，因为无法覆盖他们。 运行时，JVM会内联final方法，用final方法的代码替换方法的调用，下图是一个简单示例: final class Point int x, y; void move(int dx, int dy) x += dx; y += dy; class Test public static void main(String[] args) Point[] p = new Point[100]; for (int i = 0; i p.length; i++) p[i] = new Point(); p[i].move(i, p.length-1-i); main方法里的for循环中的Point类中的move方法将会被内联为下面的代码： for (int i = 0; i p.length; i++) p[i] = new Point(); Point pi = p[i]; int j = p.length-1-i; pi.x += i; pi.y += j; Header One Header Two Item One Item Two 参考资料：http://docs.oracle.com/javase/specs/jls/se8/html/jls-8.html#jls-8.4.3.3 修饰Class 1. final修饰Class可以防止类被继承 2. final和abstract不能同时修饰类，因为2者是互斥的。 final的语义 1. Java编译器允许final域缓存在寄存器中而不用重新加载它，如果是非fina域的话，将会被重新加载 2. final可以确保初始化过程中的安全性，不可变对象时线程安全的，在多个线程中共享这些对象无需同步。 3. 多线程中，一个对象的final域在一个线程的构造器结束的时候，在另外的线程中可见。java中有很多安全的特点都是依据String类是被设计为final来保证的 Java内存模型中的final TODO参考资料：http://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.5","tags":["java"],"categories":["java"]},{"title":"intellij idea中使用javap等JDK工具","path":"/2017/04/17/intellij-external-tools/","content":"java工程师平时工作中用到的工具挺多的，比如javap,jstack等，intellij idea 作为宇宙最强java ide idea一样可以帮我们实现这个功能，方法如下： ctrl+alt+s打开设置界面,找到Tool- External Tools 点击 +来增加一个新的外部工具。 在tool setting 的Program输入工具的路径，这中间可以插入宏，比如$JDK_PATH$，不需要自己再手动输入jdk的路径了，在Parameters中输入-c $FileClass$ ，$FileClass$代表要解析的 class文件,-c代表输出分解后的代码在Workding Directory中输入$OutputPath$,代表项目的输出路径 在java文件上右键，选择External Tools - javap就可以输入分解后的代码了，也可以自定义快捷键，比如设置alt+p就可以很方便的使用javap这个工具了，其他的工具和这个类似，都可以很方便的添加到External Tool里","tags":["java/intellij"],"categories":["java"]},{"title":"Java中将JSON反序列化为泛型对象","path":"/2017/02/24/json-to-map-include-list/","content":"将嵌套List的Map转换为Json应该都没什么问题，使用Gson和Jackson都能实现，在Gson中使用new Gson().toJson()方法，在Jackson中使用new ObjectMapper().writeValueAsString()即可。将json转换为形如MapString,List的时候遇到了一点问题，虽然返回类型是MapString,ListLong但是，Map的value的值却并不是ListLong,而是Integer类型的，这里面显然是有问题的，查看Jackson的源码和Gson的源码发现将json反序列化为对象确实有两个方法，一种适用于泛型对象，一种适用于非泛型的一般对象。 使用Gson在gson中将json字符串转反序列化为对象有两个方法： /** * This method deserializes the specified Json into an object of the specified class. It is not * suitable to use if the specified class is a generic type since it will not have the generic * type information because of the Type Erasure feature of Java. Therefore, this method should not * be used if the desired type is a generic type. Note that this method works fine if the any of * the fields of the specified object are generics, just the object itself should not be a * generic type. For the cases when the object is of generic type, invoke * @link #fromJson(String, Type). If you have the Json in a @link Reader instead of * a String, use @link #fromJson(Reader, Class) instead. * * @param T the type of the desired object * @param json the string from which the object is to be deserialized * @param classOfT the class of T * @return an object of type T from the string. Returns @code null if @code json is @code null. * @throws JsonSyntaxException if json is not a valid representation for an object of type * classOfT */public T T fromJson(String json, ClassT classOfT) throws JsonSyntaxException Object object = fromJson(json, (Type) classOfT); return Primitives.wrap(classOfT).cast(object); /** * This method deserializes the specified Json into an object of the specified type. This method * is useful if the specified object is a generic type. For non-generic objects, use * @link #fromJson(String, Class) instead. If you have the Json in a @link Reader instead of * a String, use @link #fromJson(Reader, Type) instead. * * @param T the type of the desired object * @param json the string from which the object is to be deserialized * @param typeOfT The specific genericized type of src. You can obtain this type by using the * @link com.google.gson.reflect.TypeToken class. For example, to get the type for * @code CollectionFoo, you should use: * pre * Type typeOfT = new TypeTokenlt;Collectionlt;Foogt;gt;().getType(); * /pre * @return an object of type T from the string. Returns @code null if @code json is @code null. * @throws JsonParseException if json is not a valid representation for an object of type typeOfT * @throws JsonSyntaxException if json is not a valid representation for an object of type */ @SuppressWarnings(unchecked) public T T fromJson(String json, Type typeOfT) throws JsonSyntaxException if (json == null) return null; StringReader reader = new StringReader(json); T target = (T) fromJson(reader, typeOfT); return target; 观察fromJson(String json, ClassT classOfT)的注释： It is not suitable to use if the specified class is a generic type since it will not have the generic type information because of the Type Erasure feature of Java 也就是说，由于Java泛型的擦除机制，这个方法不适用于传入泛型的类，比如MapString,Long,ListString等，这个时候可以用T fromJson(String json, Type typeOfT)替代。 下面还有一段话： Note that this method works fine if the any of the fields of the specified object are generics, just the object itself should not be a generic type ** 注意：** 如果对象不是泛型的，只是字段是泛型的话这个方法是可以使用的 刚开始不太理解这句话，后来想通了，也就是类定义上不能带有泛型比如 public interface MapK,V 这样的就不行，但是如果是下面这样的只有域上带有的泛型是可以： static class JsonDemo private ListLong list; public ListLong getList() return list; public void setList(ListLong list) this.list = list; 下面的fromJson(String json, Type typeOfT)就是专门提供给泛型类的对象使用的，如果你自己反序列化的对象带有泛型的话需要用这个方法。 使用Jackson和gson一样，jackson也提供了两个方法，一个适用于普通的类，一个适用于泛型类，只不过jackson源码的注释没有Gson的丰富，从注释上看不出来，功能和Gson的一致。 /** * Method to deserialize JSON content from given JSON content String. * * @throws IOException if a low-level I/O problem (unexpected end-of-input, * network error) occurs (passed through as-is without additional wrapping -- note * that this is one case where @link DeserializationFeature#WRAP_EXCEPTIONS * does NOT result in wrapping of exception even if enabled) * @throws JsonParseException if underlying input contains invalid content * of type @link JsonParser supports (JSON for default case) * @throws JsonMappingException if the input JSON structure does not match structure * expected for result type (or has other mismatch issues) */ @SuppressWarnings(unchecked) public T T readValue(String content, ClassT valueType) throws IOException, JsonParseException, JsonMappingException return (T) _readMapAndClose(_jsonFactory.createParser(content), _typeFactory.constructType(valueType)); /** * Method to deserialize JSON content from given JSON content String. * * @throws IOException if a low-level I/O problem (unexpected end-of-input, * network error) occurs (passed through as-is without additional wrapping -- note * that this is one case where @link DeserializationFeature#WRAP_EXCEPTIONS * does NOT result in wrapping of exception even if enabled) * @throws JsonParseException if underlying input contains invalid content * of type @link JsonParser supports (JSON for default case) * @throws JsonMappingException if the input JSON structure does not match structure * expected for result type (or has other mismatch issues) */ @SuppressWarnings( unchecked, rawtypes ) public T T readValue(String content, TypeReference valueTypeRef) throws IOException, JsonParseException, JsonMappingException return (T) _readMapAndClose(_jsonFactory.createParser(content), _typeFactory.constructType(valueTypeRef)); 简单实验使用两种方式反序列一个json，使用Class来反序列化泛型类型的对象，在printType的时候会出现ClassCastException类型转换异常。 package org.xuan;import com.fasterxml.jackson.core.type.TypeReference;import com.fasterxml.jackson.databind.ObjectMapper;import com.google.common.collect.Maps;import com.google.common.reflect.TypeToken;import com.google.gson.Gson;import java.io.IOException;import java.util.Arrays;import java.util.List;import java.util.Map;/** * Created by zhaohongxuan */public class JsonTest private static ObjectMapper mapper = new ObjectMapper();\tprivate static Gson gson = new Gson();\tpublic static void main(String[] args) throws IOException MapString, ListLong map = Maps.newHashMap(); map.put(one, Arrays.asList(10001L, 10002L, 10003L, 10004L)); map.put(two, Arrays.asList(20001L, 20002L, 20003L, 20004L)); map.put(three, Arrays.asList(30001L, 30002L, 30003L, 30004L)); map.put(four, Arrays.asList(40001L, 40002L, 40003L, 40004L)); String json = new Gson().toJson(map); System.err.println(=======================错误示范=====================); //Gson MapString, ListLong mapResult = gson.fromJson(json,Map.class); System.out.println(通过Gson转换...);// printType(mapResult); System.out.println(mapResult); //Json MapString, ListLong jsonMapResult = mapper.readValue(json,Map.class); System.out.println(通过Jackson转换...);// printType(jsonMapResult); System.out.println(jsonMapResult); System.out.println(=======================正确做法=====================); //Gson MapString, ListLong mapResult1 = gson.fromJson(json,new TypeTokenMapString, ListLong().getType()); System.out.println(通过Gson转换...); printType(mapResult1); System.out.println(mapResult1); //Json ObjectMapper mapper = new ObjectMapper(); MapString, ListLong jsonMapResult1 = mapper.readValue(json,new TypeReference MapString,ListLong() ); System.out.println(通过Jackson转换...); printType(jsonMapResult1); System.out.println(jsonMapResult1); public static void printType(MapString, ListLong map) for (Map.EntryString, ListLong entry: map.entrySet()) System.out.println(key 类型:+entry.getKey().getClass()+, value类型: +entry.getValue().getClass()+, List中元素类型+entry.getValue().get(0).getClass()); 总 结在Gson中：如果使用fromJson(String json, ClassT classOfT)来反序列化Map的话，不会造成编译错误，返回的类型就会变化，Long类型变成了Double类型,使用的时候就会出现异常，例如在遍历Map的entrySet的时候就会出现异常。 java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.Long 因此： 反序列化泛型对象如MapK,V等需要使用 fromJson(String json, Type typeOfT) 一般对象使用fromJson(String json, ClassT classOfT)在Jackson中：如果使用T readValue(String content, ClassT valueType)来反序列化Map的话，返回的类型就会由Long类型变成了Integer类型。 反序列化泛型对象如MapK,V等需要使用 T readValue(String content, TypeReference valueTypeRef) 一般对象使用T readValue(String content, ClassT valueType)","tags":["java/serialization"],"categories":["java"]},{"title":"2017阅读计划","path":"/2017/02/02/reading-in-2017/","content":"总是等到过完农历的新年才会觉得新的一年才真正的开始，元旦仿佛没有什么卵用，回首过去的一年，有很多收获，同时也有不少遗憾，京东做活动的时候买的书还有好多没有读完，新的一年，新的开始，书要一步一步的读，代码要一字一字得码，希望2017年能够更上一层楼。下面的只是个大概的提纲，没有具体的每天读几页，多少天读完等很严格的规划，因为生活中有很多突发事件会影响自己，公司加班、生病发烧，聚餐啊，跳槽等等…无法预测，用尽一切时间去学：在地铁上看，在饭后看，睡觉前少看会儿手机多读一会儿书，让心流的时间加长，高效专注的完成之后再休息。 技术方面首先，肯定是要去库存，去年京东做活动买的没读完的书争取在上半年读完。No.1《Redis设计与实现》Redis不仅是一个缓存工具，而且还是一个nosql的实现，性能极其强大，目前No.2《编程珠玑》编程方面的属于元老级别的书吧，修炼自己的内功必备，想吃透这本书我觉得一年都不一定行。No.3《Spring实战》原本是买来给女朋友入门Spring的…我先撸一遍吧，里面的例子还是很清晰的，适合初学者，我更倾向于看《Spring揭密》。No.4《Linux命令行与shell脚本编程大全（第3版）》作为一个Java行业从业者，Linux自然是必不可少的，提高自己的Linux姿势水平势在必行。No.5《利用Python进行数据分析》去年读完了《Python基础教程》，还是应该投入实际的用途，学学用Python进行数据分析吧。No.6《高性能Mysql》这个板砖书，还是看电子版的好了，放在ipad里也极其方便，不一定全部看完，但是重要章节一定得看完，而且得熟练，互联网公司必备。No.7《敏捷软件开发原则、模式与实践》再重新读一遍此神书，了解如何编写优雅的代码。 其他方面No.1《设计中的设计》培养自己的审美水平，无印良品总设计师操刀的书，值得一看。No.2《人类简史》仰慕已久的书，历史佳作。No.3《梦的解析》很古老的一本书，心理学著作，希望自己能看的进去。No.4《国富论下》上册看完了，下册岂有不看之理No.5《三体》宏大的科幻奇书，互联网行业必看的，打算在地铁上刷完。No.6《世界简史》就是对历史有所偏爱，看完《人类简史》看世界简史，读史使人明智，称为更好的自己。No.7《必然》看完KK的《失控》，《必然》势在必看。","tags":["读书计划"],"categories":["散文随笔"]},{"title":"Kafka入门","path":"/2017/01/19/simple-kafka-example/","content":"1.环境配置kafka依赖zookeeper来调度，以及选举leader，因此需要先安装zookeeper 1.1 安装zookeeper点击下载zookeeper下载合适版本的zookeeper，当前最新的稳定版本是3.4.9创建好数据目录,命名为data，下一步配置用到 $ cd opt/ tar -zxf zookeeper-3.4.6.tar.gz cd zookeeper-3.4.6$ mkdir data 1.2 配置zookeeper$ vi conf/zoo.cfgtickTime=2000dataDir=/path/to/zookeeper/dataclientPort=2181initLimit=5syncLimit=2 1.3 启动zookeeper$ bin/zkServer.sh start 相应的停止zookeeper的命令为： $ bin/zkServer.sh stop 1.4 启动zookeeper CLI$ bin/zkCli.sh 1.2 安装kafka1.2.1 下载并解压点击下载kafka的压缩包 $ cd opt/$ tar -zxf kafka_2.11-0.10.1.0.tgz$ cd kafka_2.11-0.10.1.0 1.3.1 启动和关闭Kafka启动kafka $ bin/kafka-server-start.sh config/server.properties 关闭kafka $ bin/kafka-server-stop.sh config/server.properties 2.测试单broker我的kafka服务创建在Linux虚拟机上，IP地址为：192.168.61.131（按需替换成自己的IP地址），在这里需要配置server.properties文件，将advertised.host.name设置为虚拟机的IP地址 advertised.host.name=192.168.61.131，否则在宿主机上无法访问虚拟机上面的服务 ###2.1 使用Shell命令测试topic 2.1.1 创建topic在命令行界面kafka目录，输入下面命令： bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic page_visits 2.1.2 测试发布者输入以下命令，打开发布消息CLI bin/kafka-console-producer.sh --broker-list localhost:9092 --topic page_visits 在CLI界面输入，两行测试消息 Hello kafka 你好吗？ 2.1.3 测试订阅者输入一下命令打开订阅者CLI bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --zookeeper localhost:2181 --from-beginning --topic page_visits 如果执行正确，会显示刚才发布者发送的两行消息 ###2.2 使用Java代码创建Client来发布订阅消息 需要先在pom中添加kafka依赖： dependencies dependency groupIdorg.apache.kafka/groupId artifactIdkafka_2.9.2/artifactId version0.8.1.1/version scopecompile/scope exclusions exclusion artifactIdjmxri/artifactId groupIdcom.sun.jmx/groupId /exclusion exclusion artifactIdjms/artifactId groupIdjavax.jms/groupId /exclusion exclusion artifactIdjmxtools/artifactId groupIdcom.sun.jdmk/groupId /exclusion /exclusions /dependency dependency groupIdorg.apache.kafka/groupId artifactIdkafka-clients/artifactId version0.9.0.0/version /dependency /dependencies 2.2.1 创建发布者发布消息下面一段代码，会每隔3秒中发布一个测试消息 public class MyProducer private final static String TOPIC = page_visits; public static void main(String[] args) throws InterruptedException long events = 100; Properties properties = new Properties(); properties.put(metadata.broker.list, 192.168.61.131:9092); properties.put(serializer.class, kafka.serializer.StringEncoder); ProducerConfig config = new ProducerConfig(properties); ProducerString, String producer = new ProducerString, String(config); for (long nEvent = 0; nEvent events; nEvent++) SimpleDateFormat sdf = new SimpleDateFormat(yyyy-MM-dd HH:mm:ss); KeyedMessageString,String data = new KeyedMessageString, String(TOPIC,String.valueOf(nEvent),Test message from java program + sdf.format(new Date())); Thread.sleep(3000); producer.send(data); producer.close(); 2.2.2 创建订阅者订阅消息下面的代码会绑定到虚拟机长的kafka服务，当发布者发布消息时，订阅者会不断地打印发布者发布的消息： public class MyConsumer private final static String TOPIC = page_visits; public static void main(String[] args) Properties properties = new Properties(); properties.put(bootstrap.servers,192.168.61.131:9092); properties.put(enable.auto.commit, true); properties.put(group.id, test); properties.put(auto.commit.interval.ms, 1000); properties.put(session.timeout.ms, 30000); properties.put(key.deserializer, org.apache.kafka.common.serialization.StringDeserializer); properties.put(value.deserializer,org.apache.kafka.common.serialization.StringDeserializer); KafkaConsumerString,String consumer = new KafkaConsumerString, String(properties); consumer.subscribe(Arrays.asList(TOPIC)); System.out.println(Subscribe to topic +TOPIC); while (true) ConsumerRecordsString,String consumerRecords = consumer.poll(100); for(ConsumerRecordString,String record: consumerRecords) System.out.printf(offset = %d,key = %s,value = %s ,record.offset(),record.key(),record.value());","tags":["java/kafka"],"categories":["技术随笔"]},{"title":"清醒思考的艺术","path":"/2017/01/11/art-of-thinking-clearly/","content":"大学的时候读过的一本书，当年排行德国非小说类的第一名，现在又抽空读了一遍，感觉获益颇多，每一篇都很简短，用很小的生活中的例子来解释看似很平常的一些思维谬误，这本书有个很好玩的副标题你最好让别人去犯的52个思维错误，能感受到作者的诙谐和幽默。作者在前言里就说了，生活中的思维错误是不可能避免的，能够意识到并且尽量在生活中少犯就好了，让我说其实更像是程序的bug,是无法避免的，在编程（思考）的时候多加注意就好了。 一、幸存偏误幸存偏误指的是，在生活中更容易看到成功，看不到失败，所以会过高的估计自己成功的希望。最常见的例子 每个成功的人都很努力，所以努力的人都能成功。 这种就是典型的只看到了成功的人而忽视了那些失败的人。所以作者在文章中提醒我们要常常逛逛墓地，看看那些失败者的案例，能够让我们能加清醒的思考。 二、游泳运动员错觉 三、纠缠沉默成本","tags":["读书笔记"],"categories":["散文随笔"]},{"title":"Java中的互斥锁和读写锁","path":"/2016/11/26/lock-in-java/","content":"在JDK5之前，访问共享对象的时候使用的机制只有synchronized和volatile ，JDK5的并发包里提供了一种新的更加高级的机制：互斥锁ReentrantLock，显式锁是为了弥补内置锁的方法而开发的，两者是互补的关系，显式锁并不能代替内置锁。ReentrantLock实现了一种标准的互斥锁，亦即每次最多有一个线程能够持有ReentrantLock Lock接口ReentrantLock简介concurrent包中的Lock类定义了一组抽象的加锁操作，如下代码所示，与synchronized不同的是，Lock提供了一种无条件、可轮询、定时、可中断的锁获取操作，所有的加锁和解锁操作都是显示的ReentrantLock实现了Lock接口，提供了与synchronized相同的互斥性以及内存可见性。与synchronized一样，ReentrantLock提供了可重入（即可以被单个线程多次获取）的加锁语义。 public interface Lock void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition(); ReentrantLock的使用方法： Lock lock = new ReentrantLock();...lock.lock();try finally lock.unlock(); 在使用显示锁的时候一定要在finally块中释放锁，否则如果代码中一旦出现异常，那么可能这个锁永远都无法释放就会造成某个对象的状态不一致，如果是账户余额或者别的重要的信息可能就会出现很严重的事故。 与内置锁的区别可轮询及定时的锁在内置锁中，一旦出现死锁，唯一的办法就是重启服务，ReentrantLock使用tryLock()方法来实现可轮询的或者定时的锁，如果一次不能获得全部的锁，那么通过可定时或者轮询的锁可以重新获得控制权，它会释放已经获得的锁然后重新获取所有的锁，如果在指定的时间内没有获取到所有的锁，那么就返回失败。如下例子，通过tryLock()来避免锁顺序死锁 public boolean transferMoney(Account fromAcc,Account toAcc,Amount amount,long timeout,TimeUnit timeUnit) long fixeDelay = getFixDelayNanos(timeout,timeUnit); //固定的时间 long ranMod = getRandomDelayNanos(timeout,timeUnit); //随机的时间 long stopTime = System.nanoTime() + timeUnit.toNanos(timeout); while(true) if(fromAcc.lock.tryLock()) try if(toAcc.lock.tryLock()) try if(fromAcc.getBalance().compareTo(amount)0) throw new InsufficientFundsException(); else fromAcc.debit(amount); to.credit(amount); return true; finally toAcc.lock.unlock(); finally fromAcc.lock.unklock(); if(System.nanoTime()stopTime) return false; NANOSECONDS.sleep(fixeDelay+rnd.nextLong()%ranMod) 另一种方式是使用定时锁，如果在指定的时间内无法获取到锁的话那么将操作失败 可中断的锁获取操作使用Lock接口中的lockInterruptibly方法能够在获得锁的同时保持对中断的响应。 public boolean sendSharedLine(String message) throw InterruptedException lock.lockInterruptibly(); try return cancellableSendOnSharedLine(message); finally lock.unlock(); private boolean cancellableSendOnSharedLine(String message) throw InterruptedException ... 非块结构的加锁synchronized锁的获取和释放的操作都是基于代码块的，虽然这样能够简化代码的编写，降低编码错误的可能性，但是有的时候可能需要更加灵活的加锁规则。降低锁的力度可以提高代码的伸缩性, 在某些情况下，可以将锁分解成对一组独立对象上的锁的的分解，这种技术被称为锁分段，在ConcurrentHashMap中使用了一个包含16个锁的数组，每个锁保护所有散列桶的1/16， 一种第N个散列桶由第N mod 16个锁来保护。如果散列函数合理分布，这样锁的请求就减少到了原来的116。正是由于锁分段技术，ConcurrentHashMap能够支持多大16个并发的写入器，当然如果并发量足够大的话可以将默认的锁分段数量超过默认的16个。下面的代码块就是ConcurrentHashMap的锁分段的代码，其中能看到Segment是继承与ReentrantLock的，本质上是一把互斥锁。 static class SegmentK,V extends ReentrantLock implements Serializable private static final long serialVersionUID = 2249069246763182397L; final float loadFactor; Segment(float lf) this.loadFactor = lf; 公平锁与非公平锁ReentrantLock的构造函数如下，提供了两种公平性的锁，一种是公平锁，一种是非公平的锁（默认） public ReentrantLock() sync = new NonfairSync();public ReentrantLock(boolean fair) sync = fair ? new FairSync() : new NonfairSync(); 在公平锁上，线程按照发出请求的顺序来获得锁，而当线程请求非公平锁时，如果刚好该锁的状态变为可用的话那么久允许这个线程先于队列其他线程获得锁。 公平锁与非公平锁 /** * Sync object for fair locks */ static final class FairSync extends Sync private static final long serialVersionUID = -3000897897090466540L; final void lock() acquire(1); /** * Fair version of tryAcquire. Dont grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) if (!hasQueuedPredecessors() compareAndSetState(0, acquires)) setExclusiveOwnerThread(current); return true; else if (current == getExclusiveOwnerThread()) int nextc = c + acquires; if (nextc 0) throw new Error(Maximum lock count exceeded); setState(nextc); return true; return false; /** * Sync object for non-fair locks */static final class NonfairSync extends Sync private static final long serialVersionUID = 7316153563782823691L; /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); protected final boolean tryAcquire(int acquires) return nonfairTryAcquire(acquires); 由代码可以看到公平锁和非公平都是继承于Sync的而Sync是继承与抽象的AQS（AbstractQueuedSynchronizer）的，AQS是java中锁的抽象类，包含了锁的许多公共方法，是互斥锁(例如，ReentrantLock)和共享锁(例如，Semaphore)的公共父类。可以看到公平锁和非公平锁的不同点在于tryAcquire()方法即获取锁的方式不同。 在大多数情况下，非公平锁的性能要高于公平锁的性能。主要原因是在恢复一个被挂起的线程与线程真正运行之间有很大的延迟。假如现在线程A持有一个锁，线程B请求这个锁，由于A持有这个锁，所以B挂起，当A释放锁的时候B被唤醒，再次尝试获取这个锁，如果在同时有C也请求这个锁，那么有很大可能C会在B完全唤醒前获取这个锁使用以及使用这个锁，当B获得锁的时候，C已经使用完毕并释放锁了，所以吞吐量会有所提高。但是当请求锁的平均时间较长的时候应该使用公平锁。 读写锁 ReadWriteLock TODO","tags":["java/thread"],"categories":["java"]},{"title":"使用Btrace来跟踪调试代码","path":"/2016/09/10/use-btrace-to-trace-java-program/","content":"有的时候在写程序的时候可能有些地方的日志没有照顾到，产生了bug，如果到了线上环境，有时候不得不停掉服务重新来加入日志来查看产生bug的地方，这个时候Btrace就派的上用场了，在VisualVM中可以很方便的调试目标程序，而对原有项目没有影响，当然也可以不用VisualVM而使用命令行来实现这个功能。Btrace是一个开源项目，项目托管在github上 使用VisualVM的Btrace插件最为方便，下面就写个小例子来熟悉一下 准备工作1.在visualvm官网下载visualVM可视化工具2.依次点击visualVM菜单栏的Tool-plugins打开插件窗口，选择 Btrace workBench 然后一路 next安装 目标程序 准备了一个简单的小程序：从键盘接收两个数字然后计算两个数字之和，主要目的是方便下一步用Btrace来调试打印出方法的参数的值，以及堆栈信息 package org.xuan.trace;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;/** * Created by Xuan on 2016/9/10. */public class BTraceTest public int add(int a ,int b) return a+b; public static void main(String[] args) throws IOException BTraceTest traceTest= new BTraceTest(); BufferedReader reader = new BufferedReader(new InputStreamReader(System.in)); for (int i = 0; i 10; i++) reader.readLine(); int a = (int)Math.round(Math.random()*1000); int b = (int)Math.round(Math.random()*1000); System.out.println(traceTest.add(a,b)); 跟踪程序运行第二步中的小程序，在VisualVM中选中这个虚拟机进程，然后右键Trace application进入到Btrace选项卡在文本框中输入调试的代码： /* BTrace Script Template */import com.sun.btrace.annotations.*;import static com.sun.btrace.BTraceUtils.*;@BTracepublic class TracingScript @OnMethod(clazz=org.xuan.trace.BTraceTest,method=add,location=@Location(Kind.RETURN)) public static void func(@Self org.xuan.trace.BTraceTest instance,int a,int b,@Return int result) println(打印堆栈:); jstack(); println(strcat(方法参数A：,str(a))); println(strcat(方法参数B：,str(b))); println(strcat(方法返回C：,str(result))); 点击run按钮，如果调试代码没错的话,控制台会输出编译通过的信息 * Starting BTrace task** Compiling the BTrace script ...*** Compiled** Instrumenting 1 classes ...*** Done** BTrace uprunning 然后在程序的控制台输入一个字符，程序会给出两个参数以及方法的返回值 打印堆栈:org.xuan.trace.BTraceTest.add(BTraceTest.java:12)org.xuan.trace.BTraceTest.main(Unknown Source)方法参数A：628方法参数B：461方法参数C：1089","tags":["java/jvm"],"categories":["java"]},{"title":"Java List实现group by","path":"/2016/08/22/list-group-by-guava/","content":"一般情况下我们可能很熟悉在数据库中使用group by来分组一些数据，但是如果数据来源不是数据库的话可能就需要通过在代码中实现group by了 例子：比如有一组书Book的集合,我们要按照书的类型(type)分组 package org.xuan;import lombok.AllArgsConstructor;import lombok.Data;@Data@AllArgsConstructorpublic class Book private String name; private String type; private double price; 增加几本书到list List Book bookList =Arrays.asList( new Book(java programming,java,123.1D), new Book(java in concurrency,java,123.2D), new Book(c++ primary,c++,123.3D), new Book(groovy in action,groovy,123.4D), new Book(effective java,java,123.5D), new Book(jvm in practice,java,123.6D), new Book(scala in action,scala,123.7D) ); 使用传统的java来实现group byMapString,ListBook bookMapOld = Maps.newLinkedHashMap();for (IteratorBook iterator = bookList.iterator(); iterator.hasNext(); ) Book book = iterator.next(); String type = book.getType(); if(bookMapOld.containsKey(type)) bookMapOld.get(type).add(book); else ListBook bookList2 = Lists.newLinkedList(); bookList1.add(book); bookMapOld.put(type,bookList1); 使用guava来的multiMap来实现group byMultimaps.asMap(Multimaps.index(bookList, new FunctionBook, String() public String apply(Book input) return input.getType(); )); 使用java 8来实现group byMapString,ListBookbookMap = bookList1.stream().collect(Collectors.groupingBy(b-b.getType(),Collectors.mapping((Book b)-b,Collectors.toList()))); 使用groovy来实现group bygroovy 使用closure来实现groovy by Map bookMap = bookList1.groupByit.getType()","tags":["java/guava"],"categories":["java"]},{"title":"Java NIO创建步骤","path":"/2016/07/18/java-nio-start/","content":"NIO创建过程一、打开ServerSocketChannel,用于监听客户端的连接 ServerSocketChannel acceptSvr = ServerSocketChannel.open(); 二、绑定监听端口，设置连接为非阻塞模式 acceptSvr.socket().bind(new InetSocketAddress(InetAddress.getByName(IP),port));accptSvr.configureBlocking(false); 三、创建Reactor线程，创建多路复用器并启动线程 Selector selector = Selector.open();new Thread(new ReactorTask()).start(); 四、将ServerSocketChannel 注册到Reactor线程的多路多路复用器Selector上，监听ACCEPT事件 SelectionKey key = acceptorSvr.register(selector,SelectionKey.OP_ACCEPT,ioHandler); 五、多路复用器在线程run方法中无限循环体内轮询准备就绪的Key int num = seletor.select();Set selectedKeys = selector.selectedKeys();while(it.hasNext()) SelectionKey key = (SelectionKey)it.next(); //处理IO事件 六、多路复用器监听到新的客户端接入，处理新的接入请求，完成TCP三次握手，简历物理链路 SocketChannel channel = svrChannel.accpet(); 七、设置客户端链路为非阻塞模式 channel.configureBlocking(flase);channel.socket().setReuseAddress(true); 八、将新接入的客户端连接注册到Reactor线程的多路复用器上，监听读操作，用来读取客户端发送的网络消息 SelectionKey key = soccketChannel.register(selector,SelectionKey.OP_READ,ioHandler); 九、异步读取客户端请求消息到缓冲区 int readNumber = channel.read(reaceivedBuffer); 十、对ByteBuffer进行编解码，如果有半包消息指针reset，继续读取后续保温，将解码成功的消息封装成task，投递到业务线程池中，进行业务逻辑编排。 Object message = null;while(buffer.hasRemain()) byteBuffer.mark(); Object message = decode(byteBuffer); if(message == null) byteBuffer.reset(); break; messageList.add(message); if(!byteBuffer.hasRemain()) byteBuffer,clear(); else byteBuffer.compact(); if(messageList != null !messageList.isEmpty) for(Object messageE:messageList) handlerTask(messageE); 十一、将POJO对象encode 成ByteBuffer ,调用SocketChannel的异步write接口，将消息异步发送给客户端。 socketChannel.write(buffer);","tags":["java/nio"],"categories":["java"]},{"title":"Java工程师（后端）技能树","path":"/2016/06/02/java-skill-tree/","content":"我的Java技能树点亮之路 编程思想脱离于语言之上的一些不变的知识 设计模式，重构，Clean Code ，代码大全，Unix编程艺术 算法导论什么的就算了，但是至少得学会实现《数据结构》上的集中最基本的数据结构，java实现 理解 SOA面向服务架构 工具加成让自己的开发工具从小刀变成 Linux shell vim Ngix 工具类 google guava, apache-commons 构建工具maven,gradle Web容器 tomcat 版本控制git java8新特性 mysqlmariadb 数据库进阶，慢查询，数据库引擎，索引 熟悉Http，《图解HTTP》 了解使用noSql，mongodb Java进阶并发编程 熟悉NIOOIO 熟悉一个NIO框架，我选Netty 熟悉JDK java.util.concurrent包的类，BlockQueue,CocurrentHashMap,Semaphore等 再读一遍《Java并发编程》 深入理解Java内存模型 JVM相关 熟悉GC的原理 JVM相关工具使用以及调优 读完《深入Java虚拟机》,并实践 ClassLoader相关深入理解 动态代理，Cglib使用 一些框架 分布式缓存memcached 消息队列ActiveMq实现原理以及使用JMS的使用 深入Spring相关，Spring Boot等 RPC框架Dubbo 深入Mybatis,实现原理，缓存使用等 云相关 Zookeeper，在linux上部署 Hadoop Hive Java之外 学习一门动态语言：Ruby,体会Ruby元编程 使用Rails实现自己的项目 作为Java开发者，Scala自然不能少 学习开源项目 Apache旗下的， Thrift，Tomcat、Mina等","tags":["java/skill_tree"],"categories":["java"]},{"title":"Java内存模型【译】","path":"/2016/05/17/java-memory-model/","content":"本文翻译自 Java Memory Model旨在加深自己对Java Memory Model (JMM)的理解。 The Java memory model specifies how the Java virtual machine works with the computer’s memory (RAM).The Java virtual machine is a model of a whole computer so this model naturally includes a memory model - AKA the Java memory model.It is very important to understand the Java memory model if you want to design correctly behaving concurrent programs.The Java memory model specifies how and when different threads can see values written to shared variables by other threads, and how to synchronize access to shared variables when necessary.The original Java memory model was insufficient, so the Java memory model was revised in Java 1.5. This version of the Java memory model is still in use in Java 8. Java内存模型详述了java虚拟机如何与物理机的RAM的一起工作的，java虚拟机是整个计算机的模型，所以这个模型自然包括内存模型，这个模型卡就是Java内存模型。如果你想正确的设计并发程序，知道Java内存模型是非常重要的java内存模型详解了多个不同的线程是何时而又如何写入一个共享的变量的，还有如何同步的访问一个共享变量。原来的Java内存模型是不足的，所以Java内存模型在java 5中重新修订了，这个版本的java内存模型一直在Java8中还在使用。 内部的java内存模型 The Java memory model used internally in the JVM divides memory between thread stacks and the heap. This diagram illustrates the Java memory model from a logic perspective: Java内存模型将JVM的内存按照线程栈和堆进行分割，下面的图表从逻辑的视图展示了Java内存模型：![enter description here][http://tutorials.jenkov.com/images/java-concurrency/java-memory-model-1.png] Each thread running in the Java virtual machine has its own thread stack.The thread stack contains information about what methods the thread has called to reach the current point of execution. I will refer to this as the “call stack”. As the thread executes its code, the call stack changes.The thread stack also contains all local variables for each method being executed (all methods on the call stack). A thread can only access it’s own thread stack.Local variables created by a thread are invisible to all other threads than the thread who created it. Even if two threads are executing the exact same code,the two threads will still create the local variables of that code in each their own thread stack. Thus, each thread has its own version of each local variable.All local variables of primitive types ( boolean, byte, short, char, int, long, float, double) are fully stored on the thread stack and are thus not visible to other threads.One thread may pass a copy of a pritimive variable to another thread, but it cannot share the primitive local variable itself.The heap contains all objects created in your Java application, regardless of what thread created the object. This includes the object versions of the primitive types (e.g. Byte, Integer, Long etc.).It does not matter if an object was created and assigned to a local variable, or created as a member variable of another object, the object is still stored on the heap. 每一个运行在JVM上的线程都有自己的线程栈，线程栈中包含了线程当前执行点的方法的详细信息，我想这个称之为调用栈,当线程执行了代码，调用栈就发生了变化。线程栈中也包含了所有的正在执行方法（所有在在调用栈中的方法）的局部变量，一个线程只能访问自己的线程栈。被线程创建的本地变量对于其他的线程来说是不可见的,即使两个线程执行同样的代码，这两个线程仍然会在自己的线程栈上创本地变量。所有的原始类型（ boolean, byte, short, char, int, long, float, double）的本地变量全部存储在自己的线程栈中对其他线程不可见，一个线程可以传递一个原始类型的变量给其他线程，但是不能和其他线程共享原始类型的变量。堆中包含了你的java程序中的所有的对象，不管是由哪个线程创建的对象，其中包含了原始类型对应的Wrapper类（Byte, Integer, Long etc），不管一个对象是被分配给一个局部变量还是成员变量，这个对象都仍旧保存在堆上。 Here is a diagram illustrating the call stack and local variables stored on the thread stacks, and objects stored on the heap: 下面是一个图表说明了在线程栈中保存的调用栈，局部变量和在堆中保存的所有对象。![enter description here]http://tutorials.jenkov.com/images/java-concurrency/java-memory-model-2.png] A local variable may be of a primitive type, in which case it is totally kept on the thread stack.A local variable may also be a reference to an object. In that case the reference (the local variable) is stored on the thread stack, but the object itself if stored on the heap.An object may contain methods and these methods may contain local variables. These local variables are also stored on the thread stack, even if the object the method belongs to is stored on the heap.An object’s member variables are stored on the heap along with the object itself. That is true both when the member variable is of a primitive type, and if it is a reference to an object.Static class variables are also stored on the heap along with the class definition.Objects on the heap can be accessed by all threads that have a reference to the object. When a thread has access to an object, it can also get access to that object’s member variables.If two threads call a method on the same object at the same time, they will both have access to the object’s member variables, but each thread will have its own copy of the local variables. 一个局部变量可能是原始类型的，这种情况下，它将完全保存在线程栈上一个局部变量也可能引用一个对象，这个中情况下引用（该局部变量）将会被存储在线程栈中，而被引用的对象将会被存储在堆上。一个对象可能包含多个方法，而这些方法也可能包含局部变量，这些局部变量也将会保存在线程栈上，即使该方法所属的对象是存在堆上的。一个对象的成员变量和对象本身一起被存放在堆上，不管成员变量是基本数据类型的还是引用数据类型的。静态成员变量将会和类定义一起被保存在堆上。在堆上保存的对象可以被所有和这个对象有引用关系的线程访问，当一个线程有权访问一个对象，那么这个线程也能够访问这个对象的成员变量。当两个线程同时调用同一个对象的某个方法，他们将同时拥有该对对象的成员变量的访问权，但是每个线程将会有一份局部变量的副本。 Here is a diagram illustrating the points above: 下图说明上述观点：![enter description here][http://tutorials.jenkov.com/images/java-concurrency/java-memory-model-3.png] Two threads have a set of local variables. One of the local variables (Local Variable 2) point to a shared object on the heap (Object 3).The two threads each have a different reference to the same object.Their references are local variables and are thus stored in eachthread’s thread stack (on each). The two different references point to the same object on the heap, though.Notice how the shared object (Object 3) has a reference to Object 2 and Object 4 as member variables (illustrated by the arrows from Object 3 to Object 2 and Object 4).Via these member variable references in Object 3 the two threads can access Object 2 and Object 4.The diagram also shows a local variable which point to two different objects on the heap. In this case the references point to two different objects (Object 1 and Object 5), not the same object.In theory both threads could access both Object 1 and Object 5, 但是上图中的两个线程都只有两个对象中的一个的引用。if both threads had references to both objects. But in the diagram above each thread only has a reference to one of the two objects. 两个线程都各自一个局部变量的集合，其中的一个局部变量（Local Variable 2）只想了堆上的一个共享对象（Object 3），两个线程对同一个对象有不同的引用。他们的引用都是局部变量并且都被存在自己的线程栈上，尽管两个引用只想堆上的同一个对象。注意到共享对象（Object 3）对 Object 2 和 Object 4 有作为成员变量的引用关系（Object 3指向Object 2和Object 4的箭头）。通过在Object 3 中引用成员变量，这两个线程可以访问Object 2和Object 4 上图也展示了一个指向堆上不同对象的局部变量，这种情况下引用指向了对上的不同对象（Object 1 和Object 5）而不是同一个对象，理论上讲，如果两个各对象都有两个对象的引用的话是可以访问Object 1和Object 5 So, what kind of Java code could lead to the above memory graph? Well, code as simple as the code below: 所以，什么样的Java 代码可以解释上面的内存图，代码简单如下： public class MyRunnable implements Runnable() public void run() methodOne(); public void methodOne() int localVariable1 = 45; MySharedObject localVariable2 = MySharedObject.sharedInstance; //... do more with local variables. methodTwo(); public void methodTwo() Integer localVariable1 = new Integer(99); //... do more with local variable. public class MySharedObject //static variable pointing to instance of MySharedObject public static final MySharedObject sharedInstance = new MySharedObject(); //member variables pointing to two objects on the heap public Integer object2 = new Integer(22); public Integer object4 = new Integer(44); public long member1 = 12345; public long member1 = 67890; If two threads were executing the run() method then the diagram shown earlier would be the outcome. The run() method calls methodOne() and methodOne() calls methodTwo().methodOne() declares a primitive local variable (localVariable1 of type int) and an local variable which is an object reference (localVariable2).Each thread executing methodOne() will create its own copy of localVariable1 and localVariable2 on their respective thread stacks.The localVariable1 variables will be completely separated from each other, only living on each thread’s thread stack.One thread cannot see what changes another thread makes to its copy of localVariable1. 如果两个方法同时执行 run()方法，run()方法调用methodOne()然后 methodOne()调用 methodTwo()methodOne() 声明了一个基本数据类型的局部变量（int类型 localVariable1）和一个引用数据类型的局部变量（localVariable2）每一个线程在执行methodOne()时将会创建 localVariable1 和localVariable2的副本在各自的线程栈。局部变量 localVariable1 将会和其他的变量分割开来，仅仅存活在自己线程的线程栈中。线程不能够看到其他线程对localVariable1变量副本做出的改变。 Each thread executing methodOne() will also create their own copy of localVariable2.However, the two different copies of localVariable2 both end up pointing to the same object on the heap.The code sets localVariable2 to point to an object referenced by a static variable.There is only one copy of a static variable and this copy is stored on the heap.Thus, both of the two copies of localVariable2 end up pointing to the same instance of MySharedObject which the static variable points to.The MySharedObject instance is also stored on the heap. It corresponds to Object 3 in the diagram above.Notice how the MySharedObject class contains two member variables too. The member variables themselves are stored on the heap along with the object.The two member variables point to two other Integer objects. These Integer objects correspond to Object 2 and Object 4 in the diagram above.Notice also how methodTwo() creates a local variable named localVariable1. This local variable is an object reference to an Integer object.The localVariable1 reference will be stored in one copy per thread executing methodTwo().The method sets the localVariable1 reference to point to a new Integer instance.The two Integer objects instantiated will be stored on the heap, but since the method creates a new Integer object every time the method is executed, two threads executing this method will create separate Integer instances.The Integer objects created inside methodTwo() correspond to Object 1 and Object 5 in the diagram above.Notice also the two member variables in the class MySharedObject of type long which is a primitive type.Since these variables are member variables, they are still stored on the heap along with the object. Only local variables are stored on the thread stack. 每个线程执行methodOne()时也将会创建它们各自的localVariable2拷贝。然而，两个localVariable2的不同拷贝都指向堆上的同一个对象。 代码中通过一个静态变量设置localVariable2指向一个对象引用。 仅存在一个静态变量的一份拷贝，这份拷贝存放在堆上。 因此，localVariable2的两份拷贝都指向由MySharedObject指向的静态变量的同一个实例。 MySharedObject实例也存放在堆上。它对应于上图中的Object3。注意，MySharedObject类也包含两个成员变量，这些成员变量随着这个对象存放在堆上。这两个成员变量指向另外两个Integer对象。这些Integer对象对应于上图中的Object2和Object4.注意，methodTwo()创建一个名为localVariable的本地变量。这个成员变量是一个指向一个Integer对象的对象引用。这个方法设置localVariable1引用指向一个新的Integer实例。在执行methodTwo方法时，localVariable1引用将会在每个线程中存放一份拷贝。这两个Integer对象实例化将会被存储堆上，但是每次执行这个方法时，这个方法都会创建一个新的Integer对象，两个线程执行这个方法将会创建两个不同的Integer实例。methodTwo()方法创建的Integer对象对应于上图中的Object1和Object5。注意，MySharedObject类中的两个long类型的成员变量是原始类型的。因为，这些变量是成员变量，所以它们任然随着该对象存放在堆上，仅有本地变量存放在线程栈上。 硬件的内存架构（TODO）","tags":["java/thread"],"categories":["java"]},{"title":"cURL命令的使用","path":"/2016/05/08/how-use-curl/","content":"Linux curl命令的使用 参考官方文档 https://curl.haxx.se/docs/manpage.html 一、什么是cURL wikipedia中的解释如下： cURL是一个利用URL语法在命令行下工作的文件传输工具，1997年首次发行。它支持文件上传和下载，所以是综合传输工具，但按传统，习惯称cURL为下载工具。cURL还包含了用于程序开发的libcurl。 cURL支持的通信协议有FTP、FTPS、HTTP、HTTPS、TFTP、SFTP、Gopher、SCP、Telnet、DICT、FILE、LDAP、LDAPS、IMAP、POP3、SMTP和RTSP。 简单的说，cURL就是把发出请求然后得到响应并把响应数据显示到标准输出上的一个命令行工具。 语法： curl [option] [URL] 二、cURL的用法1. 保存curl的结果到文件curl -o [filename] [URL] 比如要保存 http://zeusjava.com 到blog.html中，可以使用 curl -o blog.html http://zeusjava.com 当然，也可以直接用 curl http://zeusjava.com blog.html $ curl -o blog.html http://zeusjava.com 使用 -o 也可以用于下载文件 curl -o android-studio-2.0.exe https://dl.google.com/dl/android/studio/install/2.0.0.20/android-studio-bundle-143.2739321-windows.exe 使用 -O可以将下载的文件名自动命名为服务器端文件的名字 curl -O https://dl.google.com/dl/android/studio/install/2.0.0.20/android-studio-bundle-143.2739321-windows.exe 2.显示http response的Header信息curl -i [URL] 比如 curl -i http://zeusjava.com 服务器返回的Header信息如下： HTTP/1.1 200 OKServer: GitHub.comContent-Type: text/html; charset=utf-8Last-Modified: Thu, 14 Apr 2016 05:39:44 GMTAccess-Control-Allow-Origin: *Expires: Mon, 02 May 2016 22:38:46 GMTCache-Control: max-age=600X-GitHub-Request-Id: 17EB2B23:6096:A5D8C82:5727D49CContent-Length: 16009Accept-Ranges: bytesDate: Sat, 07 May 2016 10:25:24 GMTVia: 1.1 varnishAge: 0Connection: keep-aliveX-Served-By: cache-ams4129-AMSX-Cache: HITX-Cache-Hits: 1Vary: Accept-EncodingX-Fastly-Request-ID: cd84d46856e9a80b4a283db2225e8caeb0d439b0 由于使用过的是Github Pages 所以Server是Github.com 3.显示Http request和 response的Header信息curl -v [URL] -v选项可以向标准输出中打印和Server的通信过程的信息，包括 http request和http response的信息下面是和zeusjava.com的通信过程的头部信息： * Rebuilt URL to: http://www.zhihu.com/* Trying 58.216.25.33...* Connected to www.zhihu.com (58.216.25.33) port 80 (#0) GET / HTTP/1.1 Host: www.zhihu.com User-Agent: curl/7.48.0 Accept: */* HTTP/1.1 200 OK Server: ZWS Connection: keep-alive Date: Mon, 13 Jun 2016 06:28:32 GMT Cache-Control: no-store Content-Type: text/html; charset=UTF-8 Content-Length: 8440 X-Za-Response-Id: 1be55a9577484a62ae8289e23216dfdb Content-Security-Policy: default-src *; img-src * data:; frame-src self *.zhihu.com getpocket.com note.youdao.com; script-src self *.zhihu.com *.google-analytics.com zhstatic.zhihu.com res.wx.qq.com unsafe-eval; style-src self *.zhihu.com unsafe-inline Set-Cookie: q_c1=3af89a60e8454cad977358c33bff9823|1465799312000|1465799312000; Domain=zhihu.com; expires=Thu, 13 Jun 2019 06:28:32 GMT; Path=/ Set-Cookie: _xsrf=ed72c7326f8de881578826312673cebe; Path=/ Set-Cookie: l_cap_id=OTlmZjM4OGQ4YzEyNDkwNmJjMzQxM2NiZThlOGY3MDI=|1465799312|380fb662f09187c07ae84e38dc694197feae1f09; Domain=zhihu.com; expires=Wed, 13 Jul 2016 06:28:32 GMT; Path=/ Set-Cookie: cap_id=NDZhN2I5ZmM0ZjZlNGQxOWI4MDhkZTg0ZTZlMTU1ZDA=|1465799312|fc2935c8732a53b5216bbffebbceed1cf179f5ab; Domain=zhihu.com; expires=Wed, 13 Jul 2016 06:28:32 GMT; Path=/ Set-Cookie: n_c=1; Domain=zhihu.com; Path=/ Pragma: no-cache X-Frame-Options: DENY X-Req-ID: 43CAD096575E5290 Vary: Accept-Encoding 4. HTTP动词Http的动词有，GET,POST,PUT,DELETE等 curl -X [动词] [URL] curl默认的动作为 GET 3.1 FORM GET请求curl [-X GET] zeusjava.com/articles?article_id=1 3.2 FORM POST请求curl -X POST --data[-urlencode] article_id=1 zeusjava.com 如果需要对表单参数进行编码的话，在–data后再加上-urlencode选项 5. 使用Cookiescurl --cookie key=value [URL] cookie是客户端保存的服务端的一些信息,形式为key-value键值对，可以从Server的response的Set-Cookie中获得 使用 -c 选项，可以保存服务器的cookie到本地的文件中 curl -c [cookies file] [URL] 比如我保存 知乎的cookie到本地的cookies中 curl -c cookies.txt http://www.zhihu.com 得到的cookies.txt如下： # Netscape HTTP Cookie File# http://curl.haxx.se/docs/http-cookies.html# This file was generated by libcurl! Edit at your own risk..zhihu.com\tTRUE\t/\tFALSE\t0\tl_n_c\t1.zhihu.com\tTRUE\t/\tFALSE\t1557273691\tq_c1\t5130907cc98041298bb4a42fafa2fe5d|1462665691000|1462665691000www.zhihu.com\tFALSE\t/\tFALSE\t0\t_xsrf\tf3e5105c5196dffc93c5eefcbb1d2b55.zhihu.com\tTRUE\t/\tFALSE\t1465257691\tcap_id\tZWQ2ZDIyNmQ2NjZjNDNjYzg1Y2QyZjE3ZjU5ZGM1YWY=|1462665691|258e372f45b5610e483a25bfa3dde1debd56ca08.zhihu.com\tTRUE\t/\tFALSE\t1465257691\tl_cap_id\tNjMxYTliZGVkOWZlNDBmZDhjY2M2M2VjY2Y1MDQ0YTI=|1462665691|878a16bb3c5376f14a0d837c19db994c66b6b668.zhihu.com\tTRUE\t/\tFALSE\t0\tn_c\t1 使用 -b选项，将本地的cookies文件发送至服务器端 curl -b cookies.txt http://www.zhihu.com 6.使用User-Agent User Agent：字面意思就是用户代理，可以简单理解为访问设备的一种标识（这个标识指所代表的平台（黑莓、iPhone、Windows等）、浏览器（Chrome、IE、Safari等）、以及浏览器的版本等等），其实它包含的信息是比较多的。 下面是一个User-Agent的例子: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36 Mozilla声明了一个基于Mozilla的浏览器User-Agent，比如firefox,netscape等,Windows NT 10.0表示操作系统为 Windows 10等 curl -A [User-Agent] [URL] curl --user-agent [User-Agent] [URL] 很多网站都会根据浏览器的User-Agent来响应不同的页面风格，叫做响应式设计，比如ipad请求 www.zhihu.com浏览器就会根据ipad的页面尺寸来适配ipad的屏幕大小。 7.文件上传使用curl来模拟表单的文件上传 form method=POST enctype=multipart/form-data action=upload.do input type=file name=headimage input type=submit name =click value=点击上传 /form $ curl –form headimage@localfile –form click点击上传 [URL] 三、总结当然curl的命令不止这么多，用到哪些在做补充","tags":["linux/curl"],"categories":["技术随笔"]},{"title":"Spring MVC源码探究","path":"/2016/04/06/spring-mvc-source-code/","content":"作为一名合格的java程序员，要多深入学习一些框架，理解框架的设计的方法，背后的原理，spring mvc框架中使用了很多设计模式，比如策略模式，Spring MVC中大量使用了策略模式，像HandlerMapping接口，HandlerAdapter接口,ViewResolver接口都使用了策略模式，在执行handler和Interceptor拦截器的时候使用了责任链模式，在执行handler的时候会用到适配器模式等等，可以说沉淀了很多前辈的精华，想成为架构师的话，学习源码必不可少，下面就围绕着Spring MVC 的前端控制器DispatcherServlet一步一步的来学习Spring MVC的源码。 1 web.xml中DispatcherServlet的配置web.xml中的Spring MVC的前端控制器DispatcherServlet的配置，所有后端Controller的请求都由这个DispatcherServlet分发。 servlet servlet-nameMySpringServlet/servlet-name servlet-classorg.springframework.web.servlet.DispatcherServlet/servlet-class init-param param-namecontextConfigLocation/param-name param-valueclasspath:spring/spring-mvc.xml/param-value /init-param /servlet servlet-mapping servlet-nameMySpringServlet/servlet-name url-pattern//url-pattern /servlet-mapping DispatcherServlet 类等级视图 DispactcherServlet 中的doService()方法/** * Exposes the DispatcherServlet-specific request attributes and delegates to @link #doDispatch * for the actual dispatching. */\t@Override\tprotected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception if (logger.isDebugEnabled()) String resumed = WebAsyncUtils.getAsyncManager(request).hasConcurrentResult() ? resumed : ; logger.debug(DispatcherServlet with name + getServletName() + + resumed + processing + request.getMethod() + request for [ + getRequestUri(request) + ]); // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. MapString, Object attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) attributesSnapshot = new HashMapString, Object(); Enumeration? attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(org.springframework.web.servlet)) attributesSnapshot.put(attrName, request.getAttribute(attrName)); // Make framework objects available to handlers and view objects. request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); try //执行dispatch方法 doDispatch(request, response); finally if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) return; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) restoreAttributesAfterInclude(request, attributesSnapshot); doService方法实现了抽象类FrameworkServlet的doService方法，在doService方法中调用了doDispatcher()方法处理分发请求 2.DipatcherServlet的doDispatcher()方法doService方法中将请求委托给doDispatch()方法由doDispatch()来分发相应的请求给各个Handler(Controller),我在每一个关键步骤上标注了注释，下面还有相应的源码解释。 /** * Process the actual dispatching to the handler. * pThe handler will be obtained by applying the servlets HandlerMappings in order. * The HandlerAdapter will be obtained by querying the servlets installed HandlerAdapters * to find the first that supports the handler class. * pAll HTTP methods are handled by this method. Its up to HandlerAdapters or handlers * themselves to decide which methods are acceptable. * @param request current HTTP request * @param response current HTTP response * @throws Exception in case of any kind of processing failure */protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception HttpServletRequest processedRequest = request;\tHandlerExecutionChain mappedHandler = null;\tboolean multipartRequestParsed = false;\tWebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\ttry ModelAndView mv = null; Exception dispatchException = null; try //1.检测是否是多媒体请求，比如文件上传，将HttpServletRequest包装为MultipartHttpServletRequest processedRequest = checkMultipart(request); multipartRequestParsed = processedRequest != request; //2.遍历所有的HandlerMapper对象根据请求的URL获得相应的HandlerExecutionChain，其中HandlerMapping是一个 //接口，Spring给出了一个默认的实现配置在DispatcherServlet.properties文件中，如果找不到对应的HandlerMap//per，spring会给出提示 No mapping found for HTTP request with URI... mappedHandler = getHandler(processedRequest); if (mappedHandler == null || mappedHandler.getHandler() == null) noHandlerFound(processedRequest, response); return; //3.根据当前的request遍历所有的Adapter选择第一个支持的adapter，这里使用了责任链模式 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. //4.处理 last-modified header 判断是否被handler支持 String method = request.getMethod(); boolean isGet = GET.equals(method); if (isGet || HEAD.equals(method)) long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) logger.debug(Last-Modified value for [ + getRequestUri(request) + ] is: + lastModified); if (new ServletWebRequest(request, response).checkNotModified(lastModified) isGet) return; //5.执行handler的拦截器的preHandle方法 if (!mappedHandler.applyPreHandle(processedRequest, response)) return; try // 6.调用真正的handler，处理业务代码 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); finally if (asyncManager.isConcurrentHandlingStarted()) return; applyDefaultViewName(request, mv); //7.执行handler的拦截器的postHandle方法 mappedHandler.applyPostHandle(processedRequest, response, mv); catch (Exception ex) dispatchException = ex; //8.处理返回结果视图 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); catch (Exception ex) triggerAfterCompletion(processedRequest, response, mappedHandler, ex); catch (Error err) triggerAfterCompletionWithError(processedRequest, response, mappedHandler, err); finally if (asyncManager.isConcurrentHandlingStarted()) // Instead of postHandle and afterCompletion mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); return; // Clean up any resources used by a multipart request. if (multipartRequestParsed) cleanupMultipart(processedRequest); 1. 根据request获得所有的HandlerMapping并匹配一个合适的Handler（Controller）AbstractHandlerMapping实现了HandlerMapping接口 1：遍历所有intercepter，取指定接口的拦截器bean 2：根据url找到对应的hander 3：封装成chain @Override\tpublic final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception Object handler = getHandlerInternal(request); if (handler == null) handler = getDefaultHandler(); if (handler == null) return null; // Bean name or resolved handler? if (handler instanceof String) String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); return getHandlerExecutionChain(handler, request); /**\tprotected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler)); chain.addInterceptors(getAdaptedInterceptors()); String lookupPath = this.urlPathHelper.getLookupPathForRequest(request); for (MappedInterceptor mappedInterceptor : this.mappedInterceptors) if (mappedInterceptor.matches(lookupPath, this.pathMatcher)) chain.addInterceptor(mappedInterceptor.getInterceptor()); return chain; AbstractUrlHandlerMapping继承了AbstractHandlerMapping重写了getHandlerInternal()抽象方法。这个方法给出了根据请求的URL获得handler的实现方法。 /** * Look up a handler for the URL path of the given request. * @param request current HTTP request * @return the handler instance, or @code null if none found */\t@Override\tprotected Object getHandlerInternal(HttpServletRequest request) throws Exception String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); Object handler = lookupHandler(lookupPath, request); if (handler == null) // We need to care for the default handler directly, since we need to // expose the PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE for it as well. Object rawHandler = null; if (/.equals(lookupPath)) rawHandler = getRootHandler(); if (rawHandler == null) rawHandler = getDefaultHandler(); if (rawHandler != null) // Bean name or resolved handler? if (rawHandler instanceof String) String handlerName = (String) rawHandler; rawHandler = getApplicationContext().getBean(handlerName); validateHandler(rawHandler, request); handler = buildPathExposingHandler(rawHandler, lookupPath, lookupPath, null); if (handler != null logger.isDebugEnabled()) logger.debug(Mapping [ + lookupPath + ] to + handler); else if (handler == null logger.isTraceEnabled()) logger.trace(No handler mapping found for [ + lookupPath + ]); return handler; 2.获得HandlerExecutionChain/** * Return the HandlerExecutionChain for this request. * pTries all handler mappings in order. * @param request current HTTP request * @return the HandlerExecutionChain, or @code null if no handler could be found */\tprotected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception for (HandlerMapping hm : this.handlerMappings) if (logger.isTraceEnabled()) logger.trace( Testing handler map [ + hm + ] in DispatcherServlet with name + getServletName() + ); HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) return handler; return null; HandlerExecutionChain是由一系列的Handler和HandlerInterceptor组成的责任链，下面是HandlerExecutionChain中的成员变量 private static final Log logger = LogFactory.getLog(HandlerExecutionChain.class);\tprivate final Object handler;\tprivate HandlerInterceptor[] interceptors;\tprivate ListHandlerInterceptor interceptorList;\tprivate int interceptorIndex = -1; 3.根据相应的handler去获得合适的HandlerAdapterHandlerAdapter package org.springframework.web.servlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public interface HandlerAdapter boolean supports(Object handler);\tModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception;\tlong getLastModified(HttpServletRequest request, Object handler); HandlerAdapter的实现类HttpRequestHandlerAdapter，在DispatcherServlet.properties文件配置的默认实现的其中之一，在HandlerAdapter中执行Handler（Controller）的方法，并且给前端控制器DispatcherServlet返回一个ModelAndView /* * Copyright 2002-2012 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the License); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an AS IS BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.springframework.web.servlet.mvc;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.web.HttpRequestHandler;import org.springframework.web.servlet.HandlerAdapter;import org.springframework.web.servlet.ModelAndView;/** * Adapter to use the plain @link org.springframework.web.HttpRequestHandler * interface with the generic @link org.springframework.web.servlet.DispatcherServlet. * Supports handlers that implement the @link LastModified interface. */public class HttpRequestHandlerAdapter implements HandlerAdapter //判断是否适配当前adapter\t@Override\tpublic boolean supports(Object handler) return (handler instanceof HttpRequestHandler); @Override\tpublic ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception ((HttpRequestHandler) handler).handleRequest(request, response); return null; @Override\tpublic long getLastModified(HttpServletRequest request, Object handler) if (handler instanceof LastModified) return ((LastModified) handler).getLastModified(request); return -1L; HttpRequestHandler接口的实现类ResourceHttpRequestHandler,handleRequest()方法用来处理请求返回结果，数据转化，数据校验，格式化等操作都是在这一步进行。比如自动将Json数据转换为对应的实体等。 /** * Processes a resource request. * pChecks for the existence of the requested resource in the configured list of locations. * If the resource does not exist, a @code 404 response will be returned to the client. * If the resource exists, the request will be checked for the presence of the * @code Last-Modified header, and its value will be compared against the last-modified * timestamp of the given resource, returning a @code 304 status code if the * @code Last-Modified value is greater. If the resource is newer than the * @code Last-Modified value, or the header is not present, the content resource * of the resource will be written to the response with caching headers * set to expire one year in the future. */@Overridepublic void handleRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException checkAndPrepare(request, response, true);\t// check whether a matching resource exists\tResource resource = getResource(request);\tif (resource == null) logger.debug(No matching resource found - returning 404); response.sendError(HttpServletResponse.SC_NOT_FOUND); return; // check the resources media type\tMediaType mediaType = getMediaType(resource);\tif (mediaType != null) if (logger.isDebugEnabled()) logger.debug(Determined media type + mediaType + for + resource); else if (logger.isDebugEnabled()) logger.debug(No media type found for + resource + - not sending a content-type header); // header phase\tif (new ServletWebRequest(request, response).checkNotModified(resource.lastModified())) logger.debug(Resource not modified - returning 304); return; setHeaders(response, resource, mediaType);\t// content phase\tif (METHOD_HEAD.equals(request.getMethod())) logger.trace(HEAD request - skipping content); return; writeContent(response, resource); 4.处理返回结果视图处理异常视图 /** * Handle the result of handler selection and handler invocation, which is * either a ModelAndView or an Exception to be resolved to a ModelAndView. */\tprivate void processDispatchResult(HttpServletRequest request, HttpServletResponse response, HandlerExecutionChain mappedHandler, ModelAndView mv, Exception exception) throws Exception boolean errorView = false; if (exception != null) if (exception instanceof ModelAndViewDefiningException) logger.debug(ModelAndViewDefiningException encountered, exception); mv = ((ModelAndViewDefiningException) exception).getModelAndView(); else Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); //处理异常视图 mv = processHandlerException(request, response, handler, exception); errorView = (mv != null); // Did the handler return a view to render? if (mv != null !mv.wasCleared()) render(mv, request, response); if (errorView) WebUtils.clearErrorRequestAttributes(request); else if (logger.isDebugEnabled()) logger.debug(Null ModelAndView returned to DispatcherServlet with name + getServletName() + : assuming HandlerAdapter completed request handling); if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) // Concurrent handling started during a forward return; if (mappedHandler != null) mappedHandler.triggerAfterCompletion(request, response, null); 渲染指定的 ModelAndView /** * Render the given ModelAndView. * pThis is the last stage in handling a request. It may involve resolving the view by name. * @param mv the ModelAndView to render * @param request current HTTP servlet request * @param response current HTTP servlet response * @throws ServletException if view is missing or cannot be resolved * @throws Exception if theres a problem rendering the view */protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception // Determine locale for request and apply it to the response.\tLocale locale = this.localeResolver.resolveLocale(request);\tresponse.setLocale(locale);\tView view;\tif (mv.isReference()) // We need to resolve the view name. view = resolveViewName(mv.getViewName(), mv.getModelInternal(), locale, request); if (view == null) throw new ServletException(Could not resolve view with name + mv.getViewName() + in servlet with name + getServletName() + ); else // No need to lookup: the ModelAndView object contains the actual View object. view = mv.getView(); if (view == null) throw new ServletException(ModelAndView [ + mv + ] neither contains a view name nor a + View object in servlet with name + getServletName() + ); // Delegate to the View object for rendering.\tif (logger.isDebugEnabled()) logger.debug(Rendering view [ + view + ] in DispatcherServlet with name + getServletName() + ); try view.render(mv.getModelInternal(), request, response); catch (Exception ex) if (logger.isDebugEnabled()) logger.debug(Error rendering view [ + view + ] in DispatcherServlet with name + getServletName() + , ex); throw ex; 3.DispatcherServlet.propertiesDispatcherServlet.properties中配置的一些DispatcherServlet的一些策略模式接口的实现，包括HandlerMapping，HandlerAdapter，ViewResolver等 # Default implementation classes for DispatcherServlets strategy interfaces.# Used as fallback when no matching beans are found in the DispatcherServlet context.# Not meant to be customized by application developers.org.springframework.web.servlet.LocaleResolver=org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolverorg.springframework.web.servlet.ThemeResolver=org.springframework.web.servlet.theme.FixedThemeResolverorg.springframework.web.servlet.HandlerMapping=org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping,\\\torg.springframework.web.servlet.mvc.annotation.DefaultAnnotationHandlerMappingorg.springframework.web.servlet.HandlerAdapter=org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter,\\\torg.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter,\\\torg.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapterorg.springframework.web.servlet.HandlerExceptionResolver=org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerExceptionResolver,\\\torg.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver,\\\torg.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolverorg.springframework.web.servlet.RequestToViewNameTranslator=org.springframework.web.servlet.view.DefaultRequestToViewNameTranslatororg.springframework.web.servlet.ViewResolver=org.springframework.web.servlet.view.InternalResourceViewResolverorg.springframework.web.servlet.FlashMapManager=org.springframework.web.servlet.support.SessionFlashMapManager 4.总结下图是Spring MVC 工作流程的时序图 1. 用户向服务器发送请求，请求被Spring 前端控制Servelt DispatcherServlet捕获； 2. DispatcherServlet对请求URL进行解析，得到请求资源标识符（URI）。然后根据该URI，调用HandlerMapping获得该Handler配置的所有相关的对象（包括Handler对象以及Handler对象对应的拦截器），最后以HandlerExecutionChain对象的形式返回； 3. DispatcherServlet 根据获得的Handler，选择一个合适的HandlerAdapter。（附注：如果成功获得HandlerAdapter后，此时将开始执行拦截器的preHandler(...)方法） 4. 提取Request中的模型数据，填充Handler入参，开始执行Handler（Controller)。 在填充Handler的入参过程中，根据你的配置，Spring将帮你做一些额外的工作： HttpMessageConveter： 将请求消息（如Json、xml等数据）转换成一个对象，将对象转换为指定的响应信息 数据转换：对请求消息进行数据转换。如String转换成Integer、Double等 数据根式化：对请求消息进行数据格式化。 如将字符串转换成格式化数字或格式化日期等 数据验证： 验证数据的有效性（长度、格式等），验证结果存储到BindingResult或Error中 5. Handler执行完成后，向DispatcherServlet 返回一个ModelAndView对象； 6. 根据返回的ModelAndView，选择一个适合的ViewResolver（必须是已经注册到Spring容器中的ViewResolver)返回给DispatcherServlet ； 7. ViewResolver 结合Model和View，来渲染视图 8. 将渲染结果返回给客户端。","tags":["java/spring"],"categories":["spring框架"]},{"title":"Java集合中的Fail-fast和Fail-Safe机制","path":"/2016/03/23/java-collection-failfast-failsafe/","content":"1.何为Fail-fast和Fail-Safe机制？java.util包里的Iterator 抛出 ConcurrentModificationException异常， 在集合迭代的时候被集合的add方法或者 remove方法调用。fail-fast 指java的集合的一种错误机制，当多个线程对集合修改操作的时候就可能抛出ConcurrentModificationException异常。 java.util.concurrent包里的Iterator 通过迭代一个集合的snapshot 允许并发修改集合，但是在迭代器创建之后可能不反映Collection更新。fail-safe机制意味着多个线程在操作同一个集合的时候，不会出现ConcurrentModificationException异常,但是需要复制集合获得集合的快照，所以性能上开销会比非同步的集合开销要大。 多线程环境下用java.util.concurrent包里的集合替代 java.util包里的集合，比如 CopyOnWriteListArrayList,ConcurrentHashMapHashMap etc. 2.JDK中的源码分析下面代码是JDK1.7源码中ArrayList中的ListIterator，当Iterator创建时，当前的计数器modCount 赋值给Iterator对象,注意到modCount是一个 transient类型的成员变量，transient说明了计数器将不被序列化。 protected transient int modCount = 0; modCount用来记录List修改的次数的计数器，每修改一次(添加删除等操作)，将modCount+1，例如 add()方法： public void add(int index, E element) rangeCheckForAdd(index); checkForComodification(); l.add(index+offset, element); this.modCount = l.modCount; size++; 当Iterator执行相应操作的时候，会先检验两个计数器的值是否相等，如果不相等就抛出ConcurrentModificationException 异常。 /** * An optimized version of AbstractList.Itr */ private class Itr implements IteratorE int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() return cursor != size; @SuppressWarnings(unchecked) public E next() checkForComodification(); int i = cursor; if (i = size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i = elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; public void remove() if (lastRet 0) throw new IllegalStateException(); checkForComodification(); try ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; catch (IndexOutOfBoundsException ex) throw new ConcurrentModificationException(); final void checkForComodification() if (modCount != expectedModCount) throw new ConcurrentModificationException(); CopyOnWriteArrayList的Iterator，可以看到COWIterator在构造函数初始化的时候把集合中的元素保存了一份快照，所有的操作都在快照上面进行的。CopyOnWriteArrayList的Iterator实现类中，checkForComodification()方法，也没有抛出ConcurrentModificationException异常！ private static class COWIteratorE implements ListIteratorE /** Snapshot of the array */ private final Object[] snapshot; /** Index of element to be returned by subsequent call to next. */ private int cursor; private COWIterator(Object[] elements, int initialCursor) cursor = initialCursor; snapshot = elements; public boolean hasNext() return cursor snapshot.length; public boolean hasPrevious() return cursor 0; @SuppressWarnings(unchecked) public E next() if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++]; @SuppressWarnings(unchecked) public E previous() if (! hasPrevious()) throw new NoSuchElementException(); return (E) snapshot[--cursor]; public int nextIndex() return cursor; public int previousIndex() return cursor-1; /** * Not supported. Always throws UnsupportedOperationException. * @throws UnsupportedOperationException always; ttremove/tt * is not supported by this iterator. */ public void remove() throw new UnsupportedOperationException(); /** * Not supported. Always throws UnsupportedOperationException. * @throws UnsupportedOperationException always; ttset/tt * is not supported by this iterator. */ public void set(E e) throw new UnsupportedOperationException(); /** * Not supported. Always throws UnsupportedOperationException. * @throws UnsupportedOperationException always; ttadd/tt * is not supported by this iterator. */ public void add(E e) throw new UnsupportedOperationException();","tags":["java/collection"],"categories":["java"]},{"title":"学习Java的NIO","path":"/2016/02/28/learn-java-nio/","content":"重要的概念 什么是NIO?NIO是从java 1.4 开始引入的一个新的 IO API。 Channel、Buffer、Selector是NIO的核心部分。 IO通过字节流和字符流操作数据，NIO基于通道(Channel)和缓冲区(Buffer)数据 ChannelBufferChannel数据总是由通道到缓冲区（Read），或者由缓冲区到通道（write） 其中Channel的几个实现 FileChannel DatagramChannel SocketChannel ServerSocketChannel 分别对应文件IOUDPTCP网络IO. 下面是一个简单的例子实现，从本地文件系统读取数据到Buffer中。 /** * Channel的使用 */ @Test public void fileChannelTest() try RandomAccessFile randomAccessFile = new RandomAccessFile(D:/nio.txt,rw); FileChannel fileChannel = randomAccessFile.getChannel(); ByteBuffer byteBuffer = ByteBuffer.allocate(100); int bytesRead = fileChannel.read(byteBuffer); while (bytesRead != -1) System.out.println(Read:+bytesRead); byteBuffer.flip(); while(byteBuffer.hasRemaining()) System.out.print((char)byteBuffer.get()); byteBuffer.clear(); bytesRead = fileChannel.read(byteBuffer); randomAccessFile.close(); catch (FileNotFoundException e) e.printStackTrace(); catch (IOException e) e.printStackTrace(); BufferBuffer的几个重要实现 ByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 可以通过这些Buffer向Channel数据，或者从Channel读取数据。 使用Buffer来读写数据的步骤 写入数据到Buffer 调用flip()方法 从Buffer中读取数据 调用clear()方法或者compact() 方法 clear()方法会清空整个缓冲区，而compact会清空已经读取过的数据。 Buffer的三个属性，position,limit,capacity capacity 是缓冲区的大小position 写数据时：position表示是当前位置，当前位置写入完毕，position移动到下一个可写的位置， 范围为0~capacity-1.读数据时：position表示当前位置，当前位置读取完毕，position移动到下一个可读位置。 limitlimit表示的是最多能够读取的或者写入的数据的大小。写模式：limit等于capacity读模式：limit等于读模式的position 分配buffer使用allocate()方法来分配Buffer.例如分配一个100字节长的ByteBuffer缓冲区: ByteBuffer buf = ByteBuffer.allocate(100); 向Buffer中写入数据1.从channel中读取到Buffer中 int bytesRead = inChannel.read(buffer); 2.直接向buffer中put buffer.put(100); 从Buffer中读取数据 1.从Buffer中写数据到Channel int bytesRead inChannel.write(buffer);2.使用get()方法从Buffer中读取数据 int bytes buffer.get(); rewind()方法 rewind()方法将position设置为0 Selector Selector最重要的特点就是他允许单线程处理多个Channel. 1.创建Selector 使用Selector的open()方法创建一个Selector Selector selector = Selector.open(); 2.注册Channel 将Channel绑定到一起，使用channel.register()来实现。 channel.configureBlocking(false);Selector key = channel.register(selector,Selectionkey.OP_READ); configureBlocking是设置Channel为非阻塞模式。FileChannel不能和Selector绑定，因为FileChannel没有阻塞模式。 3.SelectionKey SelectorKey是一个抽象类 包含了 interest集合 ready集合 Channel Selector 1.interest集合通过Selector监听Channel时对什么事件感兴趣，可以监听4中类型的事件，分别是OP_CONNECT,OP_ACCEPT,OP_READ,OP_WRITE。 int interestSet = selectionKey.interestOps(); boolean isInterestedInAccept = (interestSet SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT； boolean isInterestedInConnect = interestSet SelectionKey.OP_CONNECT; boolean isInterestedInRead = interestSet SelectionKey.OP_READ; boolean isInterestedInWrite = interestSet SelectionKey.OP_WRITE; 通过来和SelectorKey常量确定某个事件是在interest集合中。 2.ready集合 ready集合是Channel已经准备就绪的集合。 selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); 3.通过Selector的select()方法选择Channel使用selector的select()方法来返回已经就绪的通道。select()方法会一直阻塞到至少有一个通道在事件上注册了。select()方法返回的int值表示已经有多少个通道已经就绪了4.调用过select()方法后，如果返回的int值大于1则表示已经有至少一个通道已经就绪了，这个时候可以调用Selector的selectedKeys()方法来选择已经就绪的Channel. Set selectKeys = selector.selectedKeys(); 遍历这个集合来访问就绪的通道。 SetSelectionKey selectedKeys = selector.selectedKeys();IteratorSelectionKey keyIterator = selectedKeys.iterator();while(keyIterator.hasNext()) SelectionKey key = keyIterator.next(); if(key.isAcceptable()) else if (key.isConnectable()) else if (key.isReadable()) else if (key.isWritable()) ng keyIterator.remove();","tags":["java/nio"],"categories":["java"]},{"title":"Scala中的特质","path":"/2016/02/23/trait-in-scala/","content":"特质的构造顺序 1. 超类的构造器 2. 特质由左至右构造 3. 每个特质中，父特质先被构造 4. 多个特质公用一个父特质，而那个特质已经被构造，则不会被再次构造 5. 所有特质构造完毕，子类被构造 eg： 其中 FileLogger和ShortLogger都继承Logger特质 calss SavingsAccount extends Account with FileLogger with ShortLogger 构造顺序 1.Account（超类） 2.Logger（第一个特质的父特质） 3.FileLogger（第一个特质） 4.ShortLogger（第一个特质） 5.SavingAccount（类） JVM中的特质 由于scala在jvm中运行，所以scala需要将特质翻译为JVM的类与接口 只有抽象方法的特质被简单的翻译成一个Java接口 trait Logger def log(msg: String) 被翻译为 public interface Logger void log(String ) 如果特质中有具体的方法，Scala会创建出一个伴生类，伴生类用静态方法存放特质的方法。 trait ConsoleLogger extends Logger def log(msg: String) println(msg) 被翻译成 public interface ConsoleLogger extends Logger void log(Stirng msg) 以及一个和ConsoleLogger接口对应的伴生类 public class ConsoleLogger$class public static void log(ConsoleLogger self, String msg) println(msg)","tags":["scala"],"categories":["scala"]},{"title":"Java中的null引用","path":"/2016/01/21/null-reference-in-java/","content":"空指针也许是java中最常见的异常，到处都埋藏着NullpointerException，最近就遇到一个NullPointException，如下： int lastMonthTotalScore = integralOperationReadMapper.getSumByIntegralIdAndDate(integralId, lastMonthDate); 一个很常见的情况，mybatis查询的一个列的和，此时Debug时 integralId、lastMonthDate 都不为空，自动注入的 integralOperationReadMapper也不为空但是Console却实实在在的打出了这一行有一个NullPointerException，此时没有注意到Wrapper类自动转换基本数据类型的情形。 getSumByIntegralIdAndDate 方法返回的是NULL，自动拆箱的时候的要将一个NULL转换为基本数据类型就出错了…o(╯□╰)o 现在总结几个NULL的经验。 1.不用null来返回方法的返回值 不要用null来舒适化变量，方法不要返回null、这样会造成null的传播，在每一个调用的地方都需要检查null 例如： public String doSomething(int id) String name = findName(id); ... return name; 这样如果findName如果返回为null，那么null就由findname游走到了doSomething。比如在findname中，如果没有找到对应的Id的姓名，就应该表明是没找到，而不是出错了。 善于运用Java的异常。 public String findName() throws NotFoundException if (...) return ...; else throw new NotFoundException(); 2.不把null放进容器内 容器（collection），是指一些对象以某种方式集合在一起，所以null不应该被放进Array，List，Set等结构，不应该出现在Map的key或者value里面。把null放进容器里面，是一些莫名其妙错误的来源。因为对象在容器里的位置一般是动态决定的，所以一旦null从某个入口跑进去了，你就很难再搞明白它去了哪里，你就得被迫在所有从这个容器里取值的位置检查null。你也很难知道到底是谁把它放进去的，代码多了就导致调试极其困难。解决方案是：如果你真要表示“没有”，那你就干脆不要把它放进去（Array，List，Set没有元素，Map根本没那个entry），或者你可以指定一个特殊的，真正合法的对象，用来表示“没有”。需要指出的是，类对象并不属于容器。所以null在必要的时候，可以作为对象成员的值，表示它不存在。 3.尽早对方法进行参数检查null 应该尽早的对null进行检查，不试图对null进行容错，采用强硬的手段,如果为空则抛出异常，可以使用java.util包里Objects.requireNonNull()方法来给方法的作者回应，告诉方法作者不应该把null传进来。 Objects.requireNonNull()方法如下： public static T T requireNonNull(T obj) if (obj == null) throw new NullPointerException(); else return obj; 4.使用Java8的Optional或者guava的Optional Optional类型的设计原理，就是把检查和访问这两个操作合二为一，成为一个原子操作。","tags":["java"],"categories":["java"]},{"title":"Scala中的模式匹配","path":"/2016/01/14/pattern-matching-in-scala/","content":"模式匹配scala有一套内建的模式匹配机制，这种机制允许在任何类型的数据上与第一个匹配策略匹配。模式匹配可以应用在很多场合，switch语句，类型检查以及提取对象中的的复杂表达式。 下面是一个小例子，说明如何与一个整型值匹配： object MatchTest1 extends App def matchTest(x: Int): String = x match case 1 = one case 2 = two case _ = many println(matchTest(3)) 这段带有case的代码块定义了一个从证书向字符串映射的函数关键字match提供了一个便捷的方法来把一个函数apply给一个对象，比如上面的模式匹配函数matchTest。下面是第二个例子匹配不同类型 object MatchTest2 extends App def matchTest(x: Any): Any = x match case 1 = one case two = 2 case y: Int = scala.Int println(matchTest(two)) 第一个case匹配如果 x是integer类型的且值为1的情况第二个case匹配如果 x是string类型的且值为two的情况Scala的模式匹配语句在通过y样例类来匹配代数类型是最有用的。Scala也允许定义独立自主的对类的匹配，在提取对象使用了预定义的unapply方法。","tags":["scala"],"categories":["scala"]},{"title":"使用Scala实现快速排序","path":"/2015/12/25/quicksort-in-scala/","content":"首先是一个用Scala写的简单的快速排序的栗子（非函数式）： def sort(xs: Array[Int]) def swap(i: Int, j: Int) val t = xs(i); xs(i) = xs(j); xs(j) = t def sort1(l: Int, r: Int) val pivot = xs((l + r) / 2) var i = l; var j = r while (i = j) while (xs(i) pivot) i += 1 while (xs(j) pivot) j -= 1 if (i = j) swap(i, j) i += 1 j -= 1 if (l j) sort1(l, j) if (j r) sort1(i, r) sort1(0, xs.length - 1) 和Java写的快速排序类似，使用操作符和控制语句来实现，只不过语法和Java有所不同。但是Scala的不同点就在于它的函数式编程，函数式编程可以写出完全不同的程序，更加简单，更加优雅。这次还是快速排序，这一次用函数式的风格来写： def quicksort(xs: Array[Int]): Array[Int] = if (xs.length = 1) xs else val pivot = xs(xs.length / 2) Array.concat( quicksort(xs filter (pivot )), xs filter (pivot ==), quicksort(xs filter (pivot ))) 函数式编程用一种简洁的方式抓住了快速排序的本质 如果数组array是空的或者只有一个元素那么肯定是已经排好序的所以直接返回 如果数组array不是空的,选择数组中间的元素当做pivot。 将数组划分为三个子数组,分别包含笔pivot大、小、相等的元素。 对于大于和小于pivot的子元素的数组递归调用sort函数。 讲三个子数组组合在一起就是排序结果。","tags":["scala"],"categories":["scala"]},{"title":"函数式编程语言Scala的学习（Hello Scala）","path":"/2015/12/20/learning-scala/","content":"Scala吸收了收并继承了多种语言中的优秀特性，另一方面也没有抛弃Java这个强大的平台，它可以运行在 Java 虚拟机之上，能够轻松地与Java互联互通。与Java不同的是，Scala既支持面向对象的特性，又支持函数式编程，被称为是Java的替代语言，是更好的Java，下面开始学习这一强大的语言。 Scala和Java比较在Scala中 所有类型都是对象 函数是对象 支持Domain specific language (DSL)领域特定语言 特质(Trait) 闭包(Closure)，嵌套函数 Erlang支持的并发设计 类型推导 基础语法表达式scala 1 + 1 res0: Int = 2 res0是解释器自动创建的变量名称，指代表达式计算的结果，是Int类型的，值为2。在scala几乎一切都是表达式。 变量和值可以将表达式赋给一个或者不变量（val）–值或者变量（var） scala val two = 1 + 1 two: Int = 2 如果需要以后修改这个名称和结果的绑定，需要使用var（变量），大部分的情况下用val的情况居多。 scala var name = zhaohongxuan name: java.lang.String = zhaohongxuan scala name = zhaoxiaoxuan name: java.lang.String = zhaoxiaoxuan 函数使用def关键字来创建函数 scala def addOne(m: Int): Int = m + 1 addOne: (m: Int)Int 调用函数： scala val three = addOne(2) three: Int = 3 在scala中，需要为函数参数制定类型的签名。但是，如果函数不带参数，括号可以省略。 scala def three() = 1 + 2 three: ()Int scala three() res2: Int = 3 scala three res3: Int = 3 匿名函数创建匿名函数 scala (x: Int) = x + 1 res2: (Int) = Int = function1 这个函数的作用是给名为x的变量加1. scala res2(1) res3: Int = 2 也可以传递匿名函数 scala val addOne = (x: Int) = x + 1 addOne: (Int) = Int = function1 scala addOne(1) res4: Int = 2 如果函数中表达式很多，可以用花括号{}来格式化代码、 scala i: Int = println(hello world) i * 2 res0: (Int) = Int = function1 部分应用（Partial application）可以使用下划线_部分应用一个函数，结果是得到另一个函数。 定义一个add函数 scala def add(m: Int, n: Int) = m + n add: (m: Int,n: Int)Int 将add函数部分应用得到一个新的匿名函数 scala val add2 = add(2, _:Int) add2: (Int) = Int = function1 scala add2(3) res50: Int = 5 可变长度参数这是一种特殊的语法，可以向方法传入任意多个同类型的参数。比如给传入的参数的首字母进行大写的操作。 def capitalizeAll(args: String*) = args.map arg = arg.capitalize scala capitalizeAll(zhaoxiaoxuan, douxiaonna) res2: Seq[String] = ArrayBuffer(Zhaoxiaoxuan, Douxiaonna) 类、继承与特质类scala class Calculator | val brand: String = HP | def add(m: Int, n: Int): Int = m + n | defined class Calculator scala val calc = new Calculator calc: Calculator = Calculator@e75a11 scala calc.add(1, 2) res1: Int = 3 scala calc.brand res2: String = HP 这个计算器类展示了在类中使用def定义方法，和使用val定义字段。其中方法就是可以可以访问类状态的函数。 构造函数构造函数不是特殊的方法，他们是除了类的方法定义之外的代码。 class Calculator(brand: String) //构造函数 val color: String = if (brand == TI) blue else if (brand == HP) black else white // An instance method. def add(m: Int, n: Int): Int = m + n 使用构造函数来构造一个实例： scala val calc = new Calculator(HP) calc: Calculator = Calculator@1e64cc4d scala calc.color res0: String = black 在上面的例子中，颜色的值就是绑定在一个ifelse表达式上的。Scala是高度面向表达式的：大多数东西都是表达式而非指令。 继承class Point(xc: Int, yc: Int) val x: Int = xc val y: Int = yc def move(dx: Int, dy: Int): Point = new Point(x + dx, y + dy)class ColorPoint(u: Int, v: Int, c: String) extends Point(u, v) val color: String = c def compareWith(pt: ColorPoint): Boolean = (pt.x == x) (pt.y == y) (pt.color == color) override def move(dx: Int, dy: Int): ColorPoint = new ColorPoint(x + dy, y + dy, color) ColorPoint继承了Point中所有的成员，包括x,y包括move方法。 子类ColorPoint增加了一个新的方法compareWith。Scala允许对成员定义进行覆盖（Override），在这个例子中，我们在子类中用move方法覆盖了的父类的move方法,当然在子类中可以使用super关键字来调用父类的move方法。 抽象类定义一个抽象类，它定义了一些方法但没有实现它们。取而代之是由扩展抽象类的子类定义这些方法。抽象类不能创建实例。 scala abstract class Shape | def getArea():Int // subclass should define this | defined class Shape scala class Circle(r: Int) extends Shape | def getArea():Int = r * r * 3 | defined class Circle scala val s = new Shape console:8: error: class Shape is abstract; cannot be instantiated val s = new Shape ^ scala val c = new Circle(2) c: Circle = Circle@65c0035b 特质特质是一些字段和行为的集合，可以扩展或者混入（Mixin）你的类中。 trait Car val brand: String trait Shiny val shineRefraction: Int class BMW extends Car val brand = BMW 通过with关键字，一个类可以扩展多个特质： class BMW extends Car with Shiny val brand = BMW val shineRefraction = 12","tags":["scala"],"categories":["scala"]},{"title":"使用Spring boot 创建RestFul服务","path":"/2015/11/29/spring-boot-restful/","content":"准备工作1.JDK82.Maven 3.0+ 程序要实现的简单功能当用户访问 http://localhost:8080/greeting 返回一个默认的Json字符串 id:1,content:Hello, World! 当用户访问 http://localhost:8080/greeting?name=User 返回 name后面的参数在后台组成的字符串 id:1,content:Hello, User! 创建Maven项目创建一个普通的maven项目，添加maven依赖如下： ?xml version=1.0 encoding=UTF-8?project xmlns=http://maven.apache.org/POM/4.0.0 xmlns:xsi=http://www.w3.org/2001/XMLSchema-instance xsi:schemaLocation=http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd modelVersion4.0.0/modelVersion groupIdcom.zeusjava/groupId artifactIdSpringMVCRESTFul/artifactId version1.0-SNAPSHOT/version properties java.version1.8/java.version /properties parent groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-parent/artifactId version1.3.0.RELEASE/version /parent dependencies dependency groupIdorg.springframework.boot/groupId artifactIdspring-boot-starter-web/artifactId /dependency /dependencies build plugins plugin groupIdorg.springframework.boot/groupId artifactIdspring-boot-maven-plugin/artifactId /plugin /plugins /build repositories repository idspring-releases/id urlhttps://repo.spring.io/libs-release/url /repository /repositories pluginRepositories pluginRepository idspring-releases/id urlhttps://repo.spring.io/libs-release/url /pluginRepository /pluginRepositories/project 各个包之间的依赖关系如下图： ##创建一个resource representation 类To model the greeting representation, you create a resource representation class.Provide a plain old java object with fields, constructors, and accessors for the id and content data: 创建一个User类，有id和name两个属性 package com.zeusjava;public class User private final long id; private final String name; public User(long id, String name) this.id = id; this.name = name; public long getId() return id; public String getName() return name; 当用户访问URL的时候，程序后台会自动获得URL上附带的名为name的参数。 创建一个resource controller在Spring4中新增了一个@RestController注解，相当于Spring3中的@Controller和@ResponseBody两个注解一起的效果创建一个UserController来处理Request如下： package com.zeusjava;import java.util.concurrent.atomic.AtomicLong;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class UserController private static final String template = Hello, %s!; private final AtomicLong counter = new AtomicLong(); @RequestMapping(/greeting) public User greeting(@RequestParam(value=name, defaultValue=World) String name) return new User(counter.incrementAndGet(), String.format(template, name)); 执行程序main方法使用Spring Boot 的SpringApplication.run()来加载程序。 package com.zeusjava;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class Application public static void main(String[] args) SpringApplication.run(Application.class, args); 测试程序在Application的main方法中运行application，在地址栏输入 http://localhost:8080/greeting 结果为： 再输入一次 http://localhost:8080/greeting?name=Zhaohongxuan 结果为： 不用配置繁琐的xml，一个简单的Restful风格的程序就创建好了。","tags":["java/spring"],"categories":["spring框架"]},{"title":"Executor任务执行框架的应用","path":"/2015/11/09/java-concurrent-executor-and-countdownlatch/","content":"最近一段时间没有写东西了，看大名鼎鼎的Brian Goetz写的Java Concurrency in Practice时候，看到任务执行框架Executor Framework的时候，觉得纸上得来终觉浅，索性写点东西加深一下印象。 在JDK1.5中，Java平台中增加了一个并发包java.util.concurrent，这个包中包含了Executor Framework，而且还包含了很多并发包，比如并发HashMapConcurrentHashMap、阻塞队列BlockQueue、栅栏的实现CyclicBarrier、信号量Semaphore、异步任务FutureTask等等。在处理多线程任务的时候，使用Executor和task要优于使用线程,这也不是我说的，是Effect Java的作者 Joshua Bloach说的，下面来阐述一下为什么。 并发任务执行当要执行一个并发任务的时候，通常有两种方式，一种是串行的处理方式，一种是并行的处理,显然，串行的方式只能一次处理一个任务，当程序在执行当前的任务的时候，就说明接下来到来的任务请求都要等待当前的任务执行完毕才能获得CPU去执行任务，这种方式虽然不会犯错，但是效率太低。那么，如果每一个任务到来都分配一个新的任务呢，这种方式貌似很好，但是： 如果任务请求量非常大的时候会出现一定的问题，因为它没有限制可以创建的线程的数量. 线程生命周期的开销很高 线程的创建和销毁不是没有代价的,根据平台的不同，开销不同，但是不要忘记，线程的创建是需要时间的。 活跃的线程会消耗系统资源 活跃的线程很消耗系统资源，尤其是内存，如果可运行的线程数量多于处理器核心数，那么多余的线程将闲置，但是闲置的线程仍然是消耗系统资源的，尤其 是内存，给GC回收垃圾带来压力，而且线程间在进行竞争的时候也会消耗大量的资源 平台可创建的线程数量是有限的 也就是说，如果创建的线程超出了平台的限制那么，JVM就可能抛出OutofMemoryError的异常 线程池和数据库连接池相似，线程池指的是一组同构工作线程的资源池，线程池与工作队列 Work Queue密切相关线程池中的线程的任务很简单：从工作队列（Work Queue）中取出一个任务，执行任务，人后返回线程池，等待执行下一个任务 线程池比为每一个任务分配一个线程要有更多优势，通过重用现有线程而不是重新创建线程，可以处理多个任务请求的时候，分摊在线程创建和销毁的过程中产生的巨大开销。而且，当请求到达的时候，线程池中的线程也已经就绪，不需要在创建线程而延迟响应的时间，提高了响应性。通过调整线程池的大小，可以创建足够多的线程来让CPU保持忙碌的状态。 创建线程池有很多种方式， 通过调用Executors的工厂方法可以创建线程池，例如：newFixThreadPool 用来创建一个固定长度的线程池newCacheThreadPool 用来创建一个可缓存的线程池newSingleThreadPool 创建一个单线程的线程池 Executor框架任务和线程不同，任务是一组逻辑工作单元，而线程是使任务异步执行的机制。在Java类库中，任务执行的主要抽象不是Thread而是Executor Executor接口定义如下 public interface Executor /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the ttExecutor/tt implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution. * @throws NullPointerException if command is null */ void execute(Runnable command); 虽然Executor只是一个简单的接口，但是却为灵活而强大的异步任务执行框架提供了基础。其中Runnable表示可以执行的任务Executor的实现还提供了对生命周期的支持。 Executor基于 生产者-消费者模式，提交任务到线程池相当于生产者，执行任务相当于消费者。 闭锁闭锁是一种同步工具类，作用是延迟线程的进度直到其到达终止状态。###举个栗子：闭锁的作用相当于一扇门，当闭锁到达结束状态之前，这扇门一直是关闭的，并且没有任何线程能通过,当闭锁到达技术状态的时候，这扇门会打开而让所有线程通过。当闭锁到达结束状态的时候，这扇门会永远保持打开状态。闭锁的作用是，可以用来确保某些活动直到其他活动都完成后才执行。 实践纸上得来终觉浅，写了代码就知道为什么了。 还比如上一次写的爬虫，如果单线程抓取的话，只能首先抓取首页，然后解析其中的图片链接，然后再下载图片，这样效率无疑是很低的，现在我加上线程池。 建立工作队列一个是抓取页面的阻塞队列naviQueue,一个是抓取页面上的图片url的阻塞队列imgQueue // 定义一个页面导航的队列final BlockingQueueString naviQueue = new LinkedBlockingQueueString(3);// 定义一个图片网址的队列final BlockingQueueString imgQueue = new LinkedBlockingQueueString(100); 创建线程池线程池的大小是下载图片线程和解析页面线程的数量之和 final int DOWNLOAD_THREAD = 30;final int PAGE_THREAD = 2;final ExecutorService exec = Executors.newFixedThreadPool((DOWNLOAD_THREAD + PAGE_THREAD)); 定义闭锁定义一个开始倒数锁和一个结束倒数锁 // 定义一个开始的倒数锁final CountDownLatch begin = new CountDownLatch(1);// 定义一个结束的倒数锁final CountDownLatch end = new CountDownLatch((DOWNLOAD_THREAD + PAGE_THREAD)); 其中，开始倒数锁的作用是，等待主线程加载首页信息，加载完成后才能继续抓取下一页的URL，所以开始倒数锁的初始大小为1，等初始化线程一旦执行完毕之后，立刻释放所有的线程，开始执行并行任务。 结束倒数锁的作用是，主线程能够等待所有的工作线程依次执行完成，而不是顺序的等待每个线程执行完毕。 初始化线程public ThreadPoolMananger() int i = 1;\tfor (; i = PAGE_THREAD; i++) exec.submit(new PageThread(i, begin, end)); for (; i = (DOWNLOAD_THREAD + PAGE_THREAD); i++) exec.submit(new ImageThread(i, D:\\\\pictures, begin, end)); HtmlParser parser = new HtmlParser();\tSimpleHttpClient client = new SimpleHttpClient();\tparser.setHtml(client.get(http://jandan.net/pic));\tSystem.out.println(====开始抓取首页);\ttry naviQueue.put(parser.getPageNavi()); parser.handleImgs(imgQueue); catch (InterruptedException e) client.close();\tSystem.out.println(首页结束，开始执行多线程抓取);\tbegin.countDown(); 构造器中初始化了页面抓取线程和一些下载图片的线程到线程池中，然后开始执行首页的抓取，等待首页抓取完毕之后，begin.coutDown(),这时候开始门的大小为0，这时候会释放所有的工作线程，开始执行多线程的抓取工作。 页面处理线程页面抓取线程在初始化主线程执行完毕之后开始执行，从页面URL队列naviQueue中取出队列头部的url，使用Jsoup进行解析，得到本页面所有的图片url并添加到待处理的图片URL队列imgQueue中然后得到下一页的链接URL，加入naviQueue中，如果在解析的过程中发现，Jsoup解析的下一页为空，那么就说明已经解析完成了。 class PageThread implements Runnable private final CountDownLatch startSignal; private final CountDownLatch stopSignal; private int index; public PageThread(int index, CountDownLatch start, CountDownLatch end) this.startSignal = start; this.stopSignal = end; this.index = index; @Override public void run() try startSignal.await(); catch (Exception e) String html = ; String url = ; int left = 0; HtmlParser parser = new HtmlParser(); SimpleHttpClient client = new SimpleHttpClient(); while (true) try url = naviQueue.take(); left = naviQueue.size(); if (.equals(url)) // 把结束的标志放回去，其他的线程也要调用 naviQueue.put(); break; catch (Exception e) System.err.println([ + index + ]: + e.getMessage()); System.out.println([ + index + ][页面left: + left + ]线程抓取html-- + url); try html = client.get(url); catch (Exception e1) parser.setHtml(html); String next = parser.getPageNavi(); try if (next == null) naviQueue.put(); parser.handleImgs(imgQueue); // 在图片队列的最后也放上一个作为结束的标志 imgQueue.put(); else naviQueue.put(next); parser.handleImgs(imgQueue); catch (InterruptedException e) e.printStackTrace(); client.close(); stopSignal.countDown(); 图片下载线程图片线程的主要任务就是下载所有的图片并保存到本地。 class ImageThread implements Runnable private final CountDownLatch startSignal;\tprivate final CountDownLatch stopSignal;\tprivate int threadIdx;\tprivate String dest;\tpublic ImageThread(int index, String dest, CountDownLatch start, CountDownLatch end) this.threadIdx = index; this.dest = dest; this.startSignal = start; this.stopSignal = end; @Override\tpublic void run() try // 等待初始的线程结束 startSignal.await(); catch (Exception e) System.out.println([ + threadIdx + ]线程开始); SimpleHttpClient client = new SimpleHttpClient(); String picurl = ; int left = 0; // 这个线程不断的从图片队列里面取出图片的地址 while (true) // 取出一个图片地址 try picurl = imgQueue.take(); left = imgQueue.size(); catch (InterruptedException e1) System.err .println([ + threadIdx + ]: + e1.getMessage()); if (.equals(picurl)) try // 结束标志，丢回去，其他的线程要根据这个判断结束 imgQueue.put(); catch (Exception e) e.printStackTrace(); // 如果说，取到图片地址为空而且页面的已经解析完毕，这个就应该要结束了。 break; try System.out.println([ + threadIdx + ][图片left: + left + ]线程开始抓取image-- + picurl); client.downloadFile(picurl, dest); catch (Exception e) System.err.println([ + threadIdx + ]: + e.getMessage()); client.close(); stopSignal.countDown();","tags":["java"],"categories":["java"]},{"title":"跑在立冬边上","path":"/2015/11/09/running-like-an-animal/","content":"村上春树说， 今天不想去跑步，所以才去跑步，这才是长跑者的思维 因为这句话，我专门买了村上君的《当我谈跑步的时，我谈些什么》，这本书让我对跑步有了更加深层次的认识。今天是2015年立冬，跑步也进入到了一年中最艰难的时候，上海的立冬并没有那么的冷，前一阵子冷空气经过上海的时候，冷了那么几天，但是过后天气又变得温暖起来了，算起来，从7月20号开始跑步到现在也快4个月了，也跑了将近500公里了。从蝉鸣的夏季，到燥热的秋季，再到冷风习习的冬季，时光就在脚步的一抬一落间逝去了，从身体流走的汗水已经数不清到底有多少了，喜欢奔跑的感觉，喜欢超越昨天自己的感觉，汗水浸润每一个细胞，感觉自己是真的自己。 十月份的国庆节中间耽误了一周没有跑步，所以国庆节一过便迫不及待的跑了起来，连着两周跑了半程马拉松，成绩也都还不错，都在2个小时之内,都是线上跑的，自己在学校的时候也跑过全程马拉松，但是，那是白天，而且有好多人一起跑，和现在不同，现在是一个人跑，而且是晚上，还有的路段，没有路灯，但是跑下来竟然没有感觉脚起泡，而且腿似乎也没有感觉特别酸痛，只是过了一天才感觉到。跑步，让自己的内心平静了很多，不管有多么不开心的事情，去跑步了，淋漓大汗过后，就会发现，其实也不过如此，哪有什么天大的事。再次，跑步让我明白了一个非常非常浅的道理，那就是，just do it. 以前做事情的时候，总是在想别人看到会怎么样，会怎么说，其实，哪有那么多闲人在意你在做什么，你去跑步根本没有人在意你，就算有人说你了，TA又和你没有半点交集怕什么，当你真正穿上跑鞋，在路上奔跑的时候，你会发现世界都是你的，每次跑完10公里，在栏杆上压腿的时候，感觉到自己的心跳和呼吸，但是心里却是很平静，我希望跑步能陪我很久很久。 这几天，上海的天气一点都不好，只要一出门跑步肯定是不会下雨的，但是等自己跑到一半的时候就开始下了，就这样连着三天，每天都被雨淋，但是感觉当雨水打在脸上的时候，会发现自己的脚步更加坚定了，因为觉得，老子连在雨里跑步都不怕，还会怕什么呢，哈哈。经过了一年最热的日子，去迎接美好的冬天，用心去过好每一天，发现身边的美。 老罗说， 失败只有一种，那便是半途而废. 回想自己，从去年12月开始捡起英语，到今天一天都不曾间断过，这可能也算是一种坚持，感觉自己萌萌哒。 不去跑永远不知道自己能跑多久，能跑多远，刚开始跑步的时候78公斤，现在76公斤，跑了4个月减了4公斤，其实没有瘦多少，其实当初跑步的时候，并不全是为了要减重，最重要的是想要更加健康的身体吧。年轻的时候就是要多做三件事： 1.多挣钱2.多读书3.多锻炼 多挣钱，让物质生活更加自由，多读书让精神更加自由，多锻炼，让生活更加自由。继续奔跑吧，坚持做你认为正确的事情！","tags":["跑步"],"categories":["散文随笔"]},{"title":"JDK动态代理和cglib动态代理","path":"/2015/10/13/jdk-dynamic-agent-and-cglib/","content":"一晃眼，国庆节已经过去了，时间到了10月中旬了，总是感觉时间不够用，想多看点书，多写点代码，在点滴中积淀属于自己的知识系统。 闲言少叙，先来说一下什么是代理模式，我们去一个新的地方总是要先找地方住，但是我们人生地不熟的掌握的资源不多，这时候一般会找中介，中介对房源很熟悉，很快就能为你找到合适的房子，这时候，中介就是一个代理,你就相当于是一个委托方。 下面是设计模式中的代理： 代理模式代理模式是常用的java设计模式，他的特征是代理类与委托类有同样的接口，代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。代理类与委托类之间通常会存在关联关系，一个代理类的对象与一个委托类的对象关联，代理类的对象本身并不真正实现服务，而是通过调用委托类的对象的相关方法，来提供特定的服务。 按照代理的创建时期，代理类可以分为两种： 静态代理由程序员创建或特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class文件就已经存在了。 动态代理在程序运行时，运用反射机制动态创建而成。 动态代理类的字节码在程序运行时由Java反射机制动态生成，无需程序员手工编写它的源代码。动态代理类不仅简化了编程工作，而且提高了软件系统的可扩展性，因为Java 反射机制可以生成任意类型的动态代理类。java.lang.reflect 包中的Proxy类和InvocationHandler 接口提供了生成动态代理类的能力。 动态代理有很多种，先看第一种，JDK动态代理 JDK动态代理先来看下JDK源码中InvocationHandler中invoke()方法 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; JDK源码中Proxy类的代码： public static Object newProxyInstance(ClassLoader loader, Class?[] interfaces, InvocationHandler h) throws IllegalArgumentException if (h == null) throw new NullPointerException(); /* * Look up or generate the designated proxy class. */ Class? cl = getProxyClass(loader, interfaces); /* * Invoke its constructor with the designated invocation handler. */ try Constructor cons = cl.getConstructor(constructorParams); return cons.newInstance(new Object[] h ); catch (NoSuchMethodException e) throw new InternalError(e.toString()); catch (IllegalAccessException e) throw new InternalError(e.toString()); catch (InstantiationException e) throw new InternalError(e.toString()); catch (InvocationTargetException e) throw new InternalError(e.toString()); 参数说明：ClassLoader loader：类加载器 Class?[] interfaces：得到全部的接口 InvocationHandler h：得到InvocationHandler接口的子类实例 PS:类加载器在Proxy类中的newProxyInstance（）方法中需要一个ClassLoader类的实例，ClassLoader实际上对应的是类加载器，在Java中主要有一下三种类加载器: Booststrap ClassLoader：此加载器采用C++编写，一般开发中是看不到的； Extendsion ClassLoader：用来进行扩展类的加载，一般对应的是jre\\lib\\ext目录中的类; AppClassLoader：(默认)加载classpath指定的类，是最常使用的是一种加载器。 JDK动态代理实现步骤实现InvocationHandler接口获得代理对象public Object getInstance(Object target) return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); 回调函数@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable Object result = null; System.out.println(jdk 动态代理 begin...); result = method.invoke(target,args); System.out.println(jdk 动态代理 end...); return result; JDK动态代理缺点： 只能对实现了接口的类进行，没有实现接口的类不能使用JDK动态代理。 cglib动态代理JDK的动态代理机制只能代理实现了接口的类，而不能实现接口的类就不能实现JDK的动态代理，cglib是针对类来实现代理的，他的原理是对指定的目标类生成一个子类，并覆盖其中方法实现增强，但因为采用的是继承，所以不能对final修饰的类进行代理。cglib实现动态代理的方法和JDK动态代理类似 实现MethodInterceptor接口获得代理对象public Object getInstance(Object target) this.target = target; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(this.target.getClass()); //设置回调方法 enhancer.setCallback(this); //创建代理对象 return enhancer.create(); 设置回调方法@Overridepublic Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable System.out.println(UserFacadeProxy.intercept begin); methodProxy.invokeSuper(o,objects); System.out.println(UserFacadeProxy.intercept end); return null; Spring AOP原理java动态代理是利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。而cglib动态代理是利用asm开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。SpringAOP动态代理策略是： 1、如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP 2、如果目标对象实现了接口，可以强制使用CGLIB实现AOP 3、如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换","tags":["cglib"],"categories":["java"]},{"title":"vue.js学习笔记（二）","path":"/2015/09/22/learn-vue-js-2/","content":"继续上一篇文章，中间耽误了一个多星期，去面试和复习以前的代码，继续愉快的的vue.js学习之旅 :)… 列表渲染vue.js的v-repeat指令用来根据相对应的ViewModel的对象数组来渲染列表。 简单示例html代码： ul id=demo li v-repeat=items class=item-$index $index : parentMsg childMsg /li/ul js代码： var demo = new Vue( el: #demo, data: parentMsg: 你好, items: [ childMsg: 赵 , childMsg: 宏轩 ] ) 这些子实例继承父实例的数据作用域，因此在重复的模板元素中你既可以访问子实例的属性，也可以访问父实例的属性。还可以通过$index属性来获取当前实例对应的数组索引。 块级重复template标签用来重复循环一个包含多个节点的块 ul template v-repeat=list limsg/li li class=divider/li /template/ul 简单值数组简单值 (primitive value) 是字符串、数字、boolean 等并非对象的值。对于包含简单值的数组，可用$value直接访问值: ul id=tags li v-repeat=tags $value /li/ul new Vue(el:tags,data: tags:[java,sql,c++]) 使用别名如果想要访问实例对象的属性，可以通过in关键字来获得repeat对象的单个对象，有点类似于java中的for-each ul id=users li v-repeat=user in users user.name - user.email /li/ul new Vue( el: #users, data: users: [ name: 赵小轩, email: hongxuanzhao@gmail.com , name: 窦小娜, email: xiaonadou@gmail.com ] ) 遍历对象使用使用v-repeat遍历一个对象的所有属性，每个重复的实例会有一个特殊的属性$key。对于简单值，你也可以象访问数组中的简单值那样使用$value属性。 ul id=repeat-object li v-repeat=primitiveValues$key : $value/li li===/li li v-repeat=objectValues$key : msg/li/ul new Vue( el: #repeat-object, data: primitiveValues: FirstName: John, LastName: Doe, Age: 30 , objectValues: one: msg: Hello , two: msg: Bye ) 迭代值域v-repeat可以接收一个整数，然后重复显示模版多次 div id=range div v-repeat=valHi! $index/div/div new Vue( el: #range, data: val: 3 ); 数组过滤器Vue有两个内置的过滤器来过滤或者排序数据，分别是：filterBy和orderBy。 filterBy语法： filterBy searchKey [in dataKey...] 返回原数组过滤后的结果。searchKey 参数是当前ViewModel 的一个属性名，这个属性的值会被用作查找的目标。in关键字指定具体要在哪个属性中进行查找。用法： 1.不使用in关键字input v-model=searchTextul li v-repeat=users | filterBy searchTextname/li/ul 这个过滤器会遍历整个users数组每个元素的每个属性值来匹配searchText的内容比如如果一个元素为name:赵宏轩,tel:021-111111,searchText的值为021,那么这条数据就是合法的数据，不会被过滤器过滤掉。 2.使用in关键字input v-model=searchTextul li v-repeat=user in users | filterBy searchText in namename/li/ul 和上一个例子数据一样，但是如果searchText的值还是021的话，那么这条数据就会被过滤掉。因为过滤的内容限定在 name属性中，如果searchText的值为赵的话，这个元素就不会被过滤掉。 OrderBy语法： orderBy sortKey [reverseKey]. orderBy用于返回原数组排序后的结果。sortKey参数是当前ViewModel的一个属性名。这个属性的值表示用来排序的键名.reverseKey参数也是当前ViewModel的一个属性名，如果这个属性值为真则数组会被倒序排列。可以使用引号来表示字面量的排序键名。使用 -1 来表示字面量的 reverse 参数。 语法： orderBy sortKey [reverseKey]. 用法： ul li v-repeat=user in users | orderBy field reversename/li/ul new Vue( /* ... */ data: field: name, reverse: false )","tags":["Coding/javascript/Vue"],"categories":["技术随笔"]},{"title":"Redis 整合Spring","path":"/2015/09/11/redis-java-spring/","content":"Redis是一种性能非常高效的Key-Value数据库，在企业项目开发中应用广泛，因为一直用Spring，所以决定使用Spring支持的spring-data-redis,java中Redis有多种客户端，Spring推荐的是Jedis，这篇文章就是基于Jedis的。 SDR(Spring Data Redis)简介**SDR(Spring Data Redis)**支持低层次的通过连接器connector连接到Redis，支持高层次的友好的模板类RedisTemplate,RedisTemplate是建立在低级别的connection基础之上。RedisConnection接收或返回字节数组需要自身处理连接，比如关闭连接，而RedisTemplate负责处理串行化和反串行化，并且管理对连接进行管理。RedisTemplate提供操作视图，比如(Bound)ValueOperations,(Bound)ListOperations,(Bound)SetOperations,(Bound)ZSetOperations,(Bound)HashOperations。RedisTemplate是线程安全的，能够用于多个实例中。RedisTemplate默认选择java-based串行化,也可以切换为其它的串行化方式，或者设置enabledDefaultSerializer为false或者设置串行化器为null，则RedisTemplate用raw byte arrays表示数据。SDR连接到redis通过RedisConnectionFactory来获得有效的RedisConnection。RedisConnection负责建立和处理和redis后端通信。RedisConnection提供getNativeconnection返回用来通信的底层connection。 Maven的pom.xml文件配置在dependencies中添加两个依赖，分别是spring-data-redis和jedis dependency groupIdorg.springframework.data/groupId artifactIdspring-data-redis/artifactId version1.4.2.RELEASE/version /dependency\tdependency groupIdredis.clients/groupId artifactIdjedis/artifactId version2.6.2/version typejar/type scopecompile/scope\t/dependency Properties文件中配置Redis的基本参数# Redis configredis.host=localhostredis.port=6379redis.password=redis.maxIdle=300redis.maxActive=600redis.maxWait=1000redis.testOnBorrow=true 配置applicationContext.xml在applicationContext.xmlS中配置jedisConnFactory和jedisTemplate，加载Properties的各个属性 ?xml version=1.0 encoding=UTF-8?beans xmlns=http://www.springframework.org/schema/beans\txmlns:xsi=http://www.w3.org/2001/XMLSchema-instance\txmlns:context=http://www.springframework.org/schema/context\txmlns:p=http://www.springframework.org/schema/p\txmlns:tx=http://www.springframework.org/schema/tx\txsi:schemaLocation=http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd context:component-scan base-package=com.zeusjava.osf.model /\tcontext:component-scan base-package=com.zeusjava.osf.dao.impl /\tcontext:component-scan base-package=com.zeusjava.osf.service /\tcontext:component-scan base-package=com.zeusjava.osf.util /\tcontext:property-placeholder location=classpath:spring/property.properties/ bean id=jedisConnFactory class=org.springframework.data.redis.connection.jedis.JedisConnectionFactory p:usePool=true p:hostName=$redis.host p:port=$redis.port p:password=$redis.password/ !-- redis template definition --\tbean id=redisTemplate class=org.springframework.data.redis.core.RedisTemplate p:connectionFactory-ref=jedisConnFactory property name=keySerializer bean class=org.springframework.data.redis.serializer.StringRedisSerializer / /property property name=hashKeySerializer bean class=org.springframework.data.redis.serializer.StringRedisSerializer / /property\t/bean bean id=transactionManager class=org.springframework.jdbc.datasource.DataSourceTransactionManager p:dataSource-ref=dataSource/ tx:annotation-driven transaction-manager=transactionManager / /beans 在java类中使用Redis进行增删改查下面是一个简单的查询的例子 @Repository(userDao)public class UserDAOImpl implements UserDAO\t@Autowired\t@Qualifier(redisTemplate)\tprivate RedisTemplateString, String redisTemplate; @Resource(name=redisTemplate)\tprivate HashOperationsString, String, Object mapOps; public User getUserByID(int id) String key = user:+id; Object obj = mapOps.get(user,key); User user = (User) obj; return user;","tags":["redis"],"categories":["spring框架"]},{"title":"vue.js学习笔记（一）","path":"/2015/09/09/learn-vue-js/","content":"简介Vue.js 是一个用于创建 web 交互界面的库。 从技术角度讲，Vue.js专注于MVVM模型的ViewModel层。它通过双向数据绑定把View层和 Model 层连接了起来。实际的DOM封装和输出格式都被抽象为了Directives和Filters。 从哲学角度讲，Vue 希望通过一个尽量简单的 API 来提供响应式的数据绑定和可组合、复用的视图组件。它不是一个大而全的框架——它只是一个简单灵活的视图层。您可以独立使用它快速开发原型、也可以混合别的库做更多的事情。它同时和诸如 Firebase 这一类的 BaaS 服务有着天然的契合度。 Vue.js 的 API 设计深受AngularJS、KnockoutJS、Ractive.js 和 Rivets.js 的影响。尽管有不少相似之处，但我们相信 Vue.js 能够在简约和功能之间的微妙平衡中体现出其独有的价值。 ViewModelViewModel在vue.js中同步Model和View的对象，在vue.js中，每个vue.js实例都是一个ViewModel它们是通过构造函数 Vue或者其子类被创建出来的 var vm =new Vue(); 视图(View)View是被Vue实例管理的DOM节点 vm.$el Vue.js 使用基于 DOM 的模板。每个 Vue 实例都关联着一个相应的 DOM 元素。当一个 Vue 实例被创建时，它会递归遍历根元素的所有子结点，同时完成必要的数据绑定。当这个视图被编译之后，它就会自动响应数据的变化。 当数据发生变化时，视图将会自动触发更新。这些更新的粒度精确到一个文字节点。同时为了更好的性能，这些更新是批量异步执行的。 模型(Model)vm.$data Vue.js中的模型就是普通的javascript对象。一旦某对象被作为 Vue 实例中的数据，它就成为一个 “响应式” 的对象了。你可以操作它们的属性，同时正在观察它的 Vue 实例也会收到提示。 指令(Directives)Vue.js的指令是带有特殊前缀v-的HTML特性，可以让Vue.js对DOM做各种处理。 简单示例div v-text =name /div 这里的前缀是默认的 v-。指令的ID 是 text，表达式是 name。这个指令告诉 Vue.js， 当 Vue 实例的 name 属性改变时，更新该 div 元素的 textContent。Directives 可以封装任何 DOM 操作。比如v-attr 会操作一个元素的特性；v-repeat 会基于数组来复制一个元素；v-on 会绑定事件等 内联表达式div v-text=hello + user.firstName + + user.lastName/div 这里我们使用了一个计算表达式 (computed expression)，而不仅仅是简单的属性名。Vue.js 会自动跟踪表达式中依赖的属性并在这些依赖发生变化的时候触发指令更新。同时，因为有异步批处理更新机制，哪怕多个依赖同时变化，表达式也只会触发一次。需要注意的是Vue.js 把内联表达式限制为一条语句。如果需要绑定更复杂的操作，可以使用计算属性。 参数div v-on=click : clickHandler/div 有些指令需要在路径或表达式前加一个参数。在这个例子中click参数代表了我们希望v-on 指令监听到点击事件之后调用该 ViewModel 实例的 clickHandler 方法。 多重指令从句你可以在同一个特性里多次绑定同一个指令。这些绑定用逗号分隔，它们在底层被分解为多个指令实例进行绑定。 #### 字面量指令 有些指令不会创建数据绑定——它们的值只是一个字符串字面量。比如 v-ref 指令： my-component v-ref=some-string-id/my-component 这里的 some-string-id 并不是一个响应式的表达式 — Vue.js不会尝试去观测组件中的对应数据。 在有些情况下，你也可以使用 Mustache 风格绑定来使得字面量指令 反应化： div v-show=showMsg v-transition=dynamicTransitionId/div 但是，请注意只有v-transition 指令具有此特性。Mustache表达式在其他字面量指令中，例如 v-ref 和 v-el，只会被计算一次。它们在编译完成后将不会再响应数据的变化。 Mustache 风格绑定你也可以使用 mustache 风格的绑定，不管在文本中还是在属性中。它们在底层会被转换成 v-text 和 v-attr 的指令。比如： div id=person-idHello name!/div 过滤器(filter)示例过滤器是用于在更新视图之前处理原始值的函数,它们通过一个“管道”在指令或绑定中进行处理： divmessage | capitalize/div 这样在 div 的文本内容被更新之前，message 的值会先传给 capitalizie 函数处理。 参数一些过滤器是可以接受参数的。参数用空格分隔开： spanorder | pluralize st nd rd th/spaninput v-on=keyup: submitForm | key enter","tags":["Coding/javascript/Vue"],"categories":["技术随笔"]},{"title":"Java中使用DES对称加解密","path":"/2015/09/07/java-des-encrypt/","content":"DESDES(Data Encryption Standard),即数据加密算法。是IBM公司于1975年研究成功并公开发表的。DES算法的入口参数有三个:Key、Data、Mode。其中Key为8个字节共64位,是DES算法的工作密钥;Data也为8个字节64位,是要被加密或被解密的数据;Mode为DES的工作方式,有两种:加密或解密。 安卓端对请求Web服务器请求字符串进行加密加密公共方法： package com.sz.kcygl.common.DESUtil;import java.security.Key;import java.security.SecureRandom;import java.security.spec.AlgorithmParameterSpec;import javax.crypto.Cipher;import javax.crypto.SecretKeyFactory;import javax.crypto.spec.DESKeySpec;import javax.crypto.spec.IvParameterSpec;import com.sun.org.apache.xml.internal.security.utils.Base64;public class DESUtil public static final String ALGORITHM_DES = DES/CBC/PKCS5Padding; /** * DES算法，加密 * * @param data * 待加密字符串 * @param key * 加密私钥，长度不能够小于8位 * @return 加密后的字节数组，一般结合Base64编码使用 * @throws CryptException * 异常 */ public static String encode(String key, String data) throws Exception return encode(key, data.getBytes()); /** * DES算法，加密 * * @param data * 待加密字符串 * @param key * 加密私钥，长度不能够小于8位 * @return 加密后的字节数组，一般结合Base64编码使用 * @throws CryptException * 异常 */ public static String encode(String key, byte[] data) throws Exception try DESKeySpec dks = new DESKeySpec(key.getBytes()); SecretKeyFactory keyFactory = SecretKeyFactory.getInstance(DES); // key的长度不能够小于8位字节 Key secretKey = keyFactory.generateSecret(dks); Cipher cipher = Cipher.getInstance(ALGORITHM_DES); IvParameterSpec iv = new IvParameterSpec(12345678.getBytes()); AlgorithmParameterSpec paramSpec = iv; cipher.init(Cipher.ENCRYPT_MODE, secretKey, paramSpec); byte[] bytes = cipher.doFinal(data); return Base64.encode(bytes); catch (Exception e) throw new Exception(e); /** * DES算法，解密 * * @param data * 待解密字符串 * @param key * 解密私钥，长度不能够小于8位 * @return 解密后的字节数组 * @throws Exception * 异常 */ public static byte[] decode(String key, byte[] data) throws Exception try SecureRandom sr = new SecureRandom(); DESKeySpec dks = new DESKeySpec(key.getBytes()); SecretKeyFactory keyFactory = SecretKeyFactory.getInstance(DES); // key的长度不能够小于8位字节 Key secretKey = keyFactory.generateSecret(dks); Cipher cipher = Cipher.getInstance(ALGORITHM_DES); IvParameterSpec iv = new IvParameterSpec(12345678.getBytes()); AlgorithmParameterSpec paramSpec = iv; cipher.init(Cipher.DECRYPT_MODE, secretKey, paramSpec); return cipher.doFinal(data); catch (Exception e) // e.printStackTrace(); throw new Exception(e); /** * 获取编码后的值 * * @param key * @param data * @return * @throws Exception * @throws Exception */ public static String decodeValue(String key, String data) throws Exception byte[] datas; String value = null; datas = decode(key, Base64.decode(data)); value = new String(datas); if (value.equals()) throw new Exception(); return value; java后台服务器通过一个拦截器，拦截掉所有需要拦截的路径 package com.sz.kcygl.web.interceptor;/** * Created by LittleXuan on 2015/8/31. */import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import com.sz.kcygl.common.DESUtil.MD5;import com.sz.kcygl.common.DESUtil.DESUtil;import net.sf.json.JSONObject;import org.apache.commons.lang.StringUtils;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.springframework.web.servlet.handler.HandlerInterceptorAdapter;import java.io.BufferedInputStream;/** * @author 赵宏轩 * 2015-08-31 */public class SignInterceptor extends HandlerInterceptorAdapter protected final Log log = LogFactory.getLog(this.getClass()); /** * 在业务处理器处理请求之前被调用 * 如果返回false * 从当前的拦截器往回执行所有拦截器的afterCompletion(),再退出拦截器链 * 如果返回true */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception String requestUri = request.getRequestURI(); String contextPath = request.getContextPath(); String url = requestUri.substring(contextPath.length()); log.info(requestUri: + requestUri); log.info(contextPath: + contextPath); log.info(url: + url); StringBuffer requestData=new StringBuffer(); BufferedInputStream buf = new BufferedInputStream(request.getInputStream()); byte[] buffer=new byte[1024]; int iRead; while((iRead=buf.read(buffer))!=-1) requestData.append(new String(buffer,0,iRead,utf-8)); JSONObject jsonObject = JSONObject.fromObject(requestData.toString()); String requestDES = jsonObject.getString(requestMessage); String signvalue = jsonObject.getString(sign); log.info(加密后的字符串：+requestDES); log.info(MD5签名：+signvalue); String afterDES=; if(StringUtils.isNotEmpty(requestDES)) afterDES = DESUtil.decodeValue(tiananapp, requestDES); log.info(解密后请求：+afterDES); MD5 md5 =new MD5(); String localSign = md5.getMD5ofStr(tiananapp+afterDES); log.info(本地MD5签名：+localSign); if(signvalue!=nullsignvalue.equalsIgnoreCase(localSign)) request.setAttribute(requestMessage,afterDES); //将解密后的请求参数还原 return true; return false; 在Spring MVC 配置文件添加拦截器配置mvc:interceptors mvc:interceptor !-- 匹配的是url路径， 如果不配置或/**,将拦截所有的Controller -- mvc:mapping path=/** / mvc:exclude-mapping path=/front/**/!-- 匹配的是不需要拦截的url路径 bean class=com.sz.kcygl.web.interceptor.SignInterceptor/bean /mvc:interceptor\t/mvc:interceptors","tags":["java"],"categories":["java"]},{"title":"根据WebMagic写的一个爬取煎蛋网的小爬虫","path":"/2015/08/12/webmagic-java-jandanspider/","content":"之前研究jsoup，想用jsoup写一个小爬虫，爬煎蛋网的无聊图，我也是够无聊的 .,挖了个坑过了半个月还没填上，昨天上知乎的时候，发现有更加好用的爬虫框架WebMagic（知乎，果然让人发现更大的世界），先用WebMagic实现一下我的小爬虫，好啦，填坑开始… 这里用到webmagic，就把webmagic介绍，使用方法都放出来，没用过的先熟悉一下。 这里是WebMagic中文使用文档，一点即达 @.@ 介绍文档已经很详细了，下面开始，生产爬虫 分析煎蛋网无聊图html源码下面是煎蛋网无聊图页面的html源码片段 div id=content h1 class=title无聊图/h1 !-- begin comments -- div id=comments div style=clear:both;/div h3 class=title id=commentsTOTAL COMMENTS: 177,359span class=plusonea href=#respond title=来一发+1/a/span/h3 span class=break/span div class=comments div class=cp-pagenavispan class=current-comment-page[7095]/span a href=http://jandan.net/pic/page-7094#comments7094/a a href=http://jandan.net/pic/page-7093#comments7093/a a class=previous-comment-page href=http://jandan.net/pic/page-7094#comments title=Older Commentsraquo;/a/div /div ol class=commentlist style=list-style-type: none; li id=comment-2894921 div div class=row div class=authorstrong title=防伪码：8d6a6ef3b33b2280a7c0803dc5cb97977799cbd2不发表评论/strong br /div div class=textspan class=righttexta href=http://jandan.net/pic/page-7095#comment-2894921177358/a/spanpimg src=http://ww3.sinaimg.cn/mw600/a801236bjw1euyksy43o7j20f20qo40d.jpg //p /div /div span class=break/span/div /li li id=comment-2894895 div div class=row div class=authorstrong title=防伪码：10d69593001a14fc2189787eb1a0315113ff1714delectate/strong br smalla href=#footer title=@回复 onclick=document.getElementById(comment).value += #39;@lt;a href=quot;http://jandan.net/pic/page-7095#comment-2894895quot;gt;delectatelt;/agt;: #39;@37 mins ago/a/span/small /div div class=textspan class=righttexta href=http://jandan.net/pic/page-7095#comment-2894895177352/a/spanp老规矩，坟请猛x，谢谢。br /img src=http://ww2.sinaimg.cn/thumbnail/0066UPGbjw1euyrnitpbzg30b404gx6p.gif org_src=http://ww2.sinaimg.cn/mw1024/0066UPGbjw1euyrnitpbzg30b404gx6p.gif onload=add_img_loading_mask(this, load_sina_gif);//p/div /div span class=break/span/div /li /ol div class=comments div class=cp-pagenavispan class=current-comment-page[7095]/span a href=http://jandan.net/pic/page-7094#comments7094/a a href=http://jandan.net/pic/page-7093#comments7093/a a class=previous-comment-page href=http://jandan.net/pic/page-7094#comments title=Older Commentsraquo;/a/div h3 p id=respond发表评论/p /h3 /div /div /div !-- END wrapper --/body/html 先理一下思路 爬取无聊图首页图片想要爬的图片路径在div[idcontent]-div[id’comments’]-ol[classcommentlist]-li[id’xxxx’]-div-div[class’row’]-…-img[src]img的src链接就是静态图片的url，如果是动态图gif的话，那么org_src才是图片的真正url，src只是对应缩略图的url让爬虫选中列表项列表li，然后遍历每个li,然后取每个li的图片url和title, 保存图片到本地用httpclient根据图片url下载该图片保存在本地就行了 爬取下一页图片找到本页的下一页标签，从上面的源码片段可以看到是class=previous-comment-page的a标签当爬虫爬完首页时，接下来爬上一页，煎蛋网是倒序的… 开始编写爬虫首先，新建一个解析图片的Processor类新建一个PicProcessor类，继承自PageProcessor，并重写process方法 第一步，先处理首页图片//处理图片类 private void processPicture(Page page) //得到所有Gif的li标签 ListString gifLists = page.getHtml().xpath(//ol[@class=commentlist]/li[@id]).all(); for (String gif:gifLists) //得到标题 String title=xpath(//div[@class=author]/strong).selectElement(gif).attr(title); logger.info(title:+title); //得到上传者 String author=xpath(//div[@class=author]/strong).selectElement(gif).text(); //将标题中的防伪码转换为：上传者名称 title=title.replace(防伪码,author); //图片url //如果有org_src属性，则是gif图片 String url=xpath(//div[@class=text]/p/img).selectElement(gif).attr(src); String gifUrl=xpath(//div[@class=text]/p/img).selectElement(gif).attr(org_src); if(StringUtils.isNotEmpty(gifUrl)) logger.info(Gif图片...替换新链接...); url=gifUrl;//如果是gif则用大图链接替换缩略图链接 logger.info(图片url: + url); //保存图片到本地 String filePath=downloadDir+ File.separator+author; String picType=url.substring(url.length()-3); try FileUtil.downloadFile(url,filePath,title, picType); catch (Exception e) e.printStackTrace(); 保存图片的工具类代码： package com.zeusjava.jandan.util;import org.apache.http.HttpEntity;import org.apache.http.HttpResponse;import org.apache.http.client.methods.HttpGet;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.HttpClients;import org.apache.log4j.Logger;import java.io.File;import java.io.FileOutputStream;import java.io.InputStream;/** * Created by LittleXuan on 2015/8/11. * 文件操作工具类 */public class FileUtil private static Logger logger = Logger.getLogger(FileUtil.class); /** * 下载文件 * * @param url * 文件http地址 * @param filePath * 目标文件路径 * @param fileName * 目标文件 * @param picType * 文件类型 * @throws java.io.IOException */ public static synchronized void downloadFile(String url,String filePath, String fileName,String picType) throws Exception logger.info(----------------------下载文件开始---------------------); CloseableHttpClient httpclient = HttpClients.createDefault(); if (url == null || .equals(url)) return; //目标目录 File desPathFile = new File(filePath); if (!desPathFile.exists()) desPathFile.mkdirs(); //得到文件绝对路径 String fullPath =filePath +File.separator+fileName+.+picType; logger.info(文件路径：+filePath); logger.info(文件名：+fileName); logger.info(源文件url：+url); //从元网址下载图片 HttpGet httpget = new HttpGet(url); HttpResponse response = httpclient.execute(httpget); HttpEntity entity = response.getEntity(); InputStream in = entity.getContent(); //设置下载地址 File file = new File(fullPath); try FileOutputStream fout = new FileOutputStream(file); int l = -1; byte[] tmp = new byte[1024]; while ((l = in.read(tmp)) != -1) fout.write(tmp,0,l); fout.flush(); fout.close(); finally in.close(); logger.info(----------------------下载文件结束---------------------); 爬取下一页@Override public void process(Page page) System.out.println(================================); //定义抽取信息，并保存信息 processPicture(page); //得到下一页链接 String comments=page.getHtml().xpath(//a[@class=previous-comment-page]).toString(); logger.info(comments:+comments); String link = xpath(a/@href).select(comments); logger.info(link: + link); Request request = new Request(link); page.addTargetRequest(request); System.out.println(================================); 网站信息配置//得到网站配置 private Site site = Site.me().setDomain(jandan.net).addHeader(Accept, application/x-ms-application, image/jpeg, application/xaml+xml, image/gif, image/pjpeg, application/x-ms-xbap, */*) .addHeader(Referer, http://jandan.net/pic).setSleepTime(10000).setUserAgent(zhaohongxuan) .addStartUrl(http://jandan.net/pic); 这里注意的是，要设置UserAgent，之前没加代理，刚开始启动程序可以爬，后来，煎蛋网就给屏蔽了，HttpClient返回HTTP/1.1 302 Moved Temporarily，煎蛋网把请求给重定向了设置SleepTime可以设置每次爬取之间的时间间隔，我写的是10000ms，即程序爬完一页之后休息10s继续爬下一页。 编写程序入口public class JanDanSpiderTest private static Logger logger = Logger.getLogger(JanDanSpiderTest.class); public static void main(String[] args) PropertyConfigurator.configure(ClassLoader.getSystemResourceAsStream(log4j.properties)); Spider.create(new PicProcessor()).scheduler(new PriorityScheduler()).run(); 由于WebMagic采用的是链式编程，可以很方便的进行配置，上面我默认用的是PriorityScheduler，当然也可以使用多线程，使用thread()括号里写上Thread的数量就行了 Spider.create(new PicProcessor()).scheduler(new PriorityScheduler()).thread(10).run(); 本程序源代码请戳JanDanSpider…","tags":["java"],"categories":["java"]},{"title":"Xpath语法学习","path":"/2015/08/11/xml-xpath-learning/","content":"最近写爬虫时，需要解析html，有好多种选择xml文档节点的方法，先熟悉一下使用xpath来选取节点、解析节点 下面是学习需要的XML文档 ?xml version=1.0 encoding=UTF-8?bookstorebook title lang=engHarry Potter/title price29.99/price/bookbook title lang=engLearning XML/title price39.95/price/book/bookstore 选取节点XPath使用路径表达式在XML文档中选取节点。节点是通过沿着路径或者step来选取的。 最有用的路径表达式如下： nodename\t选取此节点的所有子节点。/ 从根节点选取。// 从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。. 选取当前节点。.. 选取当前节点的父节点。@ 选取属性。####实例 bookstore\t选取 bookstore 元素的所有子节点。 bookstore\t选取根元素 bookstore。 注意：假如路径起始于正斜杠( )，则此路径始终代表到某元素的绝对路径！ bookstore/book\t选取属于 bookstore 的子元素的所有 book 元素。 //book\t选取所有 book 子元素，而不管它们在文档中的位置。 bookstore//book\t选择属于 bookstore 元素的后代的所有 book 元素，而不管它们位于 bookstore 之下的什么位置。 //@lang\t选取名为 lang 的所有属性。 谓语（Predicates）谓语用来查找某个特定的节点或者包含某个指定的值的节点。谓语被嵌在方括号中。 实例/bookstore/book[1]\t选取属于 bookstore 子元素的`第一个` book 元素。 /bookstore/book[last()]\t选取属于 bookstore 子元素的`最后一个` book 元素。 /bookstore/book[last()-1]\t选取属于 bookstore 子元素的`倒数第二个` book 元素。 /bookstore/book[position()3]\t选取`最前面的两个`属于 bookstore 元素的子元素的 book 元素。 //title[@lang]\t选取`所有`拥有名为`lang的属性`的 title 元素。 //title[@lang=eng]\t选取`所有` title 元素，且这些元素拥有值为 eng 的 lang 属性。 /bookstore/book[price35.00]\t选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须`大于` 35.00。 /bookstore/book[price35.00]/title\t选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。 选取未知节点XPath 通配符可用来选取未知的 XML 元素。*\t匹配任何元素节点。@*\t匹配任何属性节点。node()\t匹配任何类型的节点。 实例/bookstore/*\t选取 bookstore 元素的所有`子元素`。 //*\t选取文档中的`所有元素`。 //title[@*]\t选取所有带有属性的`title`元素。 选取若干路径通过在路径表达式中使用|运算符，您可以选取若干个路径。 实例//book/title | //book/price\t选取 book 元素的所有 title 和 price 元素。 //title | //price\t选取文档中的所有 title 和 price 元素。 /bookstore/book/title | //price\t选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。","tags":["xml"],"categories":["技术随笔"]},{"title":"微信OAuth2.0鉴权获取用户信息","path":"/2015/04/22/wechat-get-userinfo/","content":"在微信开发中经常需要在网页中获取用户的基本信息，和UnionID机制获取用户信息的方式不同,这种方式可以得到未关注本微信号的人的基本信息。 首先第一步要在微信公众平台上配置回调域名，注意域名不是URL，不要包涵http://等协议头 开发步骤1.用户同意授权，获取code在确保微信公众账号拥有授权作用域（scope参数）的权限的前提下（服务号获得高级接口后，默认拥有scope参数中的snsapi_base和snsapi_userinfo），引导关注者打开如下页面： https://open.weixin.qq.com/connect/oauth2/authorize?appid=APPIDredirect_uri=REDIRECT_URIresponse_type=codescope=SCOPEstate=STATE#wechat_redirect redirect_uri是授权后重定向的回调链接地址，请使用urlencode对链接进行处理response_type是返回类型，请填写codescope是应用授权作用域，snsapi_base （不弹出授权页面，直接跳转，只能获取用户openid），snsapi_userinfo （弹出授权页面，可通过openid拿到昵称、性别、所在地。并且，即使在未关注的情况下，只要用户授权，也能获取其信息）state否重定向后会带上state参数，开发者可以填写a-zA-Z0-9的参数值，最多128字节wechat_redirect无论直接打开还是做页面302重定向时候，必须带此参数 用户同意授权后如果用户同意授权，页面将跳转至 redirect_uri/?code=CODEstate=STATE。若用户禁止授权，则重定向后不会带上code参数，仅会带上state参数redirect_uri?stateSTATE code说明 ： code作为换取access_token的票据，每次用户授权带上的code将不一样，code只能使用一次，`5分钟`未被使用自动过期。 拼接授权连接Java代码 public static String getMenuOauthUrl(String appId,String url,String state)\tString authUrl=https://open.weixin.qq.com/connect/oauth2/authorize?appid=+appId+redirect_uri=+url+response_type=codescope=snsapi_basestate=+state+#wechat_redirect;\treturn authUrl; snsapi_base可以改为snsapi_userinfo可以得到用户所有的信息，否则只能获得openId 2.通过code换取网页授权access_token首先请注意，这里通过code换取的是一个特殊的网页授权access_token,与基础支持中的access_token（该access_token用于调用其他接口）不同。公众号可通过下述接口来获取网页授权access_token。如果网页授权的作用域为snsapi_base，则本步骤中获取到网页授权access_token的同时，也获取到了openid，snsapi_base式的网页授权流程即到此为止。 请求方法 获取code后，请求以下链接获取access_token： https://api.weixin.qq.com/sns/oauth2/access_token?appid=APPIDsecret=SECRETcode=CODEgrant_type=authorization_code code填写第一步获取的code参数grant_type填写为authorization_code得到AccessToken代码 public static MapString,String getCodeAccessToken(String appid, String secret, String code) MapString,String map = new HashMapString, String(); if (StringUtils.isBlank(appid) || StringUtils.isBlank(secret) || StringUtils.isBlank(code)) return map; StringBuilder sb = new StringBuilder(https://api.weixin.qq.com/sns/oauth2/access_token); sb.append(?appid=).append(appid).append(secret=).append(secret); sb.append(code=+code).append(grant_type=authorization_code); String result = HttpClientUtil.getRequest(sb.toString(), ,UTF-8, text/html); logger.info(result:+result); if (StringUtils.isNotEmpty(result)) JSONObject jo = JSON.parseObject(result); String errcode = jo.getString(errcode); String errmsg = jo.getString(errmsg); if (StringUtils.isNotEmpty(errcode)) //出错了 logger.info(clll wx error,errcode= + errcode + , errmsg= + errmsg); map.put(errcode, errcode); map.put(errmsg,errmsg); else String access_token = jo.getString(access_token);//访问凭证 String expires_in = jo.getString(expires_in);//凭证有效时间 String refresh_token = jo.getString(refresh_token);//用户刷新access_token String openid = jo.getString(openid); String scope = jo.getString(scope); map.put(access_token,access_token); map.put(expires_in,expires_in); map.put(refresh_token,refresh_token); map.put(openid,openid); map.put(scope,scope); return map; 如果Scope为基本信息的话，那么本步骤中获取到网页授权access_token的同时，也获取到了openid，snsapi_base式的网页授权流程即到此为止。 /** * 获取openId * @param request * @return * @throws Exception */public String getOpenId(HttpServletRequest request) throws Exception String appid = PropertiesLoader.getPropertiesByName(appId);\tString appSerect = PropertiesLoader.getPropertiesByName(secret);\tString code = this.getParameter(request, code);\tMapString, String map = AccessTokenUtil.getCodeAccessToken(appid, appSerect, code);\tString openid = map.get(openid);\tString state = this.getParameter(request, state);\treturn openid; 3.拉取用户信息(需scope为 snsapi_userinfo)如果网页授权作用域为snsapi_userinfo，则此时开发者可以通过access_token和openid拉取用户信息请求方法http：GET（请使用https协议） https://api.weixin.qq.com/sns/userinfo?access_token=ACCESS_TOKENopenid=OPENIDlang=zh_CN 得到微信返回的报文 public static String getBaseUserInfoAPI(String accessToken, String openId) logger.info(进入获取用户信息(snsapi_base)API方法); String reqUrl = WeiXinUrlUtil.getBaseUserInfoUrl(accessToken, openId); String resDoc = HttpClientUtil.getRequestHandler(reqUrl, , 获取用户信息); return resDoc; 将报文转换为自己需要的Object即可","tags":["wechat"],"categories":["技术随笔"]},{"title":"Spring MVC 数据类型绑定","path":"/2015/04/14/springmvc-data-binding/","content":"今天遇到一个问题，使用Spring MVC 从页面传递一个用户List到Controller，然后再后台解析List得到多个用户对象，在网上搜了很多答案感觉都不行,后来调试代码发现，最关键在于:List需要绑定在对象(ActionForm),直接写在request-mapping函数的参数是不行的,更重要的一点是要创建对象(ArrayList)。 之前的Jsp代码是这么写的 form action=insertInsureUser.do method=post div class=form_left开始时间:/div div class=form_right input name=insureObject.startTime/ /div div class=form_left产品代码:/div div class=form_right input name=insureObject.productCode/ h2投保人信息/h2 /div div class=form_left姓名:/div div class=form_right input name=insureObject.insureUser[0].startTime/ /div div class=form_left身份证号:/div div class=form_right input name=insureObject.insureUser[0].idCard/ /div div class=form_left性别:/div div class=form_right input name=insureObject.insureUser[0].sex/ /div div class=form_left地址:/div div class=form_right input name=insureObject.insureUser[0].address/ /div div class=form_left邮箱:/div div class=form_right input name=insureObject.insureUser[0].email/ /div div class=form_left电话号码:/div div class=form_right input name=insureObject.insureUser[0].phone/ /div h2被保人信息/h2 /div div class=form_left姓名:/div div class=form_right input name=insureObject.insureUser[1].startTime/ /div div class=form_left身份证号:/div div class=form_right input name=insureObject.insureUser[1].idCard/ /div div class=form_left性别:/div div class=form_right input name=insureObject.insureUser[1].sex/ /div div class=form_left地址:/div div class=form_right input name=insureObject.insureUser[1].address/ /div div class=form_left邮箱:/div div class=form_right input name=insureObject.insureUser[1].email/ /div div class=form_left电话号码:/div div class=form_right input name=insureObject.insureUser[1].phone/ /div/form controller代码 @RequestMapping(/insertInsureUser.do)\tpublic String queryAppUserGroup(HttpServletRequest request, HttpServletResponse response, ModelMap model, @ModelAttribute(insureObject) InsureUserQueryObject insureObject) throws Exception logger.info(=======List类型数据绑定======); if(insureObject!=nullinsureObject.getInsureUsers.size()0) for(InsureUser insureUser:insureObject) System.out.println(insureUser.getName()); 网上很多人都给不出答案,关键在于,List需要绑定在对象(ActionForm),直接写在request-mapping函数的参数是不行的,更重要的一点是要创建对象(ArrayList).实体InsureUserQueryObject代码 public class InsureUserQueryObject private String startTime;//起始时间 private String productCode;//产品代码 private ListInsureUser insureUsers;//投保人被保人 public String getStartTime() return startTime; public void setStartTime(String startTime) this.startTime = startTime; public String getProductCode() return productCode; public void setProductCode(String productCode) this.productCode = productCode; public ListInsureUser getInsureUsers() return insureUsers; public void setInsureUsers(ListInsureUser insureUsers) this.insureUsers = insureUsers; List中要用到的InsureUser代码如下 public class InsureUser private String name;//姓名 private String idCard;//身份证号 private String sex;//性别 private String address;//地址 private String email;//邮箱 private String phone;//电话号码 public String getName() return name; public void setName(String name) this.name = name; public String getIdCard() return idCard; public void setIdCard(String idCard) this.idCard = idCard; public String getSex() return sex; public void setSex(String sex) this.sex = sex; public String getAddress() return address; public void setAddress(String address) this.address = address; public String getEmail() return email; public void setEmail(String email) this.email = email; public String getPhone() return phone; public void setPhone(String phone) this.phone = phone; 后来发现，控制台报属性不存在异常，查资料后发现，Spring MVC 数据绑定和struts是不一样的，o(╯□╰)o，表单前面不需要添加实体对象insureObject,把insureObject删除掉更改过后的jsp代码为： form action=insertInsureUser.do method=post div class=form_left开始时间:/div div class=form_right input name=startTime/ /div div class=form_left产品代码:/div div class=form_right input name=productCode/ h2投保人信息/h2 /div div class=form_left姓名:/div div class=form_right input name=insureUser[0].startTime/ /div div class=form_left身份证号:/div div class=form_right input name=insureUser[0].idCard/ /div div class=form_left性别:/div div class=form_right input name=insureUser[0].sex/ /div div class=form_left地址:/div div class=form_right input name=insureUser[0].address/ /div div class=form_left邮箱:/div div class=form_right input name=insureUser[0].email/ /div div class=form_left电话号码:/div div class=form_right input name=insureUser[0].phone/ /div h2被保人信息/h2 /div div class=form_left姓名:/div div class=form_right input name=insureUser[1].startTime/ /div div class=form_left身份证号:/div div class=form_right input name=insureUser[1].idCard/ /div div class=form_left性别:/div div class=form_right input name=insureUser[1].sex/ /div div class=form_left地址:/div div class=form_right input name=insureUser[1].address/ /div div class=form_left邮箱:/div div class=form_right input name=insureUser[1].email/ /div div class=form_left电话号码:/div div class=form_right input name=insureUser[1].phone/ /div\t/form 但是发现更改过后还是有异常，数组越界异常啊摔，原来是页面在向InsureUserQueryObject的对象写数据时发现List列表是空的，于是在InsureUserQueryObject中给List赋一个ArrayList的初值，添加一个默认构造函数，在构造函数中向列表中添加一个两个InsureUser用来存储页面传过来的InsureUser对象 大功告成！！修改过后的InsureUserQueryObject public class InsureUserQueryObject private String startTime;//起始时间 private String productCode;//产品代码 private ListInsureUser insureUsers = new ArrayListInsureUser();//投保人被保人 public InsureUserQueryObject() InsureUser user1=new InsureUser();InsureUser user2=new InsureUser();insureUsers.add(user1);//添加投保人insureUsers.add(user2);//添加被保人 public String getStartTime() return startTime; public void setStartTime(String startTime) this.startTime = startTime; public String getProductCode() return productCode; public void setProductCode(String productCode) this.productCode = productCode; public ListInsureUser getInsureUsers() return insureUsers; public void setInsureUsers(ListInsureUser insureUsers) this.insureUsers = insureUsers;","tags":["java/spring"],"categories":["spring框架"]},{"title":"Git常见命令!","path":"/2015/04/10/base-git-command/","content":"Git基本操作命令创建Git版本仓库在本地的任何一个空目录，通过git init把目录变成一个Git仓库 git init 添加文件到Git仓库git add file_name 提交文件到Git仓库git commit -m commit_message 显示提交日志git log [--pretty=oneline] 可以加上--pretty=oneline参数来减少输出的信息,\tgit log --graph命令可以看到分支合并图。 回退上一个版本git reset --hard HEAD 上一个版本就是HEAD^，上上一个版本就是HEAD^^，如果版本号较多，可以写成HEAD~100。 查看命令日志git reflog 查看Git仓库状态git status 添加文件到暂存区git add 将暂存区文件提交到当前分支git commit 撤销修改git checkout --file_name 删除文件git rm file_name 远程仓库添加远程库在本地的仓库下面运行 $ git remote add origin git@github.com:zhaohongxuan/zhaohongxuan.github.io.git 将本地库内容推送到远程库上 git push [-u] origin master 其中-u参数会把本地的master分支和远程的master分支关联起来。 从远程仓库克隆$ git clone git@github.com:zhaohongxuan/zhaohongxuan.github.io.git 地址可使用SSH协议的git地址，也可以使用Https协议的地址 分支管理查看当前分支git branch 显示本地、服务器所有分支git branch -a 显示本地分支和服务器分支的映射关系git branch -vv 切换分支git checkout branch_name 创建新分支git checkout -b branch_name 提交本地分支代码到远端服务器git push origin remote_branch_name 如果远端服务器没有该分支，将会自动创建 更新远端分支代码到本地当前分支git pull origin master 合并分支到当前分支git merge branch_name 合并远程master分支到当前分支git merge origin/master 删除本地分支git checkout another_branch git branch -d branch_name 删除远程分支git push origin --delete branch_name 标签管理创建标签首先切换到要创建标签的分支 git tag tag_name 标签打在最新提交的commit上 查看标签git tag 查看标签详情git show tag tag_name 删除标签git tag -d tag_name 将标签推送至远程git push origin tag_name 使用git push origin --tags 推送所有标签到远程 删除远程标签删除远程标签需要先删除本地的标签，然后输入下面命令 git push origin :refs/tags/tagname","categories":["技术随笔"]},{"title":"【微信接口学习】基础接口","path":"/2015/04/04/wechat-base-interface/","content":"获取access_tokenaccess_token是公众号的全局唯一票据，公众号调用各接口时都需使用access_token。 1. access_token的存储至少要保留512个字符空间。 2. access_token的有效期目前为2个小时，需定时刷新，重复获取将导致上次获取的access_token失效。 3. 需要中控服务器定时获取和刷新access_token，而且还需要被动刷新access_token 接口调用请求说明 http请求方式: GET https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credentialappid=APPIDsecret=APPSECRET 正常情况下，微信会返回下述JSON数据包给公众号： access_token:ACCESS_TOKEN,expires_in:7200 获取微信服务器的IP地址接口调用请求说明 http请求方式: GET https://api.weixin.qq.com/cgi-bin/getcallbackip?access_token=ACCESS_TOKEN 正常情况下，微信会返回下述JSON数据包给公众号： ip_list:[127.0.0.1,127.0.0.1] 上传和下载多媒体文件1. 对多媒体文件的操作是通过media_id来进行的 2. 每个多媒体文件在发送到服务器3天后自动删除 上传多媒体文件接口 调用请求说明 http请求方式: POST/FORM http://file.api.weixin.qq.com/cgi-bin/media/upload?access_token=ACCESS_TOKENtype=TYPE 调用示例（使用curl命令，用FORM表单方式上传一个多媒体文件）： curl -F media=@test.jpg http://file.api.weixin.qq.com/cgi-bin/media/upload?access_token=ACCESS_TOKENtype=TYPE 正确情况下的返回JSON数据包结果如下： {“type”:”TYPE”,”media_id”:”MEDIA_ID”,”created_at”:123456789}下载多媒体文件接口调用请求说明 http请求方式: GET http://file.api.weixin.qq.com/cgi-bin/media/get?access_token=ACCESS_TOKENmedia_id=MEDIA_ID 请求示例（示例为通过curl命令获取多媒体文件） curl -I -G http://file.api.weixin.qq.com/cgi-bin/media/get?access_token=ACCESS_TOKENmedia_id=MEDIA_ID","tags":["wechat"],"categories":["技术随笔"]},{"title":"欢迎来到zhaohongxuan的代码空间!","path":"/2015/04/03/the-start-of-my-blog/","content":"每一天都是崭新的，在阳光下用力呼吸 世界好大，知识无涯，愿我能够在有生之年，能在知识的海洋多撷几枚贝壳 黑夜纵会漫长，过后便是黎明","categories":["散文随笔"]},{"title":"关于我","path":"/about/index.html","content":"#about me 我的名字叫赵宏轩（Hank Zhao），老家洛阳，现居上海，目前从事后端开发，我从2014年开始从事软件开发工作，这个网站构建于2015年，使用Hexo构建，这里没有广告，没有跟踪和分析，没有赞助和付费，这里是我进行自我表达的空间，希望我写的内容能够对你有所帮助，如果有问题，欢迎在文章下面留言，或者在X 上面DM我。 下面简单列举一下自己的喜好吧，方便你对我有进一步的认识。 喜欢跑步，跑过很多马拉松，现在比较佛系，跑步已经是一个日常习惯了。跑步装备为 Apple Watch Series 7 （之前是Series 4） + Airpods Pro，平时不带手机出门，很喜欢这个和自己单独对话的时间。 喜欢骑行，大学的时候买了一辆美利达勇士600山地车，然后就经常骑着在周边城市玩，最高记录是一天从洛阳家里一直骑到开封的学校，手机坏了没带手机。最近一次长距离骑行是单日骑行环太湖240km，现在这辆车还在使用中，已经服役十多年了，现在添置了一辆新的平把公路车Revolt F1，现在天气好的时候也会出去骑行，喜欢骑太浦河和淀山湖，欢迎上海的朋友约骑 。 喜欢开源，主要使用Java、Typescript、Go、Python语言，写过几个开源项目，可以参考我的 Github主页：zhaohongxuan (HankZhao) · GitHub 喜欢Vim，Intellij IDEA和VSCode都是Vim模式，曾经还给Ideavim录过一个视频，可以参考: ideavim插件的配置和使用 喜欢读书，喜欢读历史和哲学，还有偏社科的书籍，喜欢庄子、塔勒布、王小波、余华、刘慈欣、尼采、叔本华、查理芒格等，最喜欢的书是《红楼梦》，现在基本上不买纸质书了，基本上都使用电子书，以前是Kindle，现在使用的是微信读书，电纸书设备为Boox Poker 3，只有买不到电子版的才会考虑纸质书。我也坚信书只是信息的媒介，有价值的是信息本身，而不是传递介质。 喜欢数码产品，诺基亚塞班时期，经常给我的诺基亚6300手机刷机，智能机时代也经常玩刷机，现在基本上都是苹果全家桶了。 喜欢写作，平时使用Obsidian来写作以及记录日志和灵感，非常认同 「File Over App」的理念，正在尝试使用Obsidian构建自己的第二大脑。 做点有趣的事情，Be Happy。"},{"title":"项目","path":"/projects/index.html","content":"about my projects"},{"title":"运动","path":"/workouts/index.html","content":""}]